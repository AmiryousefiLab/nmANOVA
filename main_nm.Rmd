---
title: "nmANOVA main fucntions + paper examples"
output: html_notebook
---

a new version of nmANOVA (it takes into account NAs)
```{r}
#H0 holds for uniform
#nmANOVA(d, c( cluster1, cluster1,cluster1,cluster2,cluster2,cluster3), c( 'cluster2', 'cluster3') )
nmANOVA <- function( diss_data, partition, N_sampling = 1, subpartition = NULL ) {
  
  #diss_data - a numeric matrix or data.frame with dissimilarity measures,columns and rows should be in the same order
  #partition - a vector specifying the groups, it should be same length and in the same order as diss_data columns/rows 
  #subpartition - a vector of groups present in partition for which the method has to be applied to 
  #if subpartition is NULL, the method will be applied to all the groups present in partition ( unique( partition ) )
  
  if ( nrow( diss_data ) != ncol( diss_data ) )
    stop( "matrix has to be square" )
  
  if ( nrow( diss_data ) != length( partition ) )
    stop( "partition has to be same length as the number of row/columns in the matrix" )
  
  if ( N_sampling <= 0 )
    stop( "N_sampling has to be a positive integer" )
  
  if ( !is.null( subpartition ) & length( unique( subpartition ) ) < 2 )
    stop( "there should be at least two unique subpartitions" )
  
  
  
  partition <- as.factor( as.vector( partition ) )
  partition_sorted <- partition[ order( partition ) ]
  
  inner_partition_names <- vector()
  for ( i in 1:length( levels( partition_sorted ) ) ){
    inner_partition_names <- c( inner_partition_names, paste0( levels( partition_sorted )[i],'_', seq( 1:table( partition_sorted )[i] ) ) )
  }
  
  #set the names for each column/row based on a partition they belong to
  inner_partition_names <- inner_partition_names[ order( order ( partition ) ) ]
  partition_df <- as.data.frame( diss_data )
  colnames( partition_df ) <- inner_partition_names
  rownames( partition_df ) <- inner_partition_names
  
  #check if there is a subpartition provided  
  if ( !is.null( subpartition ) ){
    if ( length( unique( intersect( partition, subpartition ) ) ) !=  length( unique( subpartition )  )  )
      stop( "some elements from the subpartition do not match with partition" )
    subpartition <- as.factor( as.vector( subpartition ) )
    partition <- partition[ which( partition %in% intersect( partition, subpartition ) ) ]
  }
  
  selected_partitions <- which( sub('_[^_]*$', '', colnames( partition_df ) ) %in% partition )
  selected_partitions <- which( sub('_[^_]*$', '', rownames( partition_df ) ) %in% partition )
  partition_df <- partition_df[ selected_partitions, selected_partitions ]
  partition_df <- partition_df[ order( row.names( partition_df ) ), order( names( partition_df ) ) ]
  
  #the actual partition
  partition <- as.factor( sub('_[^_]*$', '', colnames( partition_df ) ) )
  #number of elements in each partition
  n_partition <- as.vector( table( partition ) )

  #calculate delta_w and delta_jj
  vec_within <- vector()
  delta_jj <- vector()
  SNM_w <- 0
  for( i in 1:length( levels( partition ) ) ){
    
    ind_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
    cur_partition <-  as.numeric( as.matrix( partition_df[ ind_partition, ind_partition ] ) )
    vec_within <- c( vec_within, cur_partition)
    delta_jj[i] <- mean( cur_partition, na.rm = TRUE )
    
  }
  
  delta_w <- mean( vec_within, na.rm = TRUE )
  
  #calculate SNM_w
  SNM_w <- 0
  for( i in 1:length( levels( partition ) ) ){
    
    ind_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
    cur_partition <-  as.numeric( as.matrix( partition_df[ ind_partition, ind_partition ] ) )
    
    n_cur_partition <- sum( is.na( cur_partition ) == FALSE )
 
   
    SNM_w <- SNM_w + n_cur_partition * (  ( delta_jj[i] - delta_w ) )^2
  }
  
  
  #calculate delta_jj', delta_prop and SNM_b
  
  off_diag_new <- 0
  for( i in 1:length( levels( partition ) ) ){
      for( j in 1:length( levels( partition ) ) ){
        if( i != j ){ 
          
          ind_row_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
          ind_col_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[j] )
          cur_partition <-  as.numeric( as.matrix( partition_df[ ind_row_partition, ind_col_partition ] ) )
          
          off_diag_new <- off_diag_new +  sum( is.na( cur_partition ) == FALSE )
          
          
          
        }
      }
  }
  
  
  num_off_diag_groups <- length( levels( partition ) )^2 - length( levels( partition ) )
  num_off_diag <- off_diag_new
  
  F_stat_array <- vector()
  prop_sampl_df_list <- list()

  for( ii in 1:N_sampling ){
 
    diagonal_sampling <- vec_within[!is.na(vec_within)]
    
    
    prop_sampl_df <- data.frame( N_sampling_num = rep( ii, num_off_diag_groups ), #which N_sampling is performed
                                 sampling_num = numeric( num_off_diag_groups ),#how many elements are sampled
                                 partitions = character( num_off_diag_groups ),# for what between group partition the sampling is performed
                                 part_mean = numeric( num_off_diag_groups ),# mean of the current between group partition
                                 prop_mean = numeric( num_off_diag_groups ),# mean of the sampled elements  
                                 sampling_ind = character( num_off_diag_groups), #indexes for the sampled elements from the vector of the whole
                                 sampled_from = character(num_off_diag_groups), 
                                 stringsAsFactors=FALSE )  
    
    non_na_vec_within <- sum( is.na( vec_within ) == FALSE )
    
    
    k <- 0
    delta_jj_prime <- vector()
    SNM_b <- 0
    SNM_b_array <- vector()
    for( i in 1:length( levels( partition ) ) ){
      for( j in 1:length( levels( partition ) ) ){
        if( i != j ){ 
          
          ind_row_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
          ind_col_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[j] )
          cur_partition <-  as.numeric( as.matrix( partition_df[ ind_row_partition, ind_col_partition ] ) )
          non_na_cur_partition <-  sum( is.na( cur_partition ) == FALSE )
          delta_jj_prime <- mean( cur_partition,  na.rm = TRUE )
           
          prop_num <- floor( non_na_cur_partition  *  non_na_vec_within  / as.numeric( num_off_diag )  ) 
    
          if( prop_num == 0 ){
            print( 'prop_num = 0 -> changed to 1' )
            prop_num <- 1 }
        
          sample_ind <- sample( c( 1:length( diagonal_sampling ) ), prop_num, replace = FALSE )
          k <- k + 1
          prop_sampl_df$sampling_num[k] <- prop_num
          prop_sampl_df$partitions[k] <- paste0( levels( partition )[i], ',', levels( partition )[j] )
          prop_sampl_df$sampling_ind[k] <- paste0( sample_ind, collapse = ',' )
          prop_sampl_df$sampled_from[k] <- paste0( round( diagonal_sampling, 3) , collapse = ',' )
          delta_prop <- mean( diagonal_sampling[ sample_ind ],  na.rm = TRUE )
          
    
          if( floor( non_na_cur_partition  *  non_na_vec_within  / as.numeric( num_off_diag )  )  != 0 ){ diagonal_sampling <- diagonal_sampling[ -sample_ind ] }
          prop_sampl_df$prop_mean[k] <- delta_prop
          
          
          delta_jj_prime <- mean( cur_partition,  na.rm = TRUE )
               
          prop_sampl_df$part_mean[k] <- delta_jj_prime
          SNM_b <- SNM_b + ( ( delta_jj_prime - delta_prop )/( sqrt( ( 1/( non_na_cur_partition ) + 1/prop_num ) ) ) )^2
          
        }
      }
    }
    
    #calculate statistics
    prop_sampl_df_list[[ii]] <- prop_sampl_df 
    SNM_b_array[ii] <- SNM_b
    F_stat_array[ii] <- ( SNM_b/length( levels( partition ) ) ) / SNM_w
    
  }
  
  
  
  F_stat <- mean( F_stat_array, na.rm = TRUE )
  
  df1 <- length( levels( partition ) )^2 - length( levels( partition ) )
  df2 <-  length( levels( partition ) ) - 1
  p_value <- pf( F_stat, df1, df2, lower.tail = F ) 
  partition_df1 <- partition_df

  
  res <- list()
  
  res[[1]] <- data.frame( N_partitions = length( levels( partition ) ), partition = paste(  levels( partition ) , collapse = ','), n_partition = paste( n_partition , collapse= ','  ), delta_w = delta_w,  delta_jj = paste( delta_jj, collapse= ',' ),  SNM_w = SNM_w,  SNM_b = mean( SNM_b_array, na.rm = TRUE ), F_stat =  F_stat, p_value = p_value  )
  
  res[[2]] <- do.call( rbind.data.frame, prop_sampl_df_list )
 
  names( res ) <- c( 'summary', 'proportional_sampling' ) 
  
  res
  
}

```

old version of nmANOVA (no NA consideration)
```{r}
nmANOVA1 <- function( diss_data, partition, N_sampling = 1, subpartition = NULL ) {
  
  #diss_data - a numeric matrix or data.frame with dissimilarity measures,columns and rows should be in the same order
  #partition - a vector specifying the groups, it should be same length and in the same order as diss_data columns/rows 
  #subpartition - a vector of groups present in partition for which the method has to be applied to 
  #if subpartition is NULL, the method will be applied to all the groups present in partition ( unique( partition ) )
  
  if ( nrow( diss_data ) != ncol( diss_data ) )
    stop( "matrix has to be square" )
  
  if ( nrow( diss_data ) != length( partition ) )
    stop( "partition has to be same length as the number of row/columns in the matrix" )
  
  if ( N_sampling <= 0 )
    stop( "N_sampling has to be a positive integer" )
  
  if ( !is.null( subpartition ) & length( unique( subpartition ) ) < 2 )
    stop( "there should be at least two unique subpartitions" )
  
  
  
  partition <- as.factor( as.vector( partition ) )
  partition_sorted <- partition[ order( partition ) ]
  
  inner_partition_names <- vector()
  for ( i in 1:length( levels( partition_sorted ) ) ){
    inner_partition_names <- c( inner_partition_names, paste0( levels( partition_sorted )[i],'_', seq( 1:table( partition_sorted )[i] ) ) )
  }
  
  #set the names for each column/row based on a partition they belong to
  inner_partition_names <- inner_partition_names[ order( order ( partition ) ) ]
  partition_df <- as.data.frame( diss_data )
  colnames( partition_df ) <- inner_partition_names
  rownames( partition_df ) <- inner_partition_names
  
  #check if there is a subpartition provided  
  if ( !is.null( subpartition ) ){
    if ( length( unique( intersect( partition, subpartition ) ) ) !=  length( unique( subpartition )  )  )
      stop( "some elements from the subpartition do not match with partition" )
    subpartition <- as.factor( as.vector( subpartition ) )
    partition <- partition[ which( partition %in% intersect( partition, subpartition ) ) ]
  }
  
  selected_partitions <- which( sub('_[^_]*$', '', colnames( partition_df ) ) %in% partition )
  selected_partitions <- which( sub('_[^_]*$', '', rownames( partition_df ) ) %in% partition )
  partition_df <- partition_df[ selected_partitions, selected_partitions ]
  partition_df <- partition_df[ order( row.names( partition_df ) ), order( names( partition_df ) ) ]
  
  #print( sum( colnames( partition_df ) == rownames( partition_df ) ) == nrow( partition_df ) )
  
  #the actual partition
  partition <- as.factor( sub('_[^_]*$', '', colnames( partition_df ) ) )
  #number of elements in each partition
  n_partition <- as.vector( table( partition ) )
  
  #calculate delta_w and delta_jj
  vec_within <- vector()
  delta_jj <- vector()
  
  for( i in 1:length( levels( partition ) ) ){
    
    ind_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
    cur_partition <-  as.numeric( as.matrix( partition_df[ ind_partition, ind_partition ] ) )
    vec_within <- c( vec_within, cur_partition)
    delta_jj[i] <- mean( cur_partition, na.rm = TRUE )
    
  }
  
  delta_w <- mean( vec_within, na.rm = TRUE )
  
  #calculate SNM_w
  SNM_w <- 0
  for( i in 1:length( levels( partition ) ) ){
    SNM_w <- SNM_w +  ( n_partition[i] * ( delta_jj[i] - delta_w ) )^2
  }
  
  
  #calculate delta_jj', delta_prop and SNM_b
  
  num_off_diag <- nrow( partition_df )^2 - length( vec_within )
  num_off_diag_groups <- length( levels( partition ) )^2 - length( levels( partition ) )
  
  F_stat_array <- vector()
  prop_sampl_df_list <- list()
  
  
  for( ii in 1:N_sampling ){
    
    diagonal_sampling <- vec_within  
    prop_sampl_df <- data.frame( N_sampling_num = rep( ii, num_off_diag_groups ), #which N_sampling is performed
                                 sampling_num = numeric( num_off_diag_groups ),#how many elements are sampled
                                 partitions = character( num_off_diag_groups ),# for what between group partition the sampling is performed
                                 part_mean = numeric( num_off_diag_groups ),# mean of the current between group partition
                                 prop_mean = numeric( num_off_diag_groups ),# mean of the sampled elements  
                                 sampling_ind = character( num_off_diag_groups), #indexes for the sampled elements from the vector of the whole
                                 sampled_from = character(num_off_diag_groups), 
                                 stringsAsFactors=FALSE )  
    
    k <- 0
    delta_jj_prime <- vector()
    SNM_b <- 0
    SNM_b_array <- vector()
    for( i in 1:length( levels( partition ) ) ){
      for( j in 1:length( levels( partition ) ) ){
        if( i != j ){ 
          
          ind_row_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
          ind_col_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[j] )
          cur_partition <-  as.numeric( as.matrix( partition_df[ ind_row_partition, ind_col_partition ] ) )
          
          #perform proportional sampling and save it
          # print(floor(  as.numeric( n_partition[i] )*as.numeric( n_partition[j] ) * as.numeric( length( vec_within  ))/as.numeric( num_off_diag )  ))
          # print( floor(  ( n_partition[i] )*( n_partition[j] ) * ( length( vec_within  ))/( num_off_diag )  )) 
          prop_num<- floor(  as.numeric( n_partition[i] )*as.numeric( n_partition[j] ) * as.numeric( length( vec_within  ))/as.numeric( num_off_diag )  )
          
          
          if( prop_num == 0 ){
            print( 'prop_num = 0 -> changed to 1' )
            prop_num <- 1 }
          sample_ind <- sample( c( 1:length( diagonal_sampling ) ), prop_num, replace = FALSE )
          k <- k + 1
          prop_sampl_df$sampling_num[k] <- prop_num
          prop_sampl_df$partitions[k] <- paste0( levels( partition )[i], ',', levels( partition )[j] )
          prop_sampl_df$sampling_ind[k] <- paste0( sample_ind, collapse = ',' )
          prop_sampl_df$sampled_from[k] <- paste0( round( diagonal_sampling, 3) , collapse = ',' )
          delta_prop <- mean( diagonal_sampling[ sample_ind ],  na.rm = TRUE )
          if( floor(  as.numeric( n_partition[i] )*as.numeric( n_partition[j] ) * as.numeric( length( vec_within  ))/as.numeric( num_off_diag )  ) != 0 ){ diagonal_sampling <- diagonal_sampling[ -sample_ind ] }
          prop_sampl_df$prop_mean[k] <- delta_prop
          
          delta_jj_prime <- mean( cur_partition,  na.rm = TRUE )
          prop_sampl_df$part_mean[k] <- delta_jj_prime
          
          SNM_b <- SNM_b + ( ( delta_jj_prime - delta_prop )/( sqrt( ( 1/( n_partition[i]*n_partition[j] ) + 1/prop_num ) ) ) )^2
          
        }
      }
    }
    
    #calculate statistics
    prop_sampl_df_list[[ii]] <- prop_sampl_df 
    SNM_b_array[ii] <- SNM_b
    F_stat_array[ii] <- ( SNM_b/length( levels( partition ) ) ) / SNM_w
    
  }
  
  
 
  F_stat <- mean( F_stat_array, na.rm = TRUE )
  
  df1 <- length( levels( partition ) )^2 - length( levels( partition ) )
  df2 <-  length( levels( partition ) ) - 1
  p_value <- pf( F_stat, df1, df2, lower.tail = F ) 
  partition_df1 <- partition_df
  
  res <- list()
  
  res[[1]] <- data.frame( N_partitions = length( levels( partition ) ), partition = paste(  levels( partition ) , collapse = ','), n_partition = paste( n_partition , collapse= ','  ), delta_w = delta_w,  delta_jj = paste( delta_jj, collapse= ',' ),  SNM_w = SNM_w,  SNM_b = mean( SNM_b_array, na.rm = TRUE ), F_stat =  F_stat, p_value = p_value  )
  
  res[[2]] <- do.call( rbind.data.frame, prop_sampl_df_list )
 
  names( res ) <- c( 'summary', 'proportional_sampling' ) 
  
  res
  
}

```


functions needed to perform simulations with different distributions and group sizes
```{r}

#generate datasets based on selection
generate_diss <- function( distribution, group_N, df_dist_par, show_plots ){
  
  if ( distribution == 'uniform' ) {
      
      dist_function <- function( N, par1, par2 ){
        r <- runif( N, par1, par2 )
        r
      } 
    }
    
  if ( distribution == 'normal' ) {
      
      dist_function <- function( N, mean, sd ){
        r <- rnorm( N, mean, sd )
        r
      } 
    }
  
  if ( distribution == 'gamma' ) {
      
      dist_function <- function( N, shape, rate ){
        r <- rnorm( N, shape, rate )
        r
      } 
    }
    
  if ( distribution == 'chisq' ) {
      
      dist_function <- function( N, df, ignored ){
        r <- rchisq( N, df )
        r
      } 
    }
  
    block_list <- list()
    block_list_row <- list()
    k <- 0
    l <- 0
    for ( i in 1:length( group_N ) ){
      l <- l + 1
      for ( j in 1:length( group_N ) ){
        k <- k + 1
        ind <- which( df_dist_par$groups == paste0( 'group', i, ',', 'group', j ) )
        par <- as.numeric( unlist( strsplit( df_dist_par$dist_par[ind], split=',', fixed=TRUE ) ) )
        block_list[[k]] <- matrix( dist_function( group_N[i]*group_N[j], par[1], par[2] ), ncol = group_N[j] )
        
        
      }
      
      r <- block_list[[1]]
      
      for( m in 2:length( group_N ) ){
         r <- cbind( r, block_list[[m]])
        
      }
      
     block_list_row[[l]] <- r
     k <- 0
      
    }
    
    r <- block_list_row[[1]]
    for( m in 2:length( group_N ) ){
         r <- rbind( r, block_list_row[[m]])
        
    }
    
    if( show_plots == TRUE) { 
      pheatmap(r, cluster_rows = F, cluster_cols = F )
      #pheatmap(r )
      }
    
    r
    
}
nmANOVA_sim <- function( distribution, group_N, par_vec, H1_group = NULL, show_plots = FALSE, N_sampling = 10  ){
  
  
        
      par1 <- par_vec[1]
      par2 <- par_vec[2]
      
      df_dist_par <- data.frame( groups = character( length( group_N )^2 ), 
                                 dist_par = character( length( group_N )^2 ), 
                                 stringsAsFactors=FALSE )
      k <- 0
      for ( i in 1:length( group_N ) ){
      for ( j in 1:length( group_N ) ){
          
          k <- k + 1 
          df_dist_par$groups[k] <- paste0( 'group', i, ',', 'group', j )
          
      if( ( !is.null( H1_group ) ) & ( length( which( H1_group$groups ==  df_dist_par$groups[k] ) ) != 0 )  ){
        
        par1_new <- H1_group$dist_par1[ which( H1_group$groups ==  df_dist_par$groups[k] )]
        par2_new <- H1_group$dist_par2[ which( H1_group$groups ==  df_dist_par$groups[k] )]
        df_dist_par$dist_par[k] <- paste0( par1_new,',', par2_new )
        
      } else{
         df_dist_par$dist_par[k] <- paste0( par1,',', par2 )
      }  
          
         
          
        }
        
      }
      
      
      #generate datasets based on selection
      diss_data <- generate_diss( distribution, group_N, df_dist_par, show_plots )
     
      partition <- vector()
      for( i in 1:length( group_N ) ){
        partition <- c( partition, rep( paste0( 'group', i ), group_N[i] ) )
        
      }
    # N_sampling <- 10
      res <-list( nmANOVA( diss_data, partition, N_sampling ), diss_data )
      #res <-list( nmANOVA1( diss_data, partition, N_sampling ), diss_data ) - was used previously
                  
      res
      
      
}


```

function that makes N iterations of N_part partitions and gives back the nmAnova p-values
```{r}

random_part <- function( diss_data, N_part=2, N_sampling = 1, iter = 1000 ){
  
  g <- split( 1:nrow( diss_data ),  sample( N_part, nrow( diss_data ) , repl = TRUE ) )
  
  partition <- c( rep( 'partition1', nrow( diss_data ) ) )
  
  for( i in 1:length( g ) ){
   partition[ g[[i]] ]  <- paste( 'partition', i, sep ='' )
    
    
  } 
  
  
} 

```


P-VALUE ABC FIGURE
Figure 1
5 files you need for code execution: 1_prop_1000_p_valuesh0.RData, unfix_seed_1000_prop_1000_delta_p_values.RData, fix_seed_1000_prop_1000_delta_p_values.RData, 
sd_unfix_seed_1000_prop_1000_delta_p_values.RData, sd_fix_seed_1000_prop_1000_delta_p_values.RData
you can modify the manuscript Figure 1 using Inkscape, file ABC2.svg
```{r}

# A: part with ks.test results
#########################

load("/Users/amalyuti/Desktop/nmANOVA/1_prop_1000_p_valuesh0.RData")
 
df <- data.frame( x = p_value_h0 )
ks.test( p_value_h0, "punif", 0, 1 )

ggplot(df, aes(x=x))+
  geom_histogram(color="black", fill="lightblue", alpha = 0.6, bins = 50) + theme_bw()  + xlab( 'p-value' ) + ylab( "Count" ) + theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )  + theme(legend.position = "none") +  annotate("text", x=0.52, y=31, label= expression( paste( italic( "Kolmogorov-Smirnov test p-value = 0.5074" )  ) ), size = 7) 



# B: part with mean change only
#########################
load("/Users/amalyuti/Desktop/nmANOVA/unfix_seed_1000_prop_1000_delta_p_values.RData")
p_value_unfix <- p_value

load("/Users/amalyuti/Desktop/nmANOVA/fix_seed_1000_prop_1000_delta_p_values.RData")
delta <- seq( 0, 10, length.out = 1000 )

df <- data.frame( delta = rep( delta, 3 ), num = c( seq(1,1000, length.out = 1000), seq( 1100,2100, length.out = 1000),seq( 2200,3200, length.out = 1000) ) ,  group_num = c( rep( 1, 1000 ), rep( 2, 1000 ), rep( 3, 1000 ) ),  x = p_value )

df2 <- data.frame( delta = rep( delta, 3 ), num = c( seq(1,1000, length.out = 1000), seq( 1100,2100, length.out = 1000),seq( 2200,3200, length.out = 1000) ) ,  group_num = c( rep( 1, 1000 ), rep( 2, 1000 ), rep( 3, 1000 ) ),  x = p_value_unfix )

s <- 
  df %>%
  group_by( group_num ) %>%
  dplyr::summarise( mean = mean(x), median = median( x))
#f <- glm( x ~ num, data = df[1:1000,])
#summary(f)
#plot(f)


ggplot( df, aes( x =  num, y = ( log(x) ) ) ) +  
  
   geom_point( data = df2, aes( x =  num, y = ( log(x) ) ),  alpha = 0.05, size = 4, col = 'red')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 
   geom_line( alpha = 0.7,  size = 2, col = 'blue')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
#geom_point( alpha = 0.5, size = 3, col = 'red')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
   
  geom_segment( aes(x = 1, xend=200,  y = log( s$mean[1])), yend=log( s$mean[1]), size = 1) +
  geom_segment( aes(x = 1100, xend=1300,  y = log( s$mean[2])), yend=log( s$mean[2]), size = 1) +
  geom_segment( aes(x = 2200, xend=2400,  y = log( s$mean[3])), yend=log( s$mean[3]), size = 1) +
  
   geom_segment( aes(x = 400, xend=600,  y = log( s$median[1])), yend=log( s$median[1]), size = 1) +
  geom_segment( aes(x = 1500, xend=1700,  y = log( s$median[2])), yend=log( s$median[2]), size = 1) +
  geom_segment( aes(x = 2600, xend=2800,  y = log( s$median[3])), yend=log( s$median[3]), size = 1) +
  
scale_x_continuous(breaks=c(1, 1000, 1100, 2100, 2200,3200) ,
        labels=c("1",'10',  "1", "10", '1', '10')) +
  
  
  #geom_line( data = df2, aes( x =  num, y = ( log(x) ) ), alpha = 0.2,  size = 2, col = 'blue')  + #xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) + 
 
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ xlab( expression(delta) ) + ylab( "log(p-value)" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )  + theme(legend.position = "none")





# C: part with sd change only
#########################
load("/Users/amalyuti/Desktop/nmANOVA/sd_unfix_seed_1000_prop_1000_delta_p_values.RData")
p_value_unfix <- p_value

load("/Users/amalyuti/Desktop/nmANOVA/sd_fix_seed_1000_prop_1000_delta_p_values.RData")

df <- data.frame( delta = rep( delta, 3 ), num = c( seq(1,1000, length.out = 1000), seq( 1100,2100, length.out = 1000),seq( 2200,3200, length.out = 1000) ) ,  group_num = c( rep( 1, 1000 ), rep( 2, 1000 ), rep( 3, 1000 ) ),  x = p_value )

df2 <- data.frame( delta = rep( delta, 3 ), num = c( seq(1,1000, length.out = 1000), seq( 1100,2100, length.out = 1000),seq( 2200,3200, length.out = 1000) ) ,  group_num = c( rep( 1, 1000 ), rep( 2, 1000 ), rep( 3, 1000 ) ),  x = p_value_unfix )

s <- 
  df %>%
  group_by( group_num ) %>%
  dplyr::summarise( mean = mean(x), median = median( x))
#f <- glm( x ~ num, data = df[1:1000,])
#summary(f)
#plot(f)


ggplot( df, aes( x =  num, y = ( log(x) ) ) ) +  
  
   geom_point( data = df2, aes( x =  num, y = log( (x) ) ),  alpha = 0.05, size = 4, col = 'red')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 
   geom_line( alpha = 0.7,  size = 2, col = 'blue')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
#geom_point( alpha = 0.5, size = 3, col = 'red')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
   
  geom_segment( aes(x = 200, xend=400,  y = log( s$mean[1])), yend=log( s$mean[1]), size = 1) +
  geom_segment( aes(x = 1300, xend=1500,  y = log( s$mean[2])), yend=log( s$mean[2]), size = 1) +
  geom_segment( aes(x = 2400, xend=2600,  y = log( s$mean[3])), yend=log( s$mean[3]), size = 1) +
  
   geom_segment( aes(x = 400, xend=600,  y = log( s$median[1])), yend=log( s$median[1]), size = 1) +
  geom_segment( aes(x = 1500, xend=1700,  y = log( s$median[2])), yend=log( s$median[2]), size = 1) +
  geom_segment( aes(x = 2600, xend=2800,  y = log( s$median[3])), yend=log( s$median[3]), size = 1) +
  
scale_x_continuous(breaks=c(1, 1000, 1100, 2100, 2200,3200) ,
        labels=c("1",'10',  "1", "10", '1', '10')) +
 # scale_y_continuous(breaks=c(1,0.8, 0.6, 0.4, 0.2,0.1) ) +
  
  
  #geom_line( data = df2, aes( x =  num, y = ( log(x) ) ), alpha = 0.2,  size = 2, col = 'blue')  + #xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) + 
 
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ xlab( expression(delta) ) + ylab( "log( p-value )" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )  + theme(legend.position = "none")




```


ASYMPTOTIC P-VALUES   
Figure 2 
p-values were collected at csc and saved in mil_df2.RData 
you can modify the manuscript Figure 2 using Inkscape, file p_val.svg
```{r}
library( ggplot2 )

#2 mil p-value dataframe
load("/Users/amalyuti/Desktop/nmANOVA/mil_df2.RData")

# inittial matrix for the figure
#load("/Users/amalyuti/Desktop/nmANOVA/mil_diss_mat_prop_sampl_df2.RData")
m <- mean( ( df$p_value ) )
df2 <- df[c(50:2000000),]
#df2 <- df

scientific_10 <- function(x) {
  parse(text=gsub("e", " %*% 10^", scales::scientific_format()(x)))
}


ggplot(df2, aes(x=log10( prop_sampl_num ), y=( -log10( p_value ) )))+ 
  geom_line()+# ylim( 5.931020e-05, 5.9345e-05) + #xlim(-50 ,320 )+
  #geom_point(col = 'red', size = 0.1)+
  scale_x_continuous(breaks=c( log10( 50 ), log10( 10000),  log10( 100000), log10( 500000 ),    log10( 2000000 ) ),
        labels= scientific_10( c( 50, 10000, 100000,  500000, 2000000 ) ) ) +
  #scale_y_continuous(label=scientific_10) +
  geom_hline( yintercept = -log10( mean( ( df$p_value ) ) ), col = 'red' ) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1) ) +
              xlab( "Number of proportional samplings performed" ) + ylab( "-log10(p-value)" ) + 
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=20), legend.text=element_text(size=20) ) 





```


BLAST
Figure 3 
2 files you need for code execution: filt_species.xlsx, allvall.txt. allvall.txt was given by Ali, colnames are missing
1 file with final selected blasts for plot (our blast table in the manuscript have those): blast_data.xlsx
you can modify the manuscript Figure 3 using Inkscape, file blast_p.svg
```{r}


filt_sp <- read.xlsx( "~/Desktop/nmANOVA/filt_species.xlsx" )
t<- read.table("~/Desktop/nmANOVA/blast matrix/allvall.txt", header=FALSE)

M <- 
  filt_sp%>%filter( Clade == 'Monocot' )
D <- 
  filt_sp%>%filter( Clade == 'Eudicot' )
  
ind_monocot <- which( unique(t$V1) %in% M$Species)
ind_eudicot <- which( unique(t$V1) %in% D$Species)
combined<- c(ind_monocot, ind_eudicot)
all_mono <- unique(t$V1)[ind_monocot]
all_eudi <- unique(t$V1)[ind_eudicot]

partition <- c( rep( 'Monocot', length( ind_monocot ) ),rep( 'Eudicot', length( ind_eudicot ) ) )


B <- matrix(0,length( combined ), length( combined ))
E <- matrix(0,length( combined ),length( combined ))

for (i in 1:length( combined )){
  
  tt<-subset(t, t$V1==(unique(t$V1)[combined])[i])#filtering is based on the first column
  
  for (j in 1:length( combined ) ) {
    
    B[i,j]<- subset(tt, tt$V2==(unique(t$V1)[combined])[j])[1,12]#the first row (highest E-value and Bitscore) and its bit score
    
    E[i,j]<- subset(tt, tt$V2==(unique(t$V1)[combined])[j])[1,11]
  }
}

#DeltaB<- 1/( -log( E ) )^2


DeltaB <- ( 1/B) # not symmetric - I checked but most of the values are symmetric
colnames( DeltaB ) <- c( paste( "Monocot", seq( 1:length( ind_monocot ) ), sep = '_' ), paste( "Eudicot", seq( 1:length( ind_eudicot ) ), sep = '_' ) )
rownames( DeltaB ) <- colnames( DeltaB )

DD <- DeltaB
res2 <- nmANOVA(DeltaB, partition, N_sampling = 10 )
M <- as.vector( DeltaB[1:length( ind_monocot), 1:length( ind_monocot)] ) 
E <-  as.vector( DeltaB[( length( ind_monocot) +1 ):nrow( DeltaB ), ( length( ind_monocot) +1 ):nrow( DeltaB ) ] )

all_mono <- unique(t$V1)[ind_monocot]
all_eudi <- unique(t$V1)[ind_eudicot]

#lets make it more significant via removing outliers and creating more distinct clusters 
excl_mono <- paste( 'Monocot', c( 7, 23, 21, 17, 8, 9  ), sep = '_' )
ind_excl_mono <-  which( colnames( DeltaB ) %in% excl_mono  )
all_mono2 <- all_mono[-c( 7, 23, 21, 17, 8, 9  )]
d <-DeltaB[-ind_excl_mono, -ind_excl_mono]
partition <- sub('_[^_]*$', '', colnames( d  ) ) 


exc_dico <- paste(  "Eudicot", c(   11, 39, 47, 59, 56, 24 ,58, 21, 28, 23, 70 , 57, 63, 71, 37, 15, 68, 69, 36 ), sep = '_' ) 
ind_excl_dico <-  which( colnames( d ) %in% exc_dico  )
all_eudi2 <- all_eudi[-c(   11, 39, 47, 59, 56, 24 ,58, 21, 28, 23, 70 , 57, 63, 71, 37, 15, 68, 69, 36 )]
d<- d[ -ind_excl_dico, -ind_excl_dico]
 partition <- sub('_[^_]*$', '', colnames( d  ) ) 
res <- nmANOVA( d , partition, N_sampling = 10 ) 
res$summary$p_value#p_value = 0.044



m2 <- matrix(NA, ncol = ncol(d), nrow = nrow(d))
m2[upper.tri(m2)] <- rowMeans(cbind(d[upper.tri(d, diag = FALSE)], 
                                d[lower.tri(d, diag = FALSE)]))
m2[lower.tri(m2)] <- rowMeans(cbind(d[upper.tri(d, diag = FALSE)], 
                                d[lower.tri(d, diag = FALSE)]))
diag(m2 ) <- diag( d)
colnames( m2 )<- colnames(d)
rownames( m2 )<- rownames(d)


mds.coor=cmdscale( as.dist( ( m2 ) ) )
mds.coor <- as.data.frame( mds.coor)
colnames( mds.coor ) <- c( 'coor1', 'coor2' )
mds.coor <- 
  mds.coor %>%
  mutate( Species =  sub('_[^_]*$', '', rownames( mds.coor ) ) )


#### plot for the paper 
 ggplot( mds.coor, aes( x =  ( coor1 ), y = ( coor2 ), shape = as.factor( Species ), col = as.factor( Species ) ) ) +  
   geom_point( alpha = 0.7,  size = 10)  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +

            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +
             theme_bw()+ xlab( "MDS coordinate 1 " ) + ylab("MDS coordinate 2" ) +
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=28), axis.text.y = element_text(angle = 0, hjust = 1, size =25), legend.title=element_text(size=28), legend.text=element_text(size=28) ) + annotate("text", x=0.0010, y=0.0033, label= expression( paste( italic( "p-value = 0.044" )  ) ), size = 10) +  #+ geom_text( aes( label = rownames( mds.coor ) ), size = 4, hjust=0, vjust = 1 ) #+ theme(legend.position = "none")
  guides( col=guide_legend(title="Species"), shape = guide_legend(title='Species'))
 
expression( paste(italic( 'drm()' ), " elapsed time (", italic(s), ')') )



#check of the dataset 
sel_species <- c( all_mono2, all_eudi2 )

t2 <- 
  t %>%
  filter( V1 %in% sel_species )%>%
  filter( V2 %in% sel_species )

  
M <- 
  filt_sp%>%filter( Clade == 'Monocot' )
D <- 
  filt_sp%>%filter( Clade == 'Eudicot' )

ind_monocot <- which( unique(t2$V1) %in% M$Species)
ind_eudicot <- which( unique(t2$V1) %in% D$Species)

combined<- c(ind_monocot, ind_eudicot)
all_mono <- unique(t2$V1)[ind_monocot]
all_eudi <- unique(t2$V1)[ind_eudicot]

partition <- c( rep( 'Monocot', length( ind_monocot ) ),rep( 'Eudicot', length( ind_eudicot ) ) )


B <- matrix(0,length( combined ), length( combined ))
E <- matrix(0,length( combined ),length( combined ))

for (i in 1:length( combined )){
  
  tt<-subset(t2, t2$V1==(unique(t2$V1)[combined])[i])#filtering is based on the first column
  
  for (j in 1:length( combined ) ) {
    
    B[i,j]<- subset(tt, tt$V2==(unique(t2$V1)[combined])[j])[1,12]#the first row (highest E-value and Bitscore) and its bit score
    
    E[i,j]<- subset(tt, tt$V2==(unique(t2$V1)[combined])[j])[1,11]
  }
}

#DeltaB<- 1/( -log( E ) )^2


DeltaB <- ( 1/B) # not symmetric - I checked but most of the values are symmetric
colnames( DeltaB ) <- c( paste( "Monocot", seq( 1:length( ind_monocot ) ), sep = '_' ), paste( "Eudicot", seq( 1:length( ind_eudicot ) ), sep = '_' ) )
rownames( DeltaB ) <- colnames( DeltaB )
  res_check <- nmANOVA(DeltaB, partition, N_sampling = 10 ) # exactly same - so save t2
  res_check$summary$p_value#p_value = 0.044
#write.xlsx(t2, file = 'blast_data.xlsx')
```



KL BLADDER DATASET
Table 6, Figure 9 (Supplementary) and Figure 4
you have to load library bladderbatch and bladderKL_JT.RData with precalculated KL values
p-values for table are in nm_df dataframe
you can modify the manuscript Figure 4 using Inkscape, file bladder_PCA.svg
```{r}
library(bladderbatch)
library( ggplot2)
data( bladderdata )

pheno <- pData(bladderEset)
#samples_cancer <- rownames( pheno[ which( pheno$cancer == 'Cancer'), ] )

edata <- exprs(bladderEset)

#now load Kullback Leibler divergence matrix
load("bladderKL_JT.RData")
bl <- bladderKL
colnames( bl )[18:29] <- paste( 'mTCC', seq(1:12), sep = '_' )
colnames( bl )[30:41] <- paste( 'sTCC+CIS', seq(1:12), sep = '_' )
colnames( bl )[42:57] <- paste( 'sTCC-CIS', seq(1:16), sep = '_' )

#colnames( bl ) <- sub('_[^_]*$', '', colnames( bl ))
#rownames( bl ) <- colnames( bl )

#for heatmap
pheatmap( log( bl + 0.01), labels_row = sub('_[^_]*$', '', colnames( bl )), labels_col =  sub('_[^_]*$', '', colnames( bl )), fontsize_row = 12, fontsize_col = 13 )

#classical multidimensional scaling based on KL
d <- as.dist(bladderKL)
mds.coor <- cmdscale(d)
plot(mds.coor[,1], mds.coor[,2], type="n", xlab="", ylab="")
text(jitter(mds.coor[,1]), jitter(mds.coor[,2]),
     rownames(mds.coor), cex=1.2)
abline(h=0,v=0,col="gray75")
df.dist=as.matrix(d, labels=TRUE)





#for PCA
prc <- prcomp( t( edata ), center = T, scale = T )
prc_res <- as.data.frame( prc$x )
prc_res <- merge( prc_res, pheno, by = 'row.names' )

#PCA plot
ggplot( prc_res , aes( x =  PC1, y = PC2, col = as.factor( outcome ) ) ) + geom_point( size = 10, alpha = 0.7 ) +
              theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
             theme_bw()+ xlab( "PC1" ) + ylab( "PC2" ) + guides(col=guide_legend(title="Sample"), shape = guide_legend(title='concentrations'))+ theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )+ annotate("text", x=-15, y=95, label= expression( paste( italic( "p-value = 0.041" )  ) ), size = 10) 


#collect results for all the partitions ijn nm_df
#change the column/row names
better_names <- c( paste0( 'Normal', '_', c( 1:8 ) ), paste0( 'Biopsy', '_', c( 1:9 ) ), paste0( 'mTCC', '_', c( 1:12 ) ), paste0( 'sTCC+CIS', '_', c( 1:12 ) ),  paste0( 'sTCC-CIS', '_', c( 1:16 ) ) ) 
colnames( bladderKL ) <- better_names
rownames( bladderKL ) <- better_names
diss_df <- bladderKL
#select partitions to be used in the paper table
partition <- list()
partition[[1]] <-c( "Normal"   ,         "Biopsy" )
partition[[2]] <-c( "Normal"   ,         "mTCC" )
partition[[3]] <-c( "Normal"   ,         "sTCC+CIS" )
partition[[4]] <-c( "Normal"   ,         "sTCC-CIS" )
partition[[5]] <-c( "Biopsy"   ,         "mTCC" )
partition[[6]] <-c( "Biopsy"   ,         "sTCC+CIS" )
partition[[7]] <-c( "Biopsy"   ,         "sTCC-CIS" )
partition[[8]] <-c( "mTCC"   ,         "sTCC+CIS" )
partition[[9]] <-c( "mTCC"   ,         "sTCC-CIS" )
partition[[10]] <-c( "sTCC+CIS"   ,         "sTCC-CIS" )

partition[[11]] <- c( "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS" )

partition[[12]] <- c( "Normal"   , "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS"   )
partition[[13]] <- c( "Biopsy"   , "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS"   )
partition[[14]] <- c( "Normal"   ,      "mTCC+sTCC+CIS+sTCC-CIS" ) 
partition[[15]] <- c( "Biopsy"   ,       "mTCC+sTCC+CIS+sTCC-CIS" )

partition[[16]] <- c( "Normal"   ,         "Biopsy" ,   "sTCC+CIS" )
partition[[17]] <- c( "Normal+Biopsy"   , "sTCC+CIS" )

partition[[18]] <- c( "Normal",         "Biopsy" ,   "sTCC-CIS" )
partition[[19]] <- c( "Normal+Biopsy", "sTCC-CIS" )

partition[[20]] <- c( "Normal",         "Biopsy" ,   "mTCC" )
partition[[21]] <- c( "Normal+Biopsy", "mTCC" )


partition[[22]] <- c( "Normal+Biopsy"  , "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS" )
partition[[23]] <- c( "Normal+Biopsy"  ,"mTCC+sTCC+CIS+sTCC-CIS" )

partition[[24]] <- c( "Biopsy"   ,"Normal", "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS"   )



d <- as.matrix( diss_df )


joints <- c( "Normal+Biopsy", "mTCC+sTCC+CIS+sTCC-CIS" )
ind_Norm_Biopsy <-  which( sub('_[^_]*$', '', colnames( d ) ) %in% c( 'Normal', 'Biopsy' ) )
ind_Cancers <-  which( sub('_[^_]*$', '', colnames( d ) ) %in% c( "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS" ) )


#nmANOVA 
res_m <- list()
res_dist <- list()
pca_plot <- list()
ggplot_list <- list()


for( i in 1:length( partition ) ){
  
  if( length( intersect( partition[[i]], joints ) ) > 0 ){
    
    sel_partition <- c( rep('Normal', 8), rep('Biopsy', 9), rep("mTCC" , 12 ), rep("sTCC+CIS" , 12 ), rep("sTCC-CIS" , 16 ) )
    l <- unique( partition[[i]] )
    sub1 <- vector()
    sub2 <- vector()
    if( "Normal+Biopsy" %in% l )  { 
      sel_partition[ ind_Norm_Biopsy ] <- 'Normal+Biopsy' 
      sub1 <- union( l, c( 'Normal', 'Biopsy') )
    }
    if( "mTCC+sTCC+CIS+sTCC-CIS" %in% l )  { 
      sel_partition[ ind_Cancers ] <- "mTCC+sTCC+CIS+sTCC-CIS" 
      sub2 <- union( l, c( 'mTCC', 'sTCC+CIS', 'sTCC-CIS') )
      }
    
    sub <- union( sub1 , sub2 )
    subpartition <- partition[[i]]
    res_m[[i]] <- nmANOVA(d, sel_partition,  10,  subpartition )
    res_m[[i]] <- res_m[[i]]$summary
    
    
   
    ind <- which( sub('_[^_]*$', '', colnames( d  ) ) %in%  sub )
     dd <- as.dist( d[ind, ind] )
      mds.coor <- cmdscale(dd)
      
      mds.coor <- as.data.frame( mds.coor)
      colnames( mds.coor ) <- c( 'coor1', 'coor2' )
      mds.coor <- 
        mds.coor %>%
        mutate( Sample =  sub('_[^_]*$', '', rownames( mds.coor ) ) )
      
      
      if( "Normal+Biopsy" %in% l ) { 
        ind <- which(mds.coor$Sample %in% c( 'Normal', 'Biopsy' ) )
        mds.coor$Sample[ind] <-  "Normal+Biopsy"
        
      }
      
      if( "mTCC+sTCC+CIS+sTCC-CIS" %in% l )  { 
      
       ind <- which(mds.coor$Sample %in%  c( 'mTCC', 'sTCC+CIS', 'sTCC-CIS') )
        mds.coor$Sample[ind] <-"mTCC+sTCC+CIS+sTCC-CIS" 
       
        
       
      }
      
      
       ggplot_list[[i]] <- ggplot( mds.coor, aes( x =  ( coor1 ), y = ( coor2 ), col = as.factor( Sample )  ) )  + xlim( -0.3, 0.3) +ylim( -0.05, 0.05 ) + 
         geom_point( alpha = 0.7,  size = 7)  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
      
                  theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
                    panel.grid.major = element_line(colour = "grey", size = 0.5)) + ggtitle( paste('p-value = ', round( res_m[[i]]$p_value, 4 ) )) +
                   theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +
                   theme_bw()+ xlab( "mds.coor1" ) + ylab( "mds.coor2" ) +
                      theme(plot.title = element_text(size = 15),axis.text.x = element_text(angle = 0, hjust = 1, size = 10), axis.title=element_text(size=10), axis.text.y = element_text(angle = 0, hjust = 1, size =10), legend.title=element_text(size=10), legend.text=element_text(size= 10) ) #+ geom_text( aes( label = rownames( mds.coor ) ), size = 4, hjust=0, vjust = 1 ) #+ theme(legend.position = "none")
      
          
          pheno2 <- 
            pheno %>%
            filter( outcome %in%  sub )
          ind <- which( colnames( edata ) %in% rownames( pheno2 ) )
          edata2 <- edata[, ind]
            
          prc <- prcomp( t( edata2 ), center = T, scale = T )
      
          prc_res <- as.data.frame( prc$x )
          prc_res <- merge( prc_res, pheno2, by = 'row.names' )
          prc_res$outcome <- as.character(prc_res$outcome  )
       if( "Normal+Biopsy" %in% l ) { 
        ind <- which(prc_res$outcome %in% c( 'Normal', 'Biopsy' ) )
        prc_res$outcome[ind] <-  "Normal+Biopsy"
    }
       
      if( "mTCC+sTCC+CIS+sTCC-CIS" %in% l )  { 
      
       ind <- which(prc_res$outcome %in%  c( 'mTCC', 'sTCC+CIS', 'sTCC-CIS') )
        prc_res$outcome[ind] <- "mTCC+sTCC+CIS+sTCC-CIS" 
      
       
      }
      
      
          
          
          #PCA plot
          pca_plot[[i]] <- ggplot( prc_res , aes( x =  PC1, y = PC2, col = as.factor( outcome ) ) ) + geom_point( size = 7, alpha = 0.7 ) +
                        theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
                        panel.grid.major = element_line(colour = "grey", size = 0.5)) +ggtitle( paste('p-value = ', round( res_m[[i]]$p_value, 4 ) ) )+
                       theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
                       theme_bw()+ xlab( "PC1" ) + ylab( "PC2" ) + guides(col=guide_legend(title="dataset"), shape = guide_legend(title='concentrations'))+ theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )

    
    
    
    
  } 
  else{
    
    sel_partition <- c( rep('Normal', 8), rep('Biopsy', 9), rep("mTCC" , 12 ), rep("sTCC+CIS" , 12 ), rep("sTCC-CIS" , 16 ) )
    subpartition <- partition[[i]]
    res_m[[i]] <- nmANOVA(d, sel_partition, 10, subpartition )
   res_m[[i]] <- res_m[[i]]$summary
  
    ind <- which( sub('_[^_]*$', '', colnames( d  ) ) %in%  subpartition )
     dd <- as.dist( d[ind, ind] )
      mds.coor <- cmdscale(dd)
      
      mds.coor <- as.data.frame( mds.coor)
      colnames( mds.coor ) <- c( 'coor1', 'coor2' )
      mds.coor <- 
        mds.coor %>%
        mutate( Sample =  sub('_[^_]*$', '', rownames( mds.coor ) ) )
      
       ggplot_list[[i]] <- ggplot( mds.coor, aes( x =  ( coor1 ), y = ( coor2 ), col = Sample  ) )  + xlim( -0.3, 0.3) +ylim( -0.05, 0.05 ) + 
         geom_point( alpha = 0.7,  size = 7)  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
      
                  theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
                    panel.grid.major = element_line(colour = "grey", size = 0.5)) +ggtitle( paste('p-value = ', round( res_m[[i]]$p_value, 4 )  ))+
                   theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +
                   theme_bw()+ xlab( "mds.coor1" ) + ylab( "mds.coor2" ) +
                      theme(plot.title = element_text(size = 15),axis.text.x = element_text(angle = 0, hjust = 1, size = 10), axis.title=element_text(size=10), axis.text.y = element_text(angle = 0, hjust = 1, size =10), legend.title=element_text(size=10), legend.text=element_text(size=10) ) #+ geom_text( aes( label = rownames( mds.coor ) ), size = 4, hjust=0, vjust = 1 ) #+ theme(legend.position = "none")
      
          
          pheno2 <- 
            pheno %>%
            filter( outcome %in%  subpartition )
          ind <- which( colnames( edata ) %in% rownames( pheno2 ) )
          edata2 <- edata[, ind]
            
          prc <- prcomp( t( edata2 ), center = T, scale = T )
          sum( colnames( edata2 ) == rownames( pheno2 ) )
          prc_res <- as.data.frame( prc$x )
          prc_res <- merge( prc_res, pheno2, by = 'row.names' )
          
          #PCA plot
          pca_plot[[i]] <- ggplot( prc_res , aes( x =  PC1, y = PC2, col = as.factor( outcome ) ) ) + geom_point( size = 7, alpha = 0.7 ) + ylim( -0.2, 0.2) +xlim( -0.03, 0.03 ) +
                        theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
                        panel.grid.major = element_line(colour = "grey", size = 0.5)) +ggtitle( paste('p-value = ', round( res_m[[i]]$p_value, 4 ) ) )+
                       theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
                       theme_bw()+ xlab( "PC1" ) + ylab( "PC2" ) + guides(col=guide_legend(title="Sample"), shape = guide_legend(title='concentrations'))+ theme(plot.title = element_text(size = 15),axis.text.x = element_text(angle = 0, hjust = 1, size = 15), axis.title=element_text(size=15), axis.text.y = element_text(angle = 0, hjust = 1, size = 15), legend.title=element_text(size=15), legend.text=element_text(size=15) )

    
    
    
  }
  
  
}  

i = 24
plot( pca_plot[[i]] )
plot( ggplot_list[[i]] )


nm_df <- 
  plyr::ldply( lapply( res_m, as.data.frame ) )

```


BEST CLUSTERING
Figure 5 (Supplementary)
results were collected at csc and saved in 'clust' folder and par_set.RData
you can modify the manuscript Figure using Inkscape, file ribbon_plot.svg
```{r}

multiplot_list <- function( plotlist, cols) {
    require(grid)

    # Make a list from the ... arguments and plotlist
    plots <-plotlist

    numPlots = length(plots)

    # Make the panel
    plotCols = cols                          # Number of columns of plots
    plotRows = ceiling(numPlots/plotCols) # Number of rows needed, calculated from # of cols

    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(plotRows, plotCols)))
    vplayout <- function(x, y)
        viewport(layout.pos.row = x, layout.pos.col = y)

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
        curRow = ceiling(i/plotCols)
        curCol = (i-1) %% plotCols + 1
        print(plots[[i]], vp = vplayout(curRow, curCol ))
    }

}


library( stringr )
library( dplyr )
library( plyr )
library(ggplot2)

load("/Users/amalyuti/Desktop/nmANOVA/par_set.RData")

#here put the path to the clust folder
setwd( '~/Desktop/nmANOVA/clust' )
file_names <- as.list( dir( pattern="200N*" ) )

par_set  <- 
  par_set %>%
  mutate( num = seq( 1:nrow( par_set ) ) )

par_set$num <- as.character( par_set$num )
par_set  <-  
  par_set %>%
  arrange( num )


res <- list()

for( i in 1:length( file_names ) ) {
  
  load( file_names[[i]] ) 
  res[[i]] <- df
  
  ind <- which( par_set$num == sub("\\.RData.*", "",  sub('.*\\_', '',file_names[[i]] ) ) )
  res[[i]] <- 
    res[[i]] %>% 
    mutate( clust_num = par_set$part_num[ind]  ) 
  
}



df<- ldply( res, as.data.frame )
plot_list <- list()
df_list  <- list()
gg_list  <- list()

for( i in 3:5 ){
  
df2 <- 
  df %>%
  filter( clust_num == i )
  

if( i == 3 )
  partition <- c( rep( 'group_1' ,34 ), rep( 'group_2' ,34 ),  rep( 'group_3' ,55 ) )

if( i == 4 )
  partition <- c( rep( 'group_1' ,13 ), rep( 'group_2' ,21),  rep( 'group_3' ,34 ), rep( 'group_4' ,55 ) )
  #partition <- c( rep( 'group_1' ,21 ), rep( 'group_2' ,34),  rep( 'group_3' ,55 ), rep( 'group_4' ,89 ) )


if( i == 5 )
  partition <- c( rep( 'group_1', 13 ), rep( 'group_2' ,21 ), rep( 'group_3' ,34),  rep( 'group_4' ,21 ), rep( 'group_5' ,34 ) )


  indi <- which( ( df2$N_sampl == 0 ) &  ( df2$num_change == 0 ) )
  
  df2_null <-
    df2 %>%
    filter( N_sampl == 0, num_change == 0   )
  p_value <-  median( df2_null$p_value )

  
  print( length( unique( df2_null$part ) ) )
  
  d <- data.frame( num_change = 0, mean = ( p_value), min = (p_value ), max = (p_value), med = (p_value))

ind <- which(df2$part == paste0( partition, collapse = ',' ) )
df2 <- df2[-ind, ]


df2 <- 
  df2 %>%
  filter( N_sampl != 0, num_change != 0   )%>%
  group_by( num_change, part)%>%
  dplyr::summarise(   p_value = mean( p_value) )


 

d <- data.frame( num_change = 0, mean = ( p_value), min = (p_value ), max = (p_value), med = (p_value))

gg <- 
  df2 %>%
  group_by(num_change )%>%
  dplyr::summarise( mean = mean( p_value), min = min(p_value ), max = max(p_value), med = median(p_value) )

gg <- rbind( d, gg)

df_list[[i-1]]  <-
  df2 %>%
  mutate( clust_num =  i )

gg_list[[i-1]] <- 
  gg %>%
  mutate( clust_num =  i )  


plot_list[[i-1]]  <- ggplot( df2, aes(   x =  ( num_change ), y = (p_value ) ) ) +  
  
#geom_point( alpha = 0.3, size = 3, col = 'blue') + 
   #geom_line(data=gg)+
  # geom_ribbon(data=gg,aes(ymin=-log( min ),ymax=-log( max)),alpha=0.1) +
   geom_boxplot( aes(group = ( num_change )), col = '#3399FF', fill = '#3399FF', alpha = 0.1 )+
  geom_line(data=gg ,aes( ( num_change ), ( med )),col = 'black', size = 1, alpha = 0.7) +
  geom_point(data=gg,aes( ( num_change ), (med)),col = '#FF6666', size =2) +

 #geom_vline(xintercept =log(p_value),  
              # color = "red", size=1) +
  
 scale_x_continuous(breaks=c(0,  10,  30, 50) ,
        labels=c('0',  '10',  '30', '50' ) ) + ylim( 0,1 ) +
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ ylab( 'p-value' ) + xlab( "Number of pairs switched" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=20), axis.text.y = element_text(angle = 0, hjust = 1, size = 20), legend.title=element_text(size=25), legend.text=element_text(size=20) )  + theme(legend.position = "none") +theme(axis.title=element_blank() )# +  annotate("text", x = 3, y = 11.5, label= expression( paste( italic( "p value for original matrix" )  ) ), size = 7
 

}




#another version of plot
df_all <- ldply( df_list, as.data.frame )
gg_all <- ldply( gg_list, as.data.frame )

df_all <- 
  df_all %>%
  mutate( hist_factor = paste( num_change, clust_num, sep = '_' ) )

 ggplot( df_all, aes(   x =  ( num_change ), y = (p_value ), col = as.factor( clust_num ) ) ) +  
  
#geom_point( alpha = 0.3, size = 3, col = 'blue') + 
   #geom_line(data=gg)+
   geom_ribbon(data=gg_all,aes(ymin=( min ),ymax= max, fill =as.factor( clust_num )) ,alpha=0.1, colour = NA ) +
 # geom_boxplot( aes(group = as.factor( hist_factor ),  fill =  as.factor( clust_num ), col = as.factor( clust_num ) ), alpha = 0.01 )+
 # geom_point(aes( group = as.factor( hist_factor ), col = as.factor( clust_num ), group = as.factor( clust_num ) ), size =1, alpha = 0.04) +
  geom_line(data=gg_all ,aes( ( num_change ), ( med ), col = as.factor( clust_num ), group = as.factor( clust_num ) ), size = 1, alpha = 0.7) +
  geom_point(data=gg_all,aes( ( num_change ), (med), col = as.factor( clust_num ), group = as.factor( clust_num ) ), size =1.4) +
  

 #geom_vline(xintercept =log(p_value),  
              # color = "red", size=1) +
  
 scale_x_continuous(breaks=c(0,  10,  30, 60 ) ,
        labels=c('0',  '10',  '30',  '60' ) ) + ylim( 0,1 ) +
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ ylab( 'p-value' ) + xlab( "Number of pairs switched" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=20), axis.text.y = element_text(angle = 0, hjust = 1, size = 20), legend.title=element_text(size=20), legend.text=element_text(size=20) ) # + theme(legend.position = "none") #+theme(axis.title=element_blank() )# +  annotate("text", x = 3, y = 11.5, label= expression( paste( italic( "p value for original matrix" )  ) ), size = 7
 




```


THREE MODELS COMPARISON
Figure 6 (Supplementary)
results were collected at csc and saved in 'new', 'rev_new' and 'reverse_413' folder
you can modify the manuscript Figure 6 using PowerPoint, file radar.pptx
```{r}


#######forward
setwd( '~/Desktop/nmANOVA/413/new/')
file_names <- as.list( dir( pattern="res_413*" ) )

res <- list()

for( i in 1:length( file_names ) ) {
  
  load( file_names[[i]] ) 
  res[[i]] <- res_df
  
  
}


df<- ldply( res, as.data.frame )


df <- 
  df %>%
  dplyr::select( -m1, -m2, -m3, -m4 )%>%
  group_by( dist_method, vector_num, delta )%>%
  summarise_each( funs = mean) %>%
  ungroup()

cor( df$np_pval, df$nm_pval )
cor( df$cl_pval, df$nm_pval )
cor( df$np_pval, df$cl_pval )


df_thr <- 
  df %>%
  mutate( nm_stat_0.05 = ifelse( nm_pval <= 0.05, 'yes', 'no' ), nm_stat_0.1 = ifelse( nm_pval <= 0.1, 'yes', 'no' ),
          np_stat_0.05 = ifelse( np_pval <= 0.05, 'yes', 'no' ), np_stat_0.1 = ifelse( np_pval <= 0.1, 'yes', 'no' ),
          cl_stat_0.05 = ifelse( cl_pval <= 0.05, 'yes', 'no' ), cl_stat_0.1 = ifelse( cl_pval <= 0.1, 'yes', 'no' ) )%>%
  mutate( group = paste( dist_method, vector_num, sep = '_' ) )
  
all_groups <- unique( df_thr$group )

df_5 <- as.data.frame( matrix(0, ncol = length( all_groups ), nrow = 5 ) )
colnames( df_5 ) <- all_groups
rownames( df_5 ) <- c( 'max', 'min', 'cl', 'np', 'nm' )
df_5[1, ] <- 0
df_5[2, ] <- -2

df_1 <- df_5

for( j in 1:length( all_groups ) ){
  
  cur_df <- 
    df_thr %>%
    filter( group == all_groups[j] ) %>%
    arrange( delta )
  
  
 df_5[3,j] <- -cur_df$delta[ which( cur_df$cl_stat_0.05 == 'yes')[1] ]
 print( 'cl' ) 
 print( length( which( cur_df$cl_stat_0.05[ ( which( cur_df$cl_stat_0.05 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 

 df_5[4,j] <- -cur_df$delta[ which( cur_df$np_stat_0.05 == 'yes')[1] ]
 print( 'np' ) 
 print( length( which( cur_df$np_stat_0.05[ ( which( cur_df$np_stat_0.05 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 
  if(  length( which( cur_df$nm_stat_0.05 == 'yes') ) >0 ){
 df_5[5,j] <- -cur_df$delta[ which( cur_df$nm_stat_0.05 == 'yes')[1] ]
 print( 'nm' ) 
 print( length( which( cur_df$nm_stat_0.05[ ( which( cur_df$nm_stat_0.05 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
  }
 
  
 df_1[3,j] <- -cur_df$delta[ which( cur_df$cl_stat_0.1 == 'yes')[1] ]
 print( 'cl' ) 
 print( length( which( cur_df$cl_stat_0.1[ ( which( cur_df$cl_stat_0.1 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 


  df_1[4,j] <- -cur_df$delta[ which( cur_df$np_stat_0.1 == 'yes')[1] ]
 print( 'np' ) 
 print( length( which( cur_df$np_stat_0.1[ ( which( cur_df$np_stat_0.1 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
   
 

  if(  length( which( cur_df$nm_stat_0.1 == 'yes') ) >0 ){
 df_1[5,j] <- -cur_df$delta[ which( cur_df$nm_stat_0.1 == 'yes')[1] ]
 print( 'nm' ) 
 print( length( which( cur_df$nm_stat_0.1[ ( which( cur_df$nm_stat_0.1 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
  }
 
  
}



library(fmsb)

# Set graphic colors
library(RColorBrewer)
colors_border=c(  rgb(0,1,0.6,0.9), rgb(1,0.2,0.4,0.6) ,  rgb(0,0.6,1,0.7) )
colors_in=c( rgb(0,1,0.6,0.4), rgb(1,0.2,0.4,0.4) , rgb(0,0.6,1,0.2) )


# plot with default options:
radarchart( df_1  , axistype=1 , 
    #custom polygon
    pcol=colors_border , pfcol=colors_in , plwd=2 , plty=1,
    #custom the grid
   cglcol="grey", cglty=1, axislabcol="black",  cglwd=0.8, caxislabels=seq(-2,0,0.5),
    #custom labels
    vlcex=1 
    )

# Add a legend
legend(x=1.5, y=1, legend = rownames(df_1[-c(1,2),]), bty = "n", pch=20 , col=colors_in , text.col = "grey", cex=1.2, pt.cex=3)






##################
#reverse


setwd( '~/Desktop/nmANOVA/reverse_413' )
file_names <- as.list( dir( pattern="reverse_res_413*" ) )

res <- list()

for( i in 1:length( file_names ) ) {
  
  load( file_names[[i]] ) 
  res[[i]] <- res_df
  
  
}


df<- ldply( res, as.data.frame )


df <- 
  df %>%
  #dplyr::select( -m1, -m2, -m3, -m4 )%>%
  group_by( dist_method, vector_num, delta )%>%
  summarise_each( funs = mean) %>%
  ungroup()

cor( df$np_pval, df$nm_pval )




df_thr <- 
  df %>%
  mutate( nm_stat_0.05 = ifelse( nm_pval <= 0.05, 'yes', 'no' ), nm_stat_0.1 = ifelse( nm_pval <= 0.1, 'yes', 'no' ),
          np_stat_0.05 = ifelse( np_pval <= 0.05, 'yes', 'no' ), np_stat_0.1 = ifelse( np_pval <= 0.1, 'yes', 'no' )
           )%>%
  mutate( group = paste( dist_method, vector_num, sep = '_' ) )
  
all_groups <- unique( df_thr$group )

df_5 <- as.data.frame( matrix(0, ncol = length( all_groups ), nrow = 4) )
colnames( df_5 ) <- all_groups
rownames( df_5 ) <- c( 'max', 'min',  'np', 'nm' )
df_5[1, ] <- 0
df_5[2, ] <- -2

df_1 <- df_5

for( j in 1:length( all_groups ) ){
  
  cur_df <- 
    df_thr %>%
    filter( group == all_groups[j] ) %>%
    arrange( delta )
  
  


 df_5[3,j] <- -cur_df$delta[ which( cur_df$np_stat_0.05 == 'yes')[1] ]
 print( 'np' ) 
 print( length( which( cur_df$np_stat_0.05[ ( which( cur_df$np_stat_0.05 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 df_5[4,j] <- -cur_df$delta[ which( cur_df$nm_stat_0.05 == 'yes')[1] ]
 print( 'nm' ) 
 print( length( which( cur_df$nm_stat_0.05[ ( which( cur_df$nm_stat_0.05 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 
  


 df_1[3,j] <- -cur_df$delta[ which( cur_df$np_stat_0.1 == 'yes')[1] ]
 print( 'np' ) 
 print( length( which( cur_df$np_stat_0.1[ ( which( cur_df$np_stat_0.1 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 df_1[4,j] <- -cur_df$delta[ which( cur_df$nm_stat_0.1 == 'yes')[1] ]
 print( 'nm' ) 
 print( length( which( cur_df$nm_stat_0.1[ ( which( cur_df$nm_stat_0.1 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 
  
}



library(fmsb)

# Color vector
colors_border=c( rgb(0.2,0.5,0.5,0.9), rgb(0.8,0.2,0.5,0.9) , rgb(0.7,0.5,0.1,0.9) )
colors_in=c( rgb(0.2,0.5,0.5,0.4), rgb(0.8,0.2,0.5,0.4) , rgb(0.7,0.5,0.1,0.4) )

# plot with default options:
radarchart( df_1  , axistype=1 , 
    #custom polygon
    pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
    #custom the grid
    cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(-2,0,5), cglwd=0.8,
    #custom labels
    vlcex=0.8 
    )

# Add a legend
legend(x=1.5, y=1, legend = rownames(df_1[-c(1,2),]), bty = "n", pch=20 , col=colors_in , text.col = "grey", cex=1.2, pt.cex=3)

###############################################################


setwd( '~/Desktop/nmANOVA/rev_new' )
file_names <- as.list( dir( pattern="reverse_res_413*" ) )

res <- list()

for( i in 1:length( file_names ) ) {
  
  load( file_names[[i]] ) 
  res[[i]] <- res_df
  
  
}


df<- ldply( res, as.data.frame )


df <- 
  df %>%
  #dplyr::select( -m1, -m2, -m3, -m4 )%>%
  group_by( dist_method, vector_num, delta )%>%
  summarise_each( funs = mean) %>%
  ungroup()

cor( df$np_pval, df$nm_pval )




df_thr <- 
  df %>%
  mutate( nm_stat_0.05 = ifelse( nm_pval <= 0.05, 'yes', 'no' ), nm_stat_0.1 = ifelse( nm_pval <= 0.1, 'yes', 'no' ),
          np_stat_0.05 = ifelse( np_pval <= 0.05, 'yes', 'no' ), np_stat_0.1 = ifelse( np_pval <= 0.1, 'yes', 'no' )
           )%>%
  mutate( group = paste( dist_method, vector_num, sep = '_' ) )
  
all_groups <- unique( df_thr$group )

df_5 <- as.data.frame( matrix(0, ncol = length( all_groups ), nrow = 4) )
colnames( df_5 ) <- all_groups
rownames( df_5 ) <- c( 'max', 'min',  'np', 'nm' )
df_5[1, ] <- 0
df_5[2, ] <- -2

df_1 <- df_5

for( j in 1:length( all_groups ) ){
  
  cur_df <- 
    df_thr %>%
    filter( group == all_groups[j] ) %>%
    arrange( delta )
  
  


 df_5[3,j] <- -cur_df$delta[ which( cur_df$np_stat_0.05 == 'yes')[1] ]
 print( 'np' ) 
 print( length( which( cur_df$np_stat_0.05[ ( which( cur_df$np_stat_0.05 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 df_5[4,j] <- -cur_df$delta[ which( cur_df$nm_stat_0.05 == 'yes')[1] ]
 print( 'nm' ) 
 print( length( which( cur_df$nm_stat_0.05[ ( which( cur_df$nm_stat_0.05 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 
  


 df_1[3,j] <- -cur_df$delta[ which( cur_df$np_stat_0.1 == 'yes')[1] ]
 print( 'np' ) 
 print( length( which( cur_df$np_stat_0.1[ ( which( cur_df$np_stat_0.1 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 df_1[4,j] <- -cur_df$delta[ which( cur_df$nm_stat_0.1 == 'yes')[1] ]
 print( 'nm' ) 
 print( length( which( cur_df$nm_stat_0.1[ ( which( cur_df$nm_stat_0.1 == 'yes' ) +1 ):nrow( cur_df ) ] == 'no' ) ) ) 
 
 
  
}

df_1 <- df_1[c(1,2, 4, 3),]

df_11 <- df_1
df_11[3, 3:9] <- NA
library(fmsb)

# Color vector
colors_border=c( rgb(0,0.6,1,0.7), rgb(1,0.2,0.4,0.6) , rgb(0.7,0.5,0.1,0.9) )
colors_in=c( rgb(0,0.6,1,0.2), rgb(1,0.2,0.4,0.4) , rgb(0.7,0.5,0.1,0.4) )

# plot with default options:
radarchart( df_1  , axistype=1 , 
    #custom polygon
    pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
    #custom the grid
    cglcol="grey", cglty=1, axislabcol="grey", caxislabels=seq(-2,0,0.5), cglwd=0.8,
    #custom labels
    vlcex=0.8 
    )

# Add a legend
legend(x=1.5, y=1, legend = rownames(df_1[-c(1,2),]), bty = "n", pch=20 , col=colors_in , text.col = "grey", cex=1.2, pt.cex=3)




par(mfrow=c(2,3) , mar=c(2,2,2,1) , oma=c(4,5,1,1) )
 
line <- 6
col <- 6
red <- sort(rep(c(0,0.2,0.4,0.6,0.8,1),col))
green <- rep(c(0,0.2,0.4,0.6,0.8,1),line)
num <- 0
 
for(i in seq(0,1,0.2)){
    num <- num+1
    plot(0, 0, type = "n", xlim = c(0, 1), ylim = c(0, 1), axes = FALSE, xlab = "", ylab = "" )
    colors <- rgb(red,green,i,1)
    mtext(paste("blue = ",i,sep="") , side=3 , line=0.15 , col="blue" , font=2)
    rect(  rep((0:(col - 1)/col),line) ,  sort(rep((0:(line - 1)/line),col),decreasing=T)   ,   rep((1:col/col),line) , sort(rep((1:line/line),col),decreasing=T),  border = "light gray" , col=colors)
    axis(2 , at=c(17,14,11,8,5,2)/18-0.035 , labels=c("0","0.2","0.4","0.6","0.8","1") , tick=F , lty=6 , pos=0.01)
    axis(3 , at=c(1.5 , 3.5 , 5.5 , 7.5 , 9.5 , 11.5)/12-0.045 , labels=c("0","0.2","0.4","0.6","0.8","1") , tick=F , pos=-0.15)
    }
 
mtext("Quantity of red", side=2 , line=34 , col="red" , font=2 , at=1.2)
mtext("Quantity of green", side=1 , line=3 , at=-0.8 , col="forestgreen" , font=2)

  
```


DRUGCOMB 
Figures 7, 8 (Supplementary) and Table 3
DrugComb table for O'Neil dataset is in summary_table_ONEIL.xlsx
p-values in all_res, filters for cell_line, heatmaps at the end
you can modify the manuscript Figure 7 using Inkscape, file EFM192B_heat.svg and Figure 8 using Inkscape, file cl_all_heast.svg
```{r}

#all_res contains nmANOVA p-values

library( pheatmap )
oneil <- read.xlsx("summary_table_ONEIL.xlsx")
all_cl <- unique( oneil$cell_line_name )

#cur_cl <- 'LOVO'
all_res <- list()
k <- 0
for (ii in 1:length( all_cl ) ){
 

#for( j in 1:4){
   k <- k+1
        cur_cl <- all_cl[ii]
        # A2058 cell line
        oneil_a2058 = oneil[oneil$cell_line_name==cur_cl,]
       #A_oneil_a2058_single <- 
       # oneil_a2058 %>%
       #  group_by( drug_row,drug_col )%>%
       #  dplyr::slice(j)
  
        A_oneil_a2058_single <- oneil_a2058 
        oneil_a2058_single = ddply(A_oneil_a2058_single, .(drug_row,drug_col), summarise, 
                                   css_row = mean(css_row), css_col = mean(css_col),
                                   ri_row = mean(ri_row), ri_col = mean(ri_col))
        # combo
        oneil_a2058_1 = oneil_a2058_single[,c('drug_row','drug_col','css_row')]
        oneil_a2058_2 = oneil_a2058_single[,c('drug_col','drug_row','css_col')]
        # single drug
        oneil_a2058_3 = oneil_a2058_single[,c('drug_col','drug_row','ri_row')]
        oneil_a2058_4 = oneil_a2058_single[,c('drug_col','drug_row','ri_col')]
        oneil_a2058_3$drug_col=oneil_a2058_3$drug_row
        oneil_a2058_4$drug_row=oneil_a2058_4$drug_col
        colnames(oneil_a2058_2) = colnames(oneil_a2058_1)
        colnames(oneil_a2058_3) = colnames(oneil_a2058_1)
        colnames(oneil_a2058_4) = colnames(oneil_a2058_1)
        oneil_a2058_all = rbind(oneil_a2058_1, oneil_a2058_2, oneil_a2058_3, oneil_a2058_4)
        # css_mat: asymetric
        
        # ri values on the diagonal
        css_mat = dcast(oneil_a2058_all, drug_row ~ drug_col, value.var = "css_row", fun.aggregate = mean)
        rownames(css_mat) = css_mat$drug_row
        css_mat = css_mat[,-1]
      
        
        # impute NA with the average of RI of single drugs
        na_index = which(is.na(css_mat)==T, arr.ind = T)
        for (i in 1:nrow(na_index)){
          css_mat[na_index[i,1], na_index[i,2]] = (css_mat[na_index[i,1],na_index[i,1]] + css_mat[na_index[i,2],na_index[i,2]])/2 
        }
        
        
        
        # to be used by hclust, force it to be symmetric by taking lower triangle
       # css_mat2 = 1 - abs(cor(css_mat)) # use correlation as distance
        css_mat2 =  1 - abs(cor(css_mat))
        css_mat2 = 1 - abs(cor(css_mat)) # use correlation as distance, column wise
        css_mat3 = 1 - abs(cor(t(css_mat))) # row wise, you have two versions of correlation matrix
# then merge these two correlation matrix, lower diagnoal as css_mat2, upper diagonal as css_mat3
        css_mat4 = css_mat2
        css_mat4[upper.tri(css_mat4)] <- t(css_mat3)[upper.tri(css_mat3)] # take lower triangle
        clusters <- hclust(as.dist(css_mat2))
        clusterCut <- cutree(clusters, 2)
        
        #pheatmap(css_mat2, clustering_distance_rows = as.dist(css_mat2),
        # clustering_distance_cols = as.dist(css_mat2),
        #clustering_method = "complete")
        

    

      
        # to run nmanova, it shall produce similarly two best clusters, determined by p-values
        partition <- paste( 'group_', clusterCut, sep = '' )
        #css_mat3 = 1 - abs(cor(css_mat))
        res <- nmANOVA( ( css_mat4 ), partition,1)
        #View(res$summary)
        all_res[[k]] <- res$summary
        all_res[[k]]$cell_line <- cur_cl
        all_res[[k]]$mat <- 'css_mat'
        all_res[[k]]$num <- k
        all_res[[k]]$cluster_num <- 2
        #all_res[[k]]$slice <- j
        
        if(res$summary$p_value < 0.05){
       print( cur_cl)
        plot(clusters)
        #css_mat2_ordered <- css_mat2[clusters$order,clusters$order]
        #pheatmap( t( as.matrix( css_mat2_ordered ) ), cluster_cols = F, cluster_rows = F )
        css_mat_ordered <- css_mat4[clusters$order,clusters$order]
        pheatmap( t( as.matrix( css_mat_ordered ) ), cluster_cols = F, cluster_rows = F )
       colnames( css_mat4 )[which(clusterCut ==2 )]
        }
}
 

        


all_res <- ldply( all_res, data.frame )


sel_cell_lines <- c( 'VCAP', 'OVCAR3', 'CAOV3', 'HT144', 'ES2', 'EFM192B', 'HCT116' ) # those gave us significant p-values

for( i in 1:length( sel_cell_lines ) ) {
  
  cur_cl <- sel_cell_lines[i]
        # A2058 cell line
        oneil_a2058 = oneil[oneil$cell_line_name==cur_cl,]
       #A_oneil_a2058_single <- 
       # oneil_a2058 %>%
       #  group_by( drug_row,drug_col )%>%
       #  dplyr::slice(j)
  
        A_oneil_a2058_single <- oneil_a2058 
        oneil_a2058_single = ddply(A_oneil_a2058_single, .(drug_row,drug_col), summarise, 
                                   css_row = mean(css_row), css_col = mean(css_col),
                                   ri_row = mean(ri_row), ri_col = mean(ri_col))
        # combo
        oneil_a2058_1 = oneil_a2058_single[,c('drug_row','drug_col','css_row')]
        oneil_a2058_2 = oneil_a2058_single[,c('drug_col','drug_row','css_col')]
        # single drug
        oneil_a2058_3 = oneil_a2058_single[,c('drug_col','drug_row','ri_row')]
        oneil_a2058_4 = oneil_a2058_single[,c('drug_col','drug_row','ri_col')]
        oneil_a2058_3$drug_col=oneil_a2058_3$drug_row
        oneil_a2058_4$drug_row=oneil_a2058_4$drug_col
        colnames(oneil_a2058_2) = colnames(oneil_a2058_1)
        colnames(oneil_a2058_3) = colnames(oneil_a2058_1)
        colnames(oneil_a2058_4) = colnames(oneil_a2058_1)
        oneil_a2058_all = rbind(oneil_a2058_1, oneil_a2058_2, oneil_a2058_3, oneil_a2058_4)
        # css_mat: asymetric
        
        # ri values on the diagonal
        css_mat = dcast(oneil_a2058_all, drug_row ~ drug_col, value.var = "css_row", fun.aggregate = mean)
        rownames(css_mat) = css_mat$drug_row
        css_mat = css_mat[,-1]
      
        
        # impute NA with the average of RI of single drugs
        na_index = which(is.na(css_mat)==T, arr.ind = T)
        for (i in 1:nrow(na_index)){
          css_mat[na_index[i,1], na_index[i,2]] = (css_mat[na_index[i,1],na_index[i,1]] + css_mat[na_index[i,2],na_index[i,2]])/2 
        }
        
        
        
        # to be used by hclust, force it to be symmetric by taking lower triangle
       # css_mat2 = 1 - abs(cor(css_mat)) # use correlation as distance
        css_mat2 =  1 - abs(cor(css_mat))
        css_mat2 = 1 - abs(cor(css_mat)) # use correlation as distance, column wise
        css_mat3 = 1 - abs(cor(t(css_mat))) # row wise, you have two versions of correlation matrix
# then merge these two correlation matrix, lower diagnoal as css_mat2, upper diagonal as css_mat3
        css_mat4 = css_mat2
        css_mat4[upper.tri(css_mat4)] <- t(css_mat3)[upper.tri(css_mat3)] # take lower triangle
        clusters <- hclust(as.dist(css_mat4))
        clusterCut <- cutree(clusters, 2)
        
        #pheatmap(css_mat2, clustering_distance_rows = as.dist(css_mat2),
        # clustering_distance_cols = as.dist(css_mat2),
        #clustering_method = "complete")
        

    

      
        # to run nmanova, it shall produce similarly two best clusters, determined by p-values
        partition <- paste( 'group_', clusterCut, sep = '' )
        #css_mat3 = 1 - abs(cor(css_mat))
        res <- nmANOVA( ( css_mat4 ), partition,1)
        
        
        if(res$summary$p_value < 0.05){
       print( cur_cl)
        plot(clusters)
        #css_mat2_ordered <- css_mat2[clusters$order,clusters$order]
        #pheatmap( t( as.matrix( css_mat2_ordered ) ), cluster_cols = F, cluster_rows = F )
        css_mat_ordered <- css_mat4[clusters$order,clusters$order]
        colnames( css_mat_ordered ) <- toupper( colnames( css_mat_ordered ) )
        rownames( css_mat_ordered ) <- toupper( rownames( css_mat_ordered ) )
        pheatmap( t( as.matrix( css_mat_ordered ) ), cluster_cols = F, cluster_rows = F, main = cur_cl,fontsize_row = 10, fontsize_col = 10  )
       colnames( css_mat4 )[which(clusterCut ==2 )]
        }
  
  
}

```








codes with previous versions 
no need to look at them
######################################################################################################################################################

make a general function for a new version of nmANOVA
```{r}

#nmANOVA(d, c( cluster1, cluster1,cluster1,cluster2,cluster2,cluster3), c( 'cluster2', 'cluster3') )
nmANOVA <- function( diss_data, partition, subpartition = NULL ) {
  
  #diss_data - a numeric matrix or data.frame with dissimilarity measures,columns and rows should be in the same order
  #partition - a vector specifying the groups, it should be same length and in the same order as diss_data columns/rows 
  #subpartition - a vector of groups present in partition for which the method has to be applied to 
  #if subpartition is NULL, the method will be applied to all the groups present in partition ( unique( partition ) )
  
  if ( nrow( diss_data ) != ncol( diss_data ) )
    stop( "matrix has to be square" )
  
  if ( nrow( diss_data ) != length( partition ) )
    stop( "partition has to be same length as the number of row/columns in the matrix" )
  
  if ( !is.null( subpartition ) & length( unique( subpartition ) ) < 2 )
    stop( "there should be at least two unique subpartitions" )
  
  partition <- as.factor( as.vector( partition ) )
  partition_sorted <- partition[ order( partition ) ]
  
  inner_partition_names <- vector()
  for ( i in 1:length( levels( partition_sorted ) ) ){
    inner_partition_names <- c( inner_partition_names, paste0( levels( partition_sorted )[i],'_', seq( 1:table( partition_sorted )[i] ) ) )
  }
  
  #set the names for each column/row based on a partition they belong to
  inner_partition_names <- inner_partition_names[ order( order ( partition ) ) ]
  partition_df <- as.data.frame( diss_data )
  colnames( partition_df ) <- inner_partition_names
  rownames( partition_df ) <- inner_partition_names
  
  #check if there is a subpartition provided  
  if ( !is.null( subpartition ) ){
    if ( length( unique( intersect( partition, subpartition ) ) ) !=  length( unique( subpartition )  )  )
    stop( "some elements from the subpartition do not match with partition" )
     subpartition <- as.factor( as.vector( subpartition ) )
     partition <- partition[ which( partition %in% intersect( partition, subpartition ) ) ]
  }
  
  selected_partitions <- which( sub('_[^_]*$', '', colnames( partition_df ) ) %in% partition )
  selected_partitions <- which( sub('_[^_]*$', '', rownames( partition_df ) ) %in% partition )
  partition_df <- partition_df[ selected_partitions, selected_partitions ]
  partition_df <- partition_df[ order( row.names( partition_df ) ), order( names( partition_df ) ) ]
  
  #print( sum( colnames( partition_df ) == rownames( partition_df ) ) == nrow( partition_df ) )
  
  #the actual partition
  partition <- as.factor( sub('_[^_]*$', '', colnames( partition_df ) ) )
  #number of elements in each partition
  n_partition <- as.vector( table( partition ) )
  
  
  #calculate delta_w and delta_jj
  vec_within <- vector()
  delta_jj <- vector()
  
  for( i in 1:length( levels( partition ) ) ){
    
    ind_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
    cur_partition <-  as.numeric( as.matrix( partition_df[ ind_partition, ind_partition ] ) )
    vec_within <- c( vec_within, cur_partition)
    delta_jj[i] <- mean( cur_partition, na.rm = TRUE )
  
  }
  
  delta_w <- mean( vec_within, na.rm = TRUE )
  
  #calculate SNM_w
  SNM_w <- 0
  for( i in 1:length( levels( partition ) ) ){
   SNM_w <- SNM_w +  ( n_partition[i] * ( delta_jj[i] - delta_w ) )^2
  }
  
  
  #calculate delta_jj', delta_prop and SNM_b
  
   
  diagonal_sampling <- vec_within
  
  num_off_diag <- nrow( partition_df )^2 - length( vec_within )
  num_off_diag_groups <- length( levels( partition ) )^2 - length( levels( partition ) )
  prop_sampl_df <- data.frame( num = numeric( num_off_diag_groups ),
                 part_mean = numeric( num_off_diag_groups ),
                 prop_mean = numeric( num_off_diag_groups ),
                 partitions = character( num_off_diag_groups ),
                 sampling_ind = character( num_off_diag_groups), 
                 sampled_from = character(num_off_diag_groups), 
                 stringsAsFactors=FALSE )  
  k <- 0
  
  delta_jj_prime <- vector()
  SNM_b <- 0
  for( i in 1:length( levels( partition ) ) ){
    for( j in 1:length( levels( partition ) ) ){
      if( i != j ){ 

        ind_row_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
        ind_col_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[j] )
        cur_partition <-  as.numeric( as.matrix( partition_df[ ind_row_partition, ind_col_partition ] ) )
        
        #perform proportional sampling and save it
        prop_num<- floor( n_partition[i]*n_partition[j] * length( vec_within )/num_off_diag )
        sample_ind <- sample( c( 1:length( diagonal_sampling ) ), prop_num, replace = FALSE )
        k <- k + 1
        prop_sampl_df$num[k] <- k
        prop_sampl_df$partitions[k] <- paste0( levels( partition )[i], ',', levels( partition )[j] )
        prop_sampl_df$sampling_ind[k] <- paste0( sample_ind, collapse = ',' )
        prop_sampl_df$sampled_from <- paste0( diagonal_sampling, collapse = ',' )
        delta_prop <- mean( diagonal_sampling[ sample_ind ] )
        diagonal_sampling <- diagonal_sampling[ -sample_ind ]
        
        prop_sampl_df$prop_mean[k] <- delta_prop
      
        delta_jj_prime <- mean( cur_partition,  na.rm = TRUE )
        prop_sampl_df$part_mean[k] <- delta_jj_prime
        
        SNM_b <- SNM_b + ( ( delta_jj_prime - delta_prop )/( sqrt( ( 1/( n_partition[i]*n_partition[j] ) + 1/prop_num ) ) ) )^2
        
      }
    }
  }
  
  #calculate statistics
  F_stat <- ( SNM_b/length( levels( partition ) ) ) / SNM_w
  df1 <- length( levels( partition ) )^2 - length( levels( partition ) )
  df2 <-  length( levels( partition ) ) - 1
  p_value <- pf( F_stat, df1, df2, lower.tail = F ) 
  #print( p_value )
  res <- list()
  
  res[[1]] <- data.frame( N_partitions = length( levels( partition ) ), partition = paste(  levels( partition ) , collapse = ','), n_partition = paste( n_partition , collapse= ','  ), delta_w = delta_w,  delta_jj = paste( delta_jj, collapse= ',' ), delta_jj_prime = paste( delta_jj_prime, collapse= ','), SNM_w = SNM_w,  SNM_b = SNM_b, F_stat =  F_stat, p_value = p_value  )
  
  res[[2]] <- prop_sampl_df
  
  names( res ) <- c( 'summary', 'proportional_sampling' ) 
  
  res
  
}
```

Jing version
```{r}
nmANOVA_2_blocks <- function( diss_data, partition, subpartition = NULL ) {
  
  #diss_data - a numeric matrix or data.frame with dissimilarity measures,columns and rows should be in the same order
  #partition - a vector specifying the groups, it should be same length and in the same order as diss_data columns/rows 
  #subpartition - a vector of groups present in partition for which the method has to be applied to 
  #if subpartition is NULL, the method will be applied to all the groups present in partition ( unique( partition ) )
  
  if ( nrow( diss_data ) != ncol( diss_data ) )
    stop( "matrix has to be square" )
  
  if ( nrow( diss_data ) != length( partition ) )
    stop( "partition has to be same length as the number of row/columns in the matrix" )
  
  if ( !is.null( subpartition ) & length( unique( subpartition ) ) < 2 )
    stop( "there should be at least two unique subpartitions" )
  
  partition <- as.factor( as.vector( partition ) )
  partition_sorted <- partition[ order( partition ) ]
  
  inner_partition_names <- vector()
  for ( i in 1:length( levels( partition_sorted ) ) ){
    inner_partition_names <- c( inner_partition_names, paste0( levels( partition_sorted )[i],'_', seq( 1:table( partition_sorted )[i] ) ) )
  }
  
  #set the names for each column/row based on a partition they belong to
  inner_partition_names <- inner_partition_names[ order( order ( partition ) ) ]
  partition_df <- as.data.frame( diss_data )
  colnames( partition_df ) <- inner_partition_names
  rownames( partition_df ) <- inner_partition_names
  
  #check if there is a subpartition provided  
  if ( !is.null( subpartition ) ){
    if ( length( unique( intersect( partition, subpartition ) ) ) !=  length( unique( subpartition )  )  )
    stop( "some elements from the subpartition do not match with partition" )
     subpartition <- as.factor( as.vector( subpartition ) )
     partition <- partition[ which( partition %in% intersect( partition, subpartition ) ) ]
  }
  
  selected_partitions <- which( sub('_[^_]*$', '', colnames( partition_df ) ) %in% partition )
  selected_partitions <- which( sub('_[^_]*$', '', rownames( partition_df ) ) %in% partition )
  partition_df <- partition_df[ selected_partitions, selected_partitions ]
  partition_df <- partition_df[ order( row.names( partition_df ) ), order( names( partition_df ) ) ]
  
  #print( sum( colnames( partition_df ) == rownames( partition_df ) ) == nrow( partition_df ) )
  
  #the actual partition
  partition <- as.factor( sub('_[^_]*$', '', colnames( partition_df ) ) )
  #number of elements in each partition
  n_partition <- as.vector( table( partition ) )
  
  # determine the maximal NX
  T1 = sum( n_partition )/2
  T2 = sqrt( sum( n_partition^2 )/2 )
  T3 = sqrt(sum( n_partition )^2/2 - sum( n_partition^2 )/2)
  NX = floor(min(c(T1,T2,T3))) 
  
  
  diagonal <- vector()
  off_diagonal <- vector()
  
  
  for( i in 1:length( levels( partition ) ) ){
    for( j in 1:length( levels( partition ) ) ){
      
      if( i == j ){ 

        ind_row_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
        ind_col_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[j] )
        diagonal <-  c( diagonal, as.vector( as.numeric( as.matrix( partition_df[ ind_row_partition, ind_col_partition ] ) ) ) )
        
      
      }
      
      if( i != j ){ 

        ind_row_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[i] )
        ind_col_partition <- which(  sub('_[^_]*$', '', colnames( partition_df ) ) == levels( partition )[j] )
        off_diagonal <-  c( off_diagonal, as.vector( as.numeric( as.matrix( partition_df[ ind_row_partition, ind_col_partition ] ) ) ) )
        
    
      }
    }
  }
  
  block1 = sample(diagonal, NX^2) # ks.test(block1,"punif",a,b)
  block2 = sample(setdiff(diagonal, block1), NX^2) # ks.test(block2,"punif",a,b)
  block12 = sample(off_diagonal, NX^2) # ks.test(block12,"punif",a,b)
  block21 = sample(setdiff(off_diagonal, block12), NX^2) # ks.test(block21,"punif",a,b)
  
  delta11 <- mean( as.vector( as.matrix( block1 ) ) )
  delta22 <- mean( as.vector( as.matrix( block2 ) ) )
  delta12 <- mean( as.vector( as.matrix( block12 ) ) )
  delta21 <- mean( as.vector( as.matrix( block21 ) ) )
  
  delta_w <- mean( c( as.vector( as.matrix( block1 ) ), as.vector( as.matrix( block2 ) ) ) ) 
  
  tmp1 = sample(block1, NX*NX/2)
  tmp2 = setdiff(block1, tmp1)
  tmp3 = sample(block2, NX*NX/2)
  tmp4 = setdiff(block2, tmp3)
  delta_w1 <- mean( c(tmp1, tmp3))
  delta_w2 <- mean( c(tmp2, tmp4))
  
  snm_w <- (( NX*( delta11 - delta_w ) )^2 + ( NX*( delta22 - delta_w  ) )^2)  #delta within the group, chi(q-1)
  snm_b <- (( NX*( delta12  - delta_w1  ) )^2 + ( NX*( delta21  - delta_w2  ) )^2)  #delta between the group, gamma(1,4)
  
  alpha_b = 1
  beta_b = 1/4
  alpha_w = 0.5
  beta_w = 1/2
  df1 = 2*alpha_b
  df2 = 2*alpha_w
  F_stat <- ( alpha_w*beta_b*snm_b )/( alpha_b*beta_w*snm_w ) # F(2*alpha_b,2*alpha_w) 
  p_value <- pf( F_stat, df1, df2, lower.tail = F)

  
  res <- data.frame( N_partitions = length( levels( partition ) ), partition = paste(  levels( partition ) , collapse = ','), n_partition = paste( n_partition , collapse= ','  ), delta_w = delta_w,  delta_w_jj = paste( c( delta_w1, delta_w2 ), collapse= ',' ), delta_jj = paste( c( delta11, delta22 ), collapse= ',' ), delta_jj_prime = paste( c( delta12, delta21 ), collapse= ','), SNM_w = snm_w,  SNM_b = snm_b, F_stat =  F_stat, p_value = p_value  )

  
  res
  
}
```

```{r}
nmANOVA_sim <- function( distribution, group_N, par_vec, H1_group = NULL, show_plots = FALSE ){
  
  
        
      par1 <- par_vec[1]
      par2 <- par_vec[2]
      
      df_dist_par <- data.frame( groups = character( length( group_N )^2 ), 
                                 dist_par = character( length( group_N )^2 ), 
                                 stringsAsFactors=FALSE )
      k <- 0
      for ( i in 1:length( group_N ) ){
      for ( j in 1:length( group_N ) ){
          
          k <- k + 1 
          df_dist_par$groups[k] <- paste0( 'group', i, ',', 'group', j )
          
      if( ( !is.null( H1_group ) ) & ( length( which( H1_group$groups ==  df_dist_par$groups[k] ) ) != 0 )  ){
        
        par1_new <- H1_group$dist_par1[ which( H1_group$groups ==  df_dist_par$groups[k] )]
        par2_new <- H1_group$dist_par2[ which( H1_group$groups ==  df_dist_par$groups[k] )]
        df_dist_par$dist_par[k] <- paste0( par1_new,',', par2_new )
        
      } else{
         df_dist_par$dist_par[k] <- paste0( par1,',', par2 )
      }  
          
         
          
        }
        
      }
      
      
      #generate datasets based on selection
      diss_data <- generate_diss( distribution, group_N, df_dist_par, show_plots )
      
      partition <- vector()
      for( i in 1:length( group_N ) ){
        partition <- c( partition, rep( paste0( 'group', i ), group_N[i] ) )
        
      }
      
      res <- nmANOVA(diss_data, partition)
      
      
      
}
nmANOVA_2_blocks_sim <- function( distribution, group_N, par_vec, H1_group = NULL, show_plots = FALSE ){
  
  
        
      par1 <- par_vec[1]
      par2 <- par_vec[2]
      
      df_dist_par <- data.frame( groups = character( length( group_N )^2 ), 
                                 dist_par = character( length( group_N )^2 ), 
                                 stringsAsFactors=FALSE )
      k <- 0
      for ( i in 1:length( group_N ) ){
      for ( j in 1:length( group_N ) ){
          
          k <- k + 1 
          df_dist_par$groups[k] <- paste0( 'group', i, ',', 'group', j )
          
      if( ( !is.null( H1_group ) ) & ( length( which( H1_group$groups ==  df_dist_par$groups[k] ) ) != 0 )  ){
        
        par1_new <- H1_group$dist_par1[ which( H1_group$groups ==  df_dist_par$groups[k] )]
        par2_new <- H1_group$dist_par2[ which( H1_group$groups ==  df_dist_par$groups[k] )]
        df_dist_par$dist_par[k] <- paste0( par1_new,',', par2_new )
        
      } else{
         df_dist_par$dist_par[k] <- paste0( par1,',', par2 )
      }  
          
         
          
        }
        
      }
      
      
      #generate datasets based on selection
      diss_data <- generate_diss( distribution, group_N, df_dist_par, show_plots )
      
      partition <- vector()
      for( i in 1:length( group_N ) ){
        partition <- c( partition, rep( paste0( 'group', i ), group_N[i] ) )
        
      }
      
      res <- nmANOVA_2_blocks(diss_data, partition)
      
      
      
}


```


check of uniform distribution distribution under H0
```{r}

distribution <- 'uniform' #distribution for the simulation matrix
group_N <- c( 13, 21, 34 )#group sizes 
par_vec <- c( 2, 1 )# distribution parameters


p_value_h0 <- vector()
p_value_dc <- vector()
partition <- c( rep( 'group1', group_N[1] ), rep( 'group2', group_N[2] ), rep( 'group3', group_N[3] ) )

for( i in 1:100  ){
   
  #set.seed(i*1000)
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec,  show_plots = FALSE )
  p_value_h0[i] <- sim_results[[1]]$summary$p_value 
  
  css_mat <- sim_results[[2]]
  css_mat2 = 1 - abs(cor(css_mat)) # use correlation as distance, column wise
  css_mat3 = 1 - abs(cor(t(css_mat))) # row wise, you have two versions of correlation matrix
  # then merge these two correlation matrix, lower diagonal as css_mat2, upper diagonal as css_mat3
  css_mat4 = css_mat2
  css_mat4[upper.tri(css_mat4)] <- t(css_mat3)[upper.tri(css_mat3)] # take lower triangle
  diag( css_mat4 ) <- NA
  sim_results1 <- nmANOVA( css_mat4, partition, 1 )
  p_value_dc[i] <- sim_results1$summary$p_value 
  
  
  }

ks.test( p_value_h0, "punif", 0, 1 )
ks.test( p_value_dc, "punif", 0, 1 )

hist( p_value_h0)
hist(p_value_dc)
set.seed(100)
f1 <- rnorm( 1000)
set.seed(100)
f2 <- rnorm( 1000)

hist(f1)
hist( c(f1, f2))
```


check correlations, distribution hypothesis - it is working
```{r}
distribution <- 'uniform' #distribution for the simulation matrix
group_N <- c( 10, 20, 30 )#group sizes 
par_vec <- c( 0, 1 )# distribution parameters

#in case you want to introduce the difference - select some groups and change parameters in H1_group
#dist_par1 is a new parameter to use instead of par1 for the specified groups
#dist_par2 is a new parameter to use instead of par2 for the specified groups
H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 2, 2 ), dist_par2 = c( 5, 5 ) )

p_value <- vector()
for( i in 1:1000 ){
  
  sim_results2 <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = FALSE, N_sampling = i  )
  p_value[i] <-  sim_results2$summary$p_value
  
}






load("/Users/amalyuti/Desktop/nmANOVA/sim_100000.RData")
prop_sampl_df <-
  prop_sampl_df %>%
  mutate( p_value_log = log( p_value ))

plot( prop_sampl_df$N_sampling_num, prop_sampl_df$p_value)

ggplot(prop_sampl_df, aes(x=( N_sampling_num ), y=( p_value )))+ 
    stat_summary(geom="ribbon", fun.data=mean_cl_normal, 
                 fun.args=list(conf.int=0.95), fill="lightblue")+
    stat_summary(geom="line", fun.y=mean )+
    stat_summary(geom="point", fun.y=mean, color="red") + theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
  geom_hline( yintercept = mean( ( prop_sampl_df$p_value ) ), col = 'red' ) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1) ) +
              xlab( "Number of proportional samplings performed" ) + ylab( "p-value" ) + 
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 20), legend.title=element_text(size=20), legend.text=element_text(size=20) ) +
geom_text(aes( x = -1, y = mean( p_value ) + 0.0000005, label = "average \n  p-value", color = "red" ), size = 7, alpha= 1,  fontface="bold")

ggplot(prop_sampl_df, aes(x=N_sampling_num, y=time))+ 
    stat_summary(geom="ribbon", fun.data=mean_cl_normal, 
                 fun.args=list(conf.int=0.95), fill="lightblue")+
    stat_summary(geom="line", fun.y=mean )+
    stat_summary(geom="point", fun.y=mean, color="red") + theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1) ) +
              xlab( "Number of proportional samplings performed" ) + ylab( "p-value" ) + 
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 20), legend.title=element_text(size=20), legend.text=element_text(size=20) )

p_value <- vector()
F_array <- sim_results[[3]]
part <- 2
for(i in 1:length( F_array ) ){
  F_stat <-  mean( F_array[1:i], na.rm = TRUE )
  
  df1 <- part^2 - part
  df2 <-  part - 1
  p_value[i] <- pf( F_stat, df1, df2, lower.tail = F ) 
  
  
  
  
}
prop_sampl_df <- data.frame( N_sampling_num = c(1 :length( F_array ) ), p_value = p_value )

ggplot(prop_sampl_df, aes(x=( N_sampling_num ), y=( p_value )))+ 
    stat_summary(geom="ribbon", fun.data=mean_cl_normal, 
                 fun.args=list(conf.int=0.95), fill="lightblue")+
    stat_summary(geom="line", fun.y=mean )+
    stat_summary(geom="point", fun.y=mean, color="red") + theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
  geom_hline( yintercept = mean( ( prop_sampl_df$p_value ) ), col = 'red' ) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1) ) +
              xlab( "Number of proportional samplings performed" ) + ylab( "p-value" ) + 
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 20), legend.title=element_text(size=20), legend.text=element_text(size=20) ) +
geom_text(aes( x = -1, y = mean( p_value ) + 0.0000005, label = "average \n  p-value", color = "red" ), size = 7, alpha= 1,  fontface="bold")


ggplot(prop_sampl_df[1000:100000, ], aes(x=( N_sampling_num ), y=( p_value )))+ 
  #geom_point( size = 1, col = 'red' ) +
  geom_line(size = 1) +
    theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
  geom_hline( yintercept = mean( ( prop_sampl_df$p_value ) ), col = 'red' ) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1) ) +
              xlab( "Number of proportional samplings performed" ) + ylab( "p-value" ) + 
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 20), legend.title=element_text(size=20), legend.text=element_text(size=20) ) +
geom_text(aes( x = -1, y = mean( p_value ) + 0.0000005, label = "average \n  p-value", color = "red" ), size = 7, alpha= 1,  fontface="bold")




#from here


F_stats <- prop_sampl_df[[3]]
df <- data.frame( prop_sampl_num = seq(1:length( F_stats ) ), F_stat = as.vector( F_stats ), p_value  = rep( 1,length( F_stats )  ) )
partition <- as.factor(  c( rep( 'group_1', 10 ), rep( 'group_2', 20 ), rep( 'group_3', 30 ) )
 )
for( i in 1:nrow( df ) ){
  
  F_stat <- mean( df$F_stat[1:i] )
  
  df1 <- length( levels( partition ) )^2 - length( levels( partition ) )
  df2 <-  length( levels( partition ) ) - 1
  p_value <- pf( F_stat, df1, df2, lower.tail = F ) 
  
  df$p_value[i] <- p_value
  
}

######################################################

```


4.1.1
```{r}

set.seed(411)

library( pheatmap )
#Example 1: uniform distribution, 3 clusters equal size

distribution <- 'uniform' #distribution for the simulation matrix
group_N <- c( 10, 10, 10 )#group sizes 
par_vec <- c( 0, 1 )# distribution parameters

#in case you want to introduce the difference - select some groups and change parameters in H1_group
#dist_par1 is a new parameter to use instead of par1 for the specified groups
#dist_par2 is a new parameter to use instead of par2 for the specified groups
#H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 20, 20 ), dist_par2 = c( 30, 30 ) )
  
#perform simulations and check distribution of p-values w
Nsim <- 1
p_value <- vector()
delta <- seq( 0, 10, length.out = 1000 )



for( i in 1:( 3*length( delta ) ) ){
  print(i)
  if ( i <= length( delta ) ){
    #set.seed(411)
  H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 0 + delta[i], 0 + delta[i] ), dist_par2 = c( 1 + delta[i], 1 + delta[i] ) )
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value[i] <- sim_results[[1]]$summary$p_value 
  }
  
 if ( ( i > length( delta ) )  & ( i <= 2*length( delta ) ) ){
  # set.seed(411)
    H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2', 'group1,group3', 'group3,group1'  ), dist_par1 = c( 0 + delta[i-length( delta )], 0 + delta[i-length( delta )],  0 + delta[i-length( delta )], 0 + delta[i-length( delta )] ), dist_par2 = c( 1 + delta[i-length( delta )], 1 + delta[i-length( delta )], 1 + delta[i-length( delta ) ], 1 + delta[i-length( delta )]  ) )
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value[i] <- sim_results[[1]]$summary$p_value 
    
    
  }
  
  if ( ( i > 2*length( delta ) )   ){
  #set.seed(411)
    H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2', 'group1,group3', 'group3,group1' ,  'group2,group3', 'group3,group2'  ), dist_par1 = c( 0 + delta[i-2*length( delta )], 0 + delta[i-2*length( delta )], 0 + delta[i-2*length( delta )], 0 + delta[i-2*length( delta )],  0 + delta[i-2*length( delta )], 0 + delta[i-2*length( delta )] ), dist_par2 = c( 1 + delta[i-2*length( delta )], 1 + delta[i-2*length( delta )], 1 + delta[i-2*length( delta ) ], 1 + delta[i-2*length( delta )], 1 + delta[i-2*length( delta )], 1 + delta[i-2*length( delta )]  ) )
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value[i] <- sim_results[[1]]$summary$p_value 
    
    
  }
  
  
}
p_value_unfix <- p_value
plot( log10( p_value ) )
#save( p_value_unfix, file = 'unfix_100_prop_1000_delta_p_values.RData' )


p_value_h0 <- vector()
p_value_nm <- vector()

for( i in 1:10  ){
   set.seed(i*1000)
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec,  show_plots = FALSE )
  p_value_h0[i] <- sim_results[[1]]$summary$p_value 
  m <- sim_results[[2]]
  m1<- as.data.frame( m)
  m1 <- unlist(m1)
n <- length(m1) * 0.7
m1[sample(1:length( m1 ), n)] <- NA
m2 <- as.data.frame(matrix(m1, ncol=30) )
 anova_dist_mat <- m2
  #anova_dist_mat <- change.dist.mat( dist_mat, partition )
 pp <- c( rep( 'group1', 10 ), rep( 'group2', 10 ), rep( 'group3', 10 ))
          #nm_res1 <- nmANOVA( anova_dist_mat, pp, N_sampling = 1)
 set.seed(i*1000)
          nm_res1 <- nmANOVA( m, pp, N_sampling = 1)
           
           set.seed(i*1000)
          nm_res2 <- nmANOVA1( m, pp, N_sampling = 1)
            p_value_h0[i] <- nm_res2$summary$p_value
          nm_res <- nm_res1$summary$p_value
          
          p_value_nm[i] <- nm_res
  }


          
ss1 <- sim_results

ks.test( p_value_h0, "punif", 0, 1 )

#save( p_value_h0, file = '1_prop_1000_p_valuesh0.RData' )
hist( p_value_h0)

hist( p_value_nm)


#for figure

library(dbplyr)
library(plyr)
library(tidyr)
library(dplyr)


load("/Users/amalyuti/Desktop/nmANOVA/unfix_seed_1000_prop_1000_delta_p_values.RData")
p_value_unfix <- p_value

load("/Users/amalyuti/Desktop/nmANOVA/fix_seed_1000_prop_1000_delta_p_values.RData")
delta <- seq( 0, 10, length.out = 1000 )

df <- data.frame( delta = rep( delta, 3 ), num = c( seq(1,1000, length.out = 1000), seq( 1100,2100, length.out = 1000),seq( 2200,3200, length.out = 1000) ) ,  group_num = c( rep( 1, 1000 ), rep( 2, 1000 ), rep( 3, 1000 ) ),  x = p_value )

df2 <- data.frame( delta = rep( delta, 3 ), num = c( seq(1,1000, length.out = 1000), seq( 1100,2100, length.out = 1000),seq( 2200,3200, length.out = 1000) ) ,  group_num = c( rep( 1, 1000 ), rep( 2, 1000 ), rep( 3, 1000 ) ),  x = p_value_unfix )

s <- 
  df %>%
  group_by( group_num ) %>%
  dplyr::summarise( mean = mean(x), median = median( x))
#f <- glm( x ~ num, data = df[1:1000,])
#summary(f)
#plot(f)


ggplot( df, aes( x =  num, y = ( log(x) ) ) ) +  
  
   geom_point( data = df2, aes( x =  num, y = ( log(x) ) ),  alpha = 0.05, size = 4, col = 'red')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 
   geom_line( alpha = 0.7,  size = 2, col = 'blue')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
#geom_point( alpha = 0.5, size = 3, col = 'red')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
   
  geom_segment( aes(x = 1, xend=200,  y = log( s$mean[1])), yend=log( s$mean[1]), size = 1) +
  geom_segment( aes(x = 1100, xend=1300,  y = log( s$mean[2])), yend=log( s$mean[2]), size = 1) +
  geom_segment( aes(x = 2200, xend=2400,  y = log( s$mean[3])), yend=log( s$mean[3]), size = 1) +
  
   geom_segment( aes(x = 400, xend=600,  y = log( s$median[1])), yend=log( s$median[1]), size = 1) +
  geom_segment( aes(x = 1500, xend=1700,  y = log( s$median[2])), yend=log( s$median[2]), size = 1) +
  geom_segment( aes(x = 2600, xend=2800,  y = log( s$median[3])), yend=log( s$median[3]), size = 1) +
  
scale_x_continuous(breaks=c(1, 1000, 1100, 2100, 2200,3200) ,
        labels=c("1",'10',  "1", "10", '1', '10')) +
  
  
  #geom_line( data = df2, aes( x =  num, y = ( log(x) ) ), alpha = 0.2,  size = 2, col = 'blue')  + #xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) + 
 
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ xlab( expression(delta) ) + ylab( "log(p-value)" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )  + theme(legend.position = "none")






load("/Users/amalyuti/Desktop/nmANOVA/1_prop_1000_p_valuesh0.RData")
 
df <- data.frame( x = p_value_h0 )

ggplot(df, aes(x=x))+
  geom_histogram(color="black", fill="lightblue", alpha = 0.6, bins = 50) + theme_bw()  + xlab( 'p-value' ) + ylab( "Count" ) + theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )  + theme(legend.position = "none") +  annotate("text", x=0.52, y=31, label= expression( paste( italic( "Kolmogorov-Smirnov test p-value = 0.5074" )  ) ), size = 7) 


```


4.1.1 with variance
```{r}



set.seed(411)

library( pheatmap )
#Example 1: uniform distribution, 3 clusters equal size

distribution <- 'uniform' #distribution for the simulation matrix
group_N <- c( 10, 10, 10 )#group sizes 
par_vec <- c( 0, 1 )# distribution parameters

#in case you want to introduce the difference - select some groups and change parameters in H1_group
#dist_par1 is a new parameter to use instead of par1 for the specified groups
#dist_par2 is a new parameter to use instead of par2 for the specified groups
#H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 20, 20 ), dist_par2 = c( 30, 30 ) )
  
#perform simulations and check distribution of p-values w
Nsim <- 1
p_value <- vector()
delta <- seq( 0, 10, length.out = 1000 )

i = 2000

for( i in 1:( 3*length( delta ) ) ){
  print(i)
  if ( i <= length( delta ) ){
    set.seed(411)
  H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 0 - delta[i], 0 - delta[i] ), dist_par2 = c( 1+ delta[i], 1 + delta[i] ) )
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value[i] <- sim_results[[1]]$summary$p_value 
  }
  
 if ( ( i > length( delta ) )  & ( i <= 2*length( delta ) ) ){
   set.seed(411)
    H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2', 'group1,group3', 'group3,group1'  ), dist_par1 = c( 0 - delta[i-length( delta )], 0 - delta[i-length( delta )],  0 - delta[i-length( delta )], 0 - delta[i-length( delta )] ), dist_par2 = c( 1 + delta[i-length( delta )], 1 + delta[i-length( delta )], 1 + delta[i-length( delta ) ], 1 + delta[i-length( delta )]  ) )
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value[i] <- sim_results[[1]]$summary$p_value 
    
    
  }
  
  if ( ( i > 2*length( delta ) )   ){
  #set.seed(411)
    H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2', 'group1,group3', 'group3,group1' ,  'group2,group3', 'group3,group2'  ), dist_par1 = c( 0 - delta[i-2*length( delta )], 0 - delta[i-2*length( delta )], 0 - delta[i-2*length( delta )], 0 - delta[i-2*length( delta )],  0 - delta[i-2*length( delta )], 0 - delta[i-2*length( delta )] ), dist_par2 = c( 1 + delta[i-2*length( delta )], 1 + delta[i-2*length( delta )], 1 + delta[i-2*length( delta ) ], 1 + delta[i-2*length( delta )], 1 + delta[i-2*length( delta )], 1 + delta[i-2*length( delta )]  ) )
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value[i] <- sim_results[[1]]$summary$p_value 
    
    
  }
  
  
}
p_value_unfix <- p_value
plot( log10( p_value ) )
#save( p_value_unfix, file = 'sd_based_unfix_100_prop_1000_delta_p_values.RData' )




load("/Users/amalyuti/Desktop/nmANOVA/sd_unfix_seed_1000_prop_1000_delta_p_values.RData")
p_value_unfix <- p_value

load("/Users/amalyuti/Desktop/nmANOVA/sd_fix_seed_1000_prop_1000_delta_p_values.RData")

df <- data.frame( delta = rep( delta, 3 ), num = c( seq(1,1000, length.out = 1000), seq( 1100,2100, length.out = 1000),seq( 2200,3200, length.out = 1000) ) ,  group_num = c( rep( 1, 1000 ), rep( 2, 1000 ), rep( 3, 1000 ) ),  x = p_value )

df2 <- data.frame( delta = rep( delta, 3 ), num = c( seq(1,1000, length.out = 1000), seq( 1100,2100, length.out = 1000),seq( 2200,3200, length.out = 1000) ) ,  group_num = c( rep( 1, 1000 ), rep( 2, 1000 ), rep( 3, 1000 ) ),  x = p_value_unfix )

s <- 
  df %>%
  group_by( group_num ) %>%
  dplyr::summarise( mean = mean(x), median = median( x))
#f <- glm( x ~ num, data = df[1:1000,])
#summary(f)
#plot(f)


ggplot( df, aes( x =  num, y = ( log(x) ) ) ) +  
  
   geom_point( data = df2, aes( x =  num, y = log( (x) ) ),  alpha = 0.05, size = 4, col = 'red')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 
   geom_line( alpha = 0.7,  size = 2, col = 'blue')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
#geom_point( alpha = 0.5, size = 3, col = 'red')  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
   
  geom_segment( aes(x = 200, xend=400,  y = log( s$mean[1])), yend=log( s$mean[1]), size = 1) +
  geom_segment( aes(x = 1300, xend=1500,  y = log( s$mean[2])), yend=log( s$mean[2]), size = 1) +
  geom_segment( aes(x = 2400, xend=2600,  y = log( s$mean[3])), yend=log( s$mean[3]), size = 1) +
  
   geom_segment( aes(x = 400, xend=600,  y = log( s$median[1])), yend=log( s$median[1]), size = 1) +
  geom_segment( aes(x = 1500, xend=1700,  y = log( s$median[2])), yend=log( s$median[2]), size = 1) +
  geom_segment( aes(x = 2600, xend=2800,  y = log( s$median[3])), yend=log( s$median[3]), size = 1) +
  
scale_x_continuous(breaks=c(1, 1000, 1100, 2100, 2200,3200) ,
        labels=c("1",'10',  "1", "10", '1', '10')) +
 # scale_y_continuous(breaks=c(1,0.8, 0.6, 0.4, 0.2,0.1) ) +
  
  
  #geom_line( data = df2, aes( x =  num, y = ( log(x) ) ), alpha = 0.2,  size = 2, col = 'blue')  + #xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) + 
 
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ xlab( expression(delta) ) + ylab( "log( p-value )" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )  + theme(legend.position = "none")




```


4.1.1 
```{r}


get.random.partition <- function( num_groups ){
  
   n1 <- vector()
  
    for( i in 1:num_groups ) {
        
      if ( i == 1 ){  
       
        n1[i] <- sample( 1:( 10 - num_groups + 1 ), 1 )
       
      }
        
       if ( i ==  num_groups ){    
        
         n1[i] <- 10 - sum( n1 )
      }
      
        
        if ( ( i !=  1 ) & ( i !=  num_groups )  ){    
        
         n1[i] <- sample( 1:( 10 - sum( n1 ) - num_groups + 2  ), 1 )
      }
      
    }
   
   n1
   
}

get.pval <- function( diss_mat, num_groups, N_s ){

  parts <- get.random.partition( num_groups )
  
  while( length( parts[ parts > 0 ] )!= num_groups  ) {
    
    parts <-get.random.partition( num_groups )
    
  }
  
  
  all_ind <- seq( 1:nrow( diss_mat ) )
  ind_list <- list()
  busy_ind <- vector()
  
  for( i in 1:length( parts ) ){
   
     ind_list[[i]] <- sample( setdiff( all_ind, busy_ind ) , floor( ( parts[i]/10 ) * nrow( diss_mat ) ) )
     busy_ind <- c( ind_list[[i]], busy_ind )
    
     }
  
  if( length( busy_ind ) != length( all_ind ) ){
    
    ind <- which( unlist( lapply( ind_list, length ) ) == min( unlist( lapply( ind_list, length ) ) ) )
    ind_list[[ ind[1] ]] <- c( ind_list[[ ind[1] ]], setdiff( all_ind, busy_ind ) )
  }
  
  partition <- rep( 'group_1', nrow( diss_mat ) ) 
  
  for( i in 1:length( ind_list ) ){
    
    partition[ ind_list[[i]] ] <- paste0( 'group_', i ) 
    
    
  }
    
  
  res <-list( nmANOVA( diss_mat, partition, N_s ), diss_mat )
  
}

library( pheatmap )
#Example 1: normal distribution, 5 clusters of different size, 50*50 matrix of dissimilarities

distribution <- 'normal' #distribution for the simulation matrix
group_N <- c( 5, 8, 10, 12, 15 )#group sizes 
par_vec <- c( 0, 1 )# distribution parameters

#in case you want to introduce the difference - select some groups and change parameters in H1_group
#dist_par1 is a new parameter to use instead of par1 for the specified groups
#dist_par2 is a new parameter to use instead of par2 for the specified groups
#H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 20, 20 ), dist_par2 = c( 30, 30 ) )
  
  H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2', 'group3,group1', 'group1,group3','group4,group1', 'group1,group4', 'group5,group1', 'group1,group5', 'group2,group3', 'group3,group2','group2,group4', 'group4,group2', 'group2,group5', 'group5,group2', 'group3,group4', 'group4,group3','group3,group5', 'group5,group3', 'group4,group5', 'group5,group4' ), dist_par1 = rep( 5, 20), dist_par2 = rep( 1, 20 ) )
  set.seed(411)
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value <- sim_results[[1]][[1]]$p_value   
  diss_mat <- sim_results[[2]]
  pheatmap( diss_mat, cluster_rows = FALSE,cluster_cols = FALSE  )
 
#save( diss_mat, file = 'diss_mat_411.RData')

load('diss_mat_411.RData'  )





N_sampl <- 1000     
df <- data.frame( N_sampl = rep( 1, ( length( group_N ) - 1 ) * N_sampl ),
                  group_N = rep( 1, ( length( group_N ) - 1 ) * N_sampl ),
                  groups_num = rep( 'a', ( length( group_N ) - 1 ) * N_sampl ),
                  SNM_w = rep( 'a', ( length( group_N ) - 1 ) * N_sampl ),
                  SNM_b = rep( 'a', ( length( group_N ) - 1 ) * N_sampl ),
                  F_val = rep( 1, ( length( group_N ) - 1 ) * N_sampl ),
                  p_value = rep( 1, ( length( group_N ) - 1 ) * N_sampl )
                  )
 k <- 0
for( i in 2:length( group_N ) ){
  for( j in 1:N_sampl ){
    set.seed( 411*i + 10*j )
    print(k)
    k <- k + 1
    r <- get.pval( diss_mat, i, 10 )
    df$N_sampl[ k ] <- j
    df$group_N[ k ] <- i
    df$groups_num[ k ] <- r[[1]]$summary$n_partition
    df$SNM_w[ k ] <- r[[1]]$summary$SNM_w
    df$SNM_b[ k ] <- r[[1]]$summary$SNM_b
    df$F_val[ k ] <- r[[1]]$summary$F_stat
    df$p_value[ k ] <- r[[1]]$summary$p_value

    
  }
  
  
}
  
 #save( df, file = 'df_Nsampl_10_Nsampling_1000_411.RData' )
  
  gr_p <- sim_results[[1]]$summary$p_value
  
 
 ggplot( df, aes( x = group_N , y = - log( p_value ) ) ) +  
   
geom_point( alpha = 0.3, size = 3, col = 'blue') + 
 geom_hline(yintercept = -log( gr_p ),  
                color = "red", size=1) +
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ ylab( '-log(p value)' ) + xlab( "Number of groups" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=20), legend.text=element_text(size=20) )  + theme(legend.position = "none") + 
 theme(legend.position = "none") +  annotate("text", x = 3, y = 11.5, label= expression( paste( italic( "p value for original matrix" )  ) ), size = 7)

 
```


4.1.1 version 2
```{r}


library( pheatmap )
#Example 1: normal distribution, 5 clusters of different size, 50*50 matrix of dissimilarities

distribution <- 'normal' #distribution for the simulation matrix
group_N <- c( 5, 8, 10, 12, 15 )#group sizes 
par_vec <- c( 0, 1 )# distribution parameters

#in case you want to introduce the difference - select some groups and change parameters in H1_group
#dist_par1 is a new parameter to use instead of par1 for the specified groups
#dist_par2 is a new parameter to use instead of par2 for the specified groups
#H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 20, 20 ), dist_par2 = c( 30, 30 ) )
  
  H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2', 'group3,group1', 'group1,group3','group4,group1', 'group1,group4', 'group5,group1', 'group1,group5', 'group2,group3', 'group3,group2','group2,group4', 'group4,group2', 'group2,group5', 'group5,group2', 'group3,group4', 'group4,group3','group3,group5', 'group5,group3', 'group4,group5', 'group5,group4' ), dist_par1 = rep( 5, 20), dist_par2 = rep( 1, 20 ) )
  set.seed(411)
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value <- sim_results[[1]]$summary$p_value   
  diss_mat <- sim_results[[2]]
 # pheatmap( diss_mat, cluster_rows = FALSE,cluster_cols = FALSE  )
 
#save( diss_mat, file = 'diss_mat_411.RData')

#load('diss_mat_411.RData'  )

partition <- c( rep( 'group_1' ,group_N[1] ), rep( 'group_2' ,group_N[2] ),  rep( 'group_3' ,group_N[3] ),  rep( 'group_4' ,group_N[4] ),  rep( 'group_5' ,group_N[5] ) )



N_sampl <- 100    
t <- 20
df <- data.frame( N_sampl = nrow( diss_mat ) * N_sampl ,
                  num_change = rep( 1, t * N_sampl ),
                  SNM_w = rep( 'a', t * N_sampl ),
                  SNM_b = rep( 'a', t * N_sampl ),
                  F_val = rep( 1,  t * N_sampl ),
                  p_value = rep( 1, t * N_sampl ), 
                  part = rep( 'a',  t * N_sampl )
                  )

 k <- 1800
 
 set.seed(NULL)
 
for( i in 19:t ){
  
  df_change <- data.frame( N_sampl = rep( 1,  N_sampl ), 
                           partition = rep( 'a',  N_sampl ) )
  j <- 1
  while( j <= N_sampl ){
    
    print(k)
    
    
    available_partitions <- seq( 1:length( partition ) )
    ind1 <- vector()
    ind2 <- vector()
      
    
    
    for( m in 1:i ) {
   
      pp <- 1
      while( pp > 0 ) {
      
      ind1[m] <- sample(  available_partitions , 1 )
      ind2[m] <- sample(  available_partitions , 1 )
      
    
      if ( partition[ind1[m]] != partition[ind2[m]]) {
      available_partitions <- setdiff( available_partitions, c( ind1[m], ind2[m] ) )
      pp  <- 0 
      
      }
     
      }
      
    }
    
    partition_new <- partition
    partition_new[ind1] <- partition[ind2]
    partition_new[ind2] <- partition[ind1]
    

   df_change$N_sampl[j] <- j
   df_change$partition[j] <- paste0(partition_new, collapse = ',' )
    
    num <- ifelse( j == N_sampl, 0, 1 ) 
   if ( length( unique( df_change$partition ) ) != ( num + j ) ){
    j <- j 
     
   }else{ 
     
     
    
     k <- k + 1
   
     r <- nmANOVA( diss_mat, partition_new,N_sampling= 100 )
      
   
    df$N_sampl[ k ] <- j
    df$num_change[ k ] <- i
    df$part[ k ] <-  paste0(partition_new, collapse = ',' )
    df$SNM_w[ k ] <- r$summary$SNM_w
    df$SNM_b[ k ] <- r$summary$SNM_b
    df$F_val[ k ] <- r$summary$F_stat
    df$p_value[ k ] <- r$summary$p_value

     j <- j+ 1
  }
  
  
  } 
}
 
ind <- which(df$part == paste0( partition, collapse = ',' ) )


gg <- 
  df %>%
  group_by(num_change )%>%
  dplyr::summarise( mean = mean( p_value), min = min(p_value ), max = max(p_value), med = median(p_value) )

d <- data.frame( num_change = 0, mean = ( p_value), min = (p_value ), max = (p_value), med = (p_value))

gg <- rbind( d, gg)


ggplot( df, aes(   x =  num_change, y = -log(p_value) ) ) +  
  
geom_point( alpha = 0.3, size = 3, col = 'blue') + 
   #geom_line(data=gg)+
  # geom_ribbon(data=gg,aes(ymin=-log( min ),ymax=-log( max)),alpha=0.1) +
  geom_line(data=gg,aes( num_change, -log( mean )),col = 'black', size = 1, alpha = 0.5) +
  geom_point(data=gg,aes( num_change, -log(mean)),col = 'red', size =5) +
 
 #geom_vline(xintercept =log(p_value),  
              # color = "red", size=1) +
  
  scale_x_continuous(breaks=c(0,  5, 10, 15,20) ,
        labels=c("0",  "5", "10", '15', '20')) +
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ ylab( '-log(p value)' ) + xlab( "Number of element pairs switched" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=20), legend.text=element_text(size=20) )  + theme(legend.position = "none") + 
 theme(legend.position = "none")# +  annotate("text", x = 3, y = 11.5, label= expression( paste( italic( "p value for original matrix" )  ) ), size = 7)

  
ggplot( df, aes(   x =  num_change, y = (p_value) ) ) +  
  
geom_point( alpha = 0.3, size = 3, col = 'blue') + 
   #geom_line(data=gg)+
  # geom_ribbon(data=gg,aes(ymin=-log( min ),ymax=-log( max)),alpha=0.1) +
  geom_line(data=gg,aes( num_change, ( mean )),col = 'black', size = 1, alpha = 0.5) +
  geom_point(data=gg,aes( num_change, (mean)),col = 'red', size =5) +
 
 #geom_vline(xintercept =log(p_value),  
              # color = "red", size=1) +
  
  scale_x_continuous(breaks=c(0,  5, 10, 15,20) ,
        labels=c("0",  "5", "10", '15', '20')) +
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ ylab( 'p value' ) + xlab( "Number of element pairs switched" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=20), legend.text=element_text(size=20) )  + theme(legend.position = "none") + 
 theme(legend.position = "none")# +  annotate("text", x = 3, y = 11.5, label= expression( paste( italic( "p value for original matrix" )  ) ), size = 7
 
#save( df, file = 'df_Nsampl_10_Nsampling_1000_411.RData' )
  
load("/Users/amalyuti/Desktop/nmANOVA/5000_df_csc_p_value/diss_mat_rib.RData")

sim_results <- nmANOVA(diss_mat, partition, 200 )
  p_value <- sim_results$summary$p_value   



setwd( '~/Desktop/nmANOVA/3000_df_csc_p_value' )
file_names <- as.list( dir( pattern="nm*" ) )

missing_numbers <-  setdiff( seq(1:25),as.numeric( gsub("\\..*","", str_extract(file_names, "[^_]*$") ) ) ) 

res <- list()

for( i in 1:length( file_names ) ) {
  
  load( file_names[[i]] ) 
  res[[i]] <- df
  
}

df<- ldply( res, as.data.frame )


ind <- which(df$part == paste0( partition, collapse = ',' ) )
df2 <- df[-ind, ]

df2 <- 
  df2 %>%
  group_by( num_change, part)%>%
  dplyr::summarise(   p_value = mean( p_value) )

g <- 
  df2%>%
  group_by( num_change )%>%
  dplyr::summarise( n = n())
 

gg <- 
  df2 %>%
  group_by(num_change )%>%
  dplyr::summarise( mean = mean( p_value), min = min(p_value ), max = max(p_value), med = median(p_value) )

d <- data.frame( num_change = 0, mean = ( p_value), min = (p_value ), max = (p_value), med = (p_value))

gg <- rbind( d, gg)

df2 <- as.data.frame( df2)

ggplot( df2, aes(   x =  num_change, y = (p_value ) ) ) +  
  
#geom_point( alpha = 0.3, size = 3, col = 'blue') + 
   #geom_line(data=gg)+
  # geom_ribbon(data=gg,aes(ymin=-log( min ),ymax=-log( max)),alpha=0.1) +
   geom_boxplot( aes(group = num_change), col = '#3399FF', fill = '#3399FF', alpha = 0.1 )+
  geom_line(data=gg ,aes( num_change, ( med )),col = 'black', size = 1, alpha = 0.7) +
  geom_point(data=gg,aes( num_change, (med)),col = '#FF6666', size =5) +

 #geom_vline(xintercept =log(p_value),  
              # color = "red", size=1) +
  
  scale_x_continuous(breaks=c(0,  5, 10, 15,20, 25) ,
        labels=c("0",  "5", "10", '15', '20', '25')) +
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ ylab( 'p-value' ) + xlab( "Number of pairs switched" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )  + theme(legend.position = "none") + 
 theme(legend.position = "none")# +  annotate("text", x = 3, y = 11.5, label= expression( paste( italic( "p value for original matrix" )  ) ), size = 7
 





```
BEST CLUSTERING
Supplementary Figure 5

```{r}


#library( pheatmap )
#Example 1: normal distribution, 5 clusters of different size, 50*50 matrix of dissimilarities

distribution <- 'normal' #distribution for the simulation matrix
group_N <- c( 13, 21, 34, 55 )#group sizes 
par_vec <- c( 0, 1 )# distribution parameters

#in case you want to introduce the difference - select some groups and change parameters in H1_group
#dist_par1 is a new parameter to use instead of par1 for the specified groups
#dist_par2 is a new parameter to use instead of par2 for the specified groups
#H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 20, 20 ), dist_par2 = c( 30, 30 ) )
  
  H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2', 'group3,group1', 'group1,group3','group4,group1', 'group1,group4', 'group2,group3', 'group3,group2','group2,group4', 'group4,group2', 'group3,group4', 'group4,group3' ), dist_par1 = rep( 5, 12), dist_par2 = rep( 1,12 ) )
  set.seed(411)
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value <- sim_results[[1]]$summary$p_value   
  diss_mat <- sim_results[[2]]
  pheatmap( diss_mat, cluster_rows = FALSE,cluster_cols = FALSE  )
 
#save( diss_mat, file = 'clust_diss_mat.RData')

load('clust_diss_mat.RData'  )

partition <- c( rep( 'group_1' ,group_N[1] ), rep( 'group_2' ,group_N[2] ),  rep( 'group_3' ,group_N[3] ),  rep( 'group_4' ,group_N[4] ) )


### from here




#load('clust_diss_mat.RData'  )


load( "/projappl/project_2000774/drda_benchmark/clust_diss_mat.RData")
str(diss_mat)

i_num <-
  seq( 1:61 )

part_num <- c( 3, 4, 5)

par_set <- 
  
  crossing( i_num, part_num )

#save( par_set, file = 'par_set.RData')

ii <- 5

i <- par_set$i_num[ii]
part_num <- par_set$part_num[ii]

1

N_sampl <- 10    
t <- 1
df <- data.frame( N_sampl = rep( 1, t * N_sampl ) ,
                  num_change = rep( 1, t * N_sampl ),
                  SNM_w = rep( 1, t * N_sampl ),
                  SNM_b = rep( 1, t * N_sampl ),
                  F_val = rep( 1,  t * N_sampl ),
                  p_value = rep( 1, t * N_sampl ), 
                  part = as.character( rep( 'a', t * N_sampl ) )
                  )
df$part <- as.character( df$part)
 k <- 0
 
 set.seed(NULL)
 

  df_change <- data.frame( N_sampl = rep( 1,  N_sampl ), 
                           partition = rep( 'a',  N_sampl ) )
  j <- 1
  while( j <= N_sampl ){
    
    print(k)
    
    
    available_partitions <- seq( 1:length( partition ) )
    ind1 <- vector()
    ind2 <- vector()
      
    
    
    for( m in 1:i ) {
   
     
      
      
      ind1[m] <- sample(  available_partitions , 1 )
      ind2[m] <- sample(  available_partitions , 1 )
      
    
      
      available_partitions <- setdiff( available_partitions, c( ind1[m], ind2[m] ) )
      
      
    }
    
    partition_new <- partition
    partition_new[ind1] <- partition[ind2]
    partition_new[ind2] <- partition[ind1]
    

   df_change$N_sampl[j] <- j
   df_change$partition[j] <- paste0(partition_new, collapse = ',' )
    
    
     k <- k + 1
   
     r <- nmANOVA( diss_mat, partition_new,N_sampling = 200 )
      
   
    df$N_sampl[ k ] <- j
    df$num_change[ k ] <- i
    df$part[ k ] <-  paste0(partition_new, collapse = ',' )
    df$SNM_w[ k ] <- r$summary$SNM_w
    df$SNM_b[ k ] <- r$summary$SNM_b
    df$F_val[ k ] <- r$summary$F_stat
    df$p_value[ k ] <- r$summary$p_value

     j <- j+ 1
  
  
  
  
}
 

  df$N_sampl[ k + 1 ] <- 0
    df$num_change[ k + 1  ] <- 0
    df$part[ k + 1] <-  partition

    r <- nmANOVA( diss_mat, partition, N_sampling = 1 )
    df$SNM_w[ k  + 1] <- r$summary$SNM_w
    df$SNM_b[ k + 1] <- r$summary$SNM_b
    df$F_val[ k + 1] <- r$summary$F_stat
    df$p_value[ k + 1 ] <- r$summary$p_value



dataDir <-"/projappl/project_2000774/drda_benchmark/A_results/"
save( df, file = paste( dataDir, paste( 'clust_nm_df',as.numeric( i ), sep = '_'), ".RData", sep = '' ) )










#####################################
#for plot

multiplot_list <- function( plotlist, cols) {
    require(grid)

    # Make a list from the ... arguments and plotlist
    plots <-plotlist

    numPlots = length(plots)

    # Make the panel
    plotCols = cols                          # Number of columns of plots
    plotRows = ceiling(numPlots/plotCols) # Number of rows needed, calculated from # of cols

    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(plotRows, plotCols)))
    vplayout <- function(x, y)
        viewport(layout.pos.row = x, layout.pos.col = y)

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
        curRow = ceiling(i/plotCols)
        curCol = (i-1) %% plotCols + 1
        print(plots[[i]], vp = vplayout(curRow, curCol ))
    }

}


library( stringr )
library( dplyr )
library( plyr )
library(ggplot2)

load("/Users/amalyuti/Desktop/nmANOVA/par_set.RData")


setwd( '~/Desktop/nmANOVA/clust' )
file_names <- as.list( dir( pattern="200N*" ) )

par_set  <- 
  par_set %>%
  mutate( num = seq( 1:nrow( par_set ) ) )

par_set$num <- as.character( par_set$num )
par_set  <-  
  par_set %>%
  arrange( num )


res <- list()

for( i in 1:length( file_names ) ) {
  
  load( file_names[[i]] ) 
  res[[i]] <- df
  
  ind <- which( par_set$num == sub("\\.RData.*", "",  sub('.*\\_', '',file_names[[i]] ) ) )
  res[[i]] <- 
    res[[i]] %>% 
    mutate( clust_num = par_set$part_num[ind]  ) 
  
}



df<- ldply( res, as.data.frame )
plot_list <- list()
df_list  <- list()
gg_list  <- list()

for( i in 3:5 ){
  
df2 <- 
  df %>%
  filter( clust_num == i )
  

if( i == 3 )
  partition <- c( rep( 'group_1' ,34 ), rep( 'group_2' ,34 ),  rep( 'group_3' ,55 ) )

if( i == 4 )
  partition <- c( rep( 'group_1' ,13 ), rep( 'group_2' ,21),  rep( 'group_3' ,34 ), rep( 'group_4' ,55 ) )
  #partition <- c( rep( 'group_1' ,21 ), rep( 'group_2' ,34),  rep( 'group_3' ,55 ), rep( 'group_4' ,89 ) )


if( i == 5 )
  partition <- c( rep( 'group_1', 13 ), rep( 'group_2' ,21 ), rep( 'group_3' ,34),  rep( 'group_4' ,21 ), rep( 'group_5' ,34 ) )


  indi <- which( ( df2$N_sampl == 0 ) &  ( df2$num_change == 0 ) )
  
  df2_null <-
    df2 %>%
    filter( N_sampl == 0, num_change == 0   )
  p_value <-  median( df2_null$p_value )

  
  print( length( unique( df2_null$part ) ) )
  
  d <- data.frame( num_change = 0, mean = ( p_value), min = (p_value ), max = (p_value), med = (p_value))

ind <- which(df2$part == paste0( partition, collapse = ',' ) )
df2 <- df2[-ind, ]


df2 <- 
  df2 %>%
  filter( N_sampl != 0, num_change != 0   )%>%
  group_by( num_change, part)%>%
  dplyr::summarise(   p_value = mean( p_value) )


 

d <- data.frame( num_change = 0, mean = ( p_value), min = (p_value ), max = (p_value), med = (p_value))

gg <- 
  df2 %>%
  group_by(num_change )%>%
  dplyr::summarise( mean = mean( p_value), min = min(p_value ), max = max(p_value), med = median(p_value) )

gg <- rbind( d, gg)

df_list[[i-1]]  <-
  df2 %>%
  mutate( clust_num =  i )

gg_list[[i-1]] <- 
  gg %>%
  mutate( clust_num =  i )  


plot_list[[i-1]]  <- ggplot( df2, aes(   x =  ( num_change ), y = (p_value ) ) ) +  
  
#geom_point( alpha = 0.3, size = 3, col = 'blue') + 
   #geom_line(data=gg)+
  # geom_ribbon(data=gg,aes(ymin=-log( min ),ymax=-log( max)),alpha=0.1) +
   geom_boxplot( aes(group = ( num_change )), col = '#3399FF', fill = '#3399FF', alpha = 0.1 )+
  geom_line(data=gg ,aes( ( num_change ), ( med )),col = 'black', size = 1, alpha = 0.7) +
  geom_point(data=gg,aes( ( num_change ), (med)),col = '#FF6666', size =2) +

 #geom_vline(xintercept =log(p_value),  
              # color = "red", size=1) +
  
 scale_x_continuous(breaks=c(0,  10,  30, 50) ,
        labels=c('0',  '10',  '30', '50' ) ) + ylim( 0,1 ) +
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ ylab( 'p-value' ) + xlab( "Number of pairs switched" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=20), axis.text.y = element_text(angle = 0, hjust = 1, size = 20), legend.title=element_text(size=25), legend.text=element_text(size=20) )  + theme(legend.position = "none") +theme(axis.title=element_blank() )# +  annotate("text", x = 3, y = 11.5, label= expression( paste( italic( "p value for original matrix" )  ) ), size = 7
 

}




#another version of plot
df_all <- ldply( df_list, as.data.frame )
gg_all <- ldply( gg_list, as.data.frame )

df_all <- 
  df_all %>%
  mutate( hist_factor = paste( num_change, clust_num, sep = '_' ) )

 ggplot( df_all, aes(   x =  ( num_change ), y = (p_value ), col = as.factor( clust_num ) ) ) +  
  
#geom_point( alpha = 0.3, size = 3, col = 'blue') + 
   #geom_line(data=gg)+
   geom_ribbon(data=gg_all,aes(ymin=( min ),ymax= max, fill =as.factor( clust_num )) ,alpha=0.1, colour = NA ) +
 # geom_boxplot( aes(group = as.factor( hist_factor ),  fill =  as.factor( clust_num ), col = as.factor( clust_num ) ), alpha = 0.01 )+
 # geom_point(aes( group = as.factor( hist_factor ), col = as.factor( clust_num ), group = as.factor( clust_num ) ), size =1, alpha = 0.04) +
  geom_line(data=gg_all ,aes( ( num_change ), ( med ), col = as.factor( clust_num ), group = as.factor( clust_num ) ), size = 1, alpha = 0.7) +
  geom_point(data=gg_all,aes( ( num_change ), (med), col = as.factor( clust_num ), group = as.factor( clust_num ) ), size =1.4) +
  

 #geom_vline(xintercept =log(p_value),  
              # color = "red", size=1) +
  
 scale_x_continuous(breaks=c(0,  10,  30, 60 ) ,
        labels=c('0',  '10',  '30',  '60' ) ) + ylim( 0,1 ) +
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ ylab( 'p-value' ) + xlab( "Number of pairs switched" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 20), axis.title=element_text(size=20), axis.text.y = element_text(angle = 0, hjust = 1, size = 20), legend.title=element_text(size=20), legend.text=element_text(size=20) ) # + theme(legend.position = "none") #+theme(axis.title=element_blank() )# +  annotate("text", x = 3, y = 11.5, label= expression( paste( italic( "p value for original matrix" )  ) ), size = 7
 




```



DrugComb functions
```{r}

get_syn_from_single <- function( df, study_name_s, cell_line_name_s, ri ){
  
      #ri$drug_name <- toupper( ri$drug_name )
      
       m <- 
         df %>%
         #filter( study_name == study_name_s )%>%
         filter( cell_line_name == cell_line_name_s ) %>%
         dplyr::select(  contains( '_row'), contains( '_col' ), contains('ri') ) %>%
         dplyr::select( contains( 'css' ), everything( ) ) 
       
       df_stat <- 
        m %>%
        dplyr::select( drug_row, drug_col, contains( 'css' ) ) %>%
        group_by( drug_col, drug_row ) %>%
        dplyr::summarise_all( 'mean' ) 
       
      all_drugs <- unique( c( df_stat$drug_col, df_stat$drug_row ) )
      
      dc_df <- as.data.frame( matrix( NA, ncol = length( all_drugs ), nrow = length( all_drugs ) ) )
      rownames( dc_df ) <-  as.vector( sort( all_drugs ) )
      colnames( dc_df ) <-  as.vector( sort( all_drugs ) ) 
      sum( rownames( dc_df ) == colnames( dc_df ) )
      
      
      
      for( i in 1:nrow( df_stat ) ) {
        
        dr_col <- df_stat$drug_col[i]
        dr_row <- df_stat$drug_row[i]
        ind_row <- which( rownames( dc_df ) == dr_row )
        ind_col <- which( colnames( dc_df ) == dr_col )
        
        
        ri_row <- 
          ri %>%
          filter( cell_line == cell_line_name_s, drug_name == dr_row )
       
        ri_col <- 
          ri %>%
          filter( cell_line == cell_line_name_s, drug_name == dr_col )
       if(dr_col == 'ss5-FU' | dr_row == 'ss5-FU'){
        str(ri_row)
       print(dr_row)
       print( df_stat$css_row[i] )
       str(ri_col)
        print( dr_col )
        print(df_stat$css_col[i])}
       
        dc_df[ ind_row, ind_col ] <- df_stat$css_row[i] - ri_row$ri[1]
        dc_df[ ind_col, ind_row ] <- df_stat$css_col[i] - ri_col$ri[1]
      
      }
      
      max( as.matrix( dc_df ), na.rm = TRUE )
      min( as.matrix( dc_df ), na.rm = TRUE )
      
     print( sum( is.na( dc_df) ) - length( all_drugs )  )
    
   
         dc_df 
        
  
}


get_syn_from_dc <- function( df, study_name_s, cell_line_name_s ){
  
  
       m <- 
         df %>%
         filter( study_name == study_name_s )%>%
         filter( cell_line_name == cell_line_name_s ) %>%
         dplyr::select(  contains( '_row'), contains( '_col' ), contains('ri') ) %>%
         dplyr::select( contains( 'css' ), everything( ) ) 
       
       df_stat <- 
        m %>%
        dplyr::select( drug_row, drug_col, contains( 'css' ) ) %>%
        group_by( drug_col, drug_row ) %>%
        dplyr::summarise_all( 'mean' ) 
       
      all_drugs <- unique( c( df_stat$drug_col, df_stat$drug_row ) )
      
      dc_df <- as.data.frame( matrix( NA, ncol = length( all_drugs ), nrow = length( all_drugs ) ) )
      rownames( dc_df ) <-  as.vector( sort( all_drugs ) )
      colnames( dc_df ) <-  as.vector( sort( all_drugs ) ) 
      sum( rownames( dc_df ) == colnames( dc_df ) )
      
      
      
      for( i in 1:nrow( df_stat ) ) {
        
        dr_col <- df_stat$drug_col[i]
        dr_row <- df_stat$drug_row[i]
        ind_row <- which( rownames( dc_df ) == dr_row )
        ind_col <- which( colnames( dc_df ) == dr_col )
        dc_df[ ind_row, ind_col ] <- df_stat$css_row[i] - df_stat$css_ri[i]
        dc_df[ ind_col, ind_row ] <- df_stat$css_col[i] - df_stat$css_ri[i]
      
      }
      
      max( as.matrix( dc_df ), na.rm = TRUE )
      min( as.matrix( dc_df ), na.rm = TRUE )
      
     print( sum( is.na( dc_df) ) - length( all_drugs )  )
    
   
         dc_df 
        
  
}


get_df_from_dc <- function( df, study_name_s, cell_line_name_s ){
  
  
       m <- 
         df %>%
         #filter( study_name == study_name_s )%>%
         filter( cell_line_name == cell_line_name_s ) %>%
         dplyr::select( contains( '_row'), contains( '_col' ) ) %>%
         dplyr::select( contains( 'css' ), everything( ) ) 
       
       df_stat <- 
        m %>%
        dplyr::select( drug_row, drug_col, contains( 'css' ) ) %>%
        group_by( drug_col, drug_row ) %>%
        dplyr::summarise_all( 'mean' )
       
      all_drugs <- unique( c( df_stat$drug_col, df_stat$drug_row ) )
      
      dc_df <- as.data.frame( matrix( NA, ncol = length( all_drugs ), nrow = length( all_drugs ) ) )
      rownames( dc_df ) <-  as.vector( sort( all_drugs ) )
      colnames( dc_df ) <-  as.vector( sort( all_drugs ) ) 
      sum( rownames( dc_df ) == colnames( dc_df ) )
      
      
      
      for( i in 1:nrow( df_stat ) ) {
        
        dr_col <- df_stat$drug_col[i]
        dr_row <- df_stat$drug_row[i]
        ind_row <- which( rownames( dc_df ) == dr_row )
        ind_col <- which( colnames( dc_df ) == dr_col )
        dc_df[ ind_row, ind_col ] <- df_stat$css_row[i]
        dc_df[ ind_col, ind_row ] <- df_stat$css_col[i]
      
      }
      
      max( as.matrix( dc_df ), na.rm = TRUE )
      min( as.matrix( dc_df ), na.rm = TRUE )
      
     print( sum( is.na( dc_df) ) - length( all_drugs )  )
    
   
         dc_df 
        
  
}
```

DrugComb
```{r}


dc <- read.csv("~/Desktop/nmANOVA/drugComb.csv", header = TRUE)

stat0 <- 
  dc %>%
  filter( is.na( drug_col) ) %>%
  group_by( cell_line_name, study_name )%>%
  dplyr::summarise( n = n())

stat00 <- 
  dc %>%
  filter( !is.na( drug_col) ) %>%
  group_by( cell_line_name, study_name )%>%
  dplyr::summarise( n = n())

stat000 <- 
  stat0 %>%
  left_join( stat00, by = c( 'cell_line_name', 'study_name' ) )

stat <- 
  dc %>%
  group_by( study_name, cell_line_name )%>%
  dplyr::summarise( n = n() )%>%
  ungroup()

stat2 <- 
  dc %>%
  filter( abs( css_ri - css_col ) >5 )%>%
  group_by( study_name, cell_line_name )%>%
  dplyr::summarise( n_ri = n() )%>%
  ungroup()

stat3 <- 
  stat2 %>%
  left_join( stat, by = c( 'study_name', 'cell_line_name' ) )%>%
  mutate( diff = abs( n_ri - n ) )%>%
  filter( n >1000)




pp <- dc%>%filter( study_name == 'ALMANAC')
c <- unique( pp$cell_line_name )
for( i in 1:length( c ) ){
cl <- c[i]

df <- get_df_from_dc( dc, 'ONEIL', 'SKMES1' )
colnames( df )[1] <- 'long'
rownames( df )[1] <- 'long'
df_plot <- 
  df %>%
  dplyr::select( ind, everything() )

df_plot <- as.data.frame( t( df_plot ) )

df_plot <- 
  df_plot %>%
  dplyr::select( ind, everything() )
pheatmap( df_plot, cluster_cols = FALSE, cluster_rows = FALSE, main = paste0( cl ) ) 
}

df <- get_df_from_dc( dc, 'ALMANAC', 'NCI-H460' )
colnames( df )[1] <- 'long'
rownames( df )[1] <- 'long'

df_plot <- 
  df %>%
  dplyr::select( ind, everything() )

df_plot <- as.data.frame( t( df_plot ) )

df_plot <- 
  df_plot %>%
  dplyr::select( ind, everything() )
pheatmap( df_plot, cluster_cols = FALSE, cluster_rows = FALSE, main = paste0( cl ) ) 


partition <- rep( 'group1', nrow( df ) )

ind <- which( rownames( df ) %in% c( 'DINACICLIB', 'SORAFENIB', 'SUNITINIB', 'VINBLASTINE', 'VINORELBINE' ) )
#ind <- which( rownames( df2 ) %in% c( 'MK-4827', 'MK-8776', 'MK-8669', 'MK-5108', 'MK-2206', 'MK-4541' ) )
partition[ ind ] <- 'group2' 
res <- nmANOVA( abs( df ), partition, 10)
View(res$summary)


df2 <- get_syn_from_dc( dc, 'ONEIL', 'SKMES1' ) #dld1 could work

pheatmap( df2, cluster_cols = FALSE, cluster_rows = FALSE )


df2_plot <- 
  df2 %>%
  dplyr::select( ind, everything() )

df2_plot <- as.data.frame( t( df2_plot ) )

df2_plot <- 
  df2_plot %>%
  dplyr::select( ind, everything() )
pheatmap( df2_plot, cluster_cols = FALSE, cluster_rows = FALSE )

partition <- rep( 'group1', nrow( df2 ) )

ind <- which( rownames( df2 ) %in% c( 'DINACICLIB', 'SORAFENIB', 'SUNITINIB', 'VINBLASTINE', 'VINORELBINE' ) )
#ind <- which( rownames( df2 ) %in% c( 'MK-4827', 'MK-8776', 'MK-8669', 'MK-5108', 'MK-2206', 'MK-4541' ) )
partition[ ind ] <- 'group2' 
res <- nmANOVA( abs( df2 ), partition, 10)
View(res$summary)
sum(is.na( df2))
 



pp <- dc%>%filter( study_name == 'ONEIL')
c <- unique( pp$cell_line_name )
cl <- c[22]
print(cl)
df3 <- get_syn_from_single( dc, 'ONEIL', cl, ri_oneil ) #dld1 could work
sum(is.na( df3))
df3_plot <- 
  df3 %>%
  dplyr::select( ind, everything() )

df3_plot <- as.data.frame( t( df3_plot ) )

df3_plot <- 
  df3_plot %>%
  dplyr::select( ind, everything() )
pheatmap( df3_plot, cluster_cols = FALSE, cluster_rows = FALSE )


partition <- rep( 'group1', nrow( df3 ) )

ind <- which( rownames( df3 ) %in% c( 'SUNITINIB', 'SORAFENIB' ) )
#SKMES1:ind <- which( rownames( df3 ) %in% c( 'DINACICLIB', 'SORAFENIB', 'SUNITINIB', 'VINBLASTINE', 'VINORELBINE' ) )
#ind <- which( rownames( df2 ) %in% c( 'MK-4827', 'MK-8776', 'MK-8669', 'MK-5108', 'MK-2206', 'MK-4541' ) )
partition[ ind ] <- 'group2' 
res <- nmANOVA( abs( df3 ), partition, 10)
res <- nmANOVA( ( df3 ), partition, 10)
View(res$summary)










df2 <- get_syn_from_dc( dc, 'ONEIL', 'ZR751' )
#colnames( df2 )[1] <- 'long'
#rownames( df2 )[1] <- 'long'
pheatmap( df2, cluster_cols = FALSE, cluster_rows = FALSE )


partition <- rep( 'group1', nrow( df2 ) )

df2_plot <- 
  df2 %>%
  dplyr::select( ind, everything() )

df2_plot <- as.data.frame( t( df2_plot ) )

df2_plot <- 
  df2_plot %>%
  dplyr::select( ind, everything() )
pheatmap( df2_plot, cluster_cols = FALSE, cluster_rows = FALSE )

ind <- which( rownames( df2 ) %in% c( 'DINACICLIB', 'SORAFENIB', 'SUNITINIB', 'VINBLASTINE', 'VINORELBINE' ) )
#ind <- which( rownames( df2 ) %in% c( 'MK-4827', 'MK-8776', 'MK-8669', 'MK-5108', 'MK-2206', 'MK-4541' ) )
partition[ ind ] <- 'group2' 
res <- nmANOVA( abs( df2 ), partition, 10)
View(res$summary)


d <- 
  dc %>%
  filter( study_name == 'ONEIL' , cell_line_name == 'SKMES1')%>%
  mutate( diff = abs( css_row - css_ri )  )%>%
  filter( diff >10)


drug_info <-
  dc %>%
  filter( study_name == 'ALMANAC')%>%
  dplyr::select( contains('drug') )%>%
  dplyr::select( contains( 'row'))%>%
  distinct()

save(drug_info, file = 'drug_info.RData')
  

```

drug table
```{r}
library(readxl)
FIMM_compounds_set1 <- read_excel("~/Desktop/proteasome_inhibitor_MM/FMO6/FIMM_compounds_set1.xlsx")
all_drugs <- union( unique( oneil$drug_row ), unique( oneil$drug_col ) )

ind1 <- which( toupper( FIMM_compounds_set1$`Preferred name` ) %in% toupper( all_drugs ) )
ind2 <- which( FIMM_compounds_set1$`Non-proprietary name` %in% all_drugs )
ind <- union( ind1,ind2 )


drug_groups <- read_excel("~/Desktop/nmANOVA/drug_groups.xlsx")
ind11 <- which( toupper( FIMM_compounds_set1$`Preferred name` ) %in% toupper( drug_groups$Drug ) )

ind <- union(ind1, ind11)

table <- 
  FIMM_compounds_set1[ind, ] %>%
  dplyr::select( `Preferred name`, `Mechanism/Targets`, Class, `Class explained` , `Primary_target` )%>%
  dplyr::select( Drug = `Preferred name`, `Mechanism/Targets`,`Class explained` , `Primary_target` )%>%
  mutate( Drug = toupper( Drug ) ) 
  

write.xlsx( table, file = 'collect_drug_info.xlsx')

setdiff( toupper( all_drugs), toupper(table$Drug  ))
 t <- read_excel("~/Desktop/nmANOVA/collect_drug_info.xlsx")
 t <- 
   t %>%
   arrange( Drug)

```




```{r}
library(openxlsx)
library(plyr)
library(reshape2)

#oneil = read.xlsx("summary_table_ONEIL.xlsx")
all_cl <- unique( oneil$cell_line_name )

#cur_cl <- 'LOVO'
all_res <- list()
k <- 0
for (ii in 1:length( all_cl ) ){
 

#for( j in 1:4){
   k <- k+1
        cur_cl <- all_cl[ii]
        # A2058 cell line
        oneil_a2058 = oneil[oneil$cell_line_name==cur_cl,]
       #A_oneil_a2058_single <- 
       # oneil_a2058 %>%
       #  group_by( drug_row,drug_col )%>%
       #  dplyr::slice(j)
  
        A_oneil_a2058_single <- oneil_a2058 
        oneil_a2058_single = ddply(A_oneil_a2058_single, .(drug_row,drug_col), summarise, 
                                   css_row = mean(css_row), css_col = mean(css_col),
                                   ri_row = mean(ri_row), ri_col = mean(ri_col))
        # combo
        oneil_a2058_1 = oneil_a2058_single[,c('drug_row','drug_col','css_row')]
        oneil_a2058_2 = oneil_a2058_single[,c('drug_col','drug_row','css_col')]
        # single drug
        oneil_a2058_3 = oneil_a2058_single[,c('drug_col','drug_row','ri_row')]
        oneil_a2058_4 = oneil_a2058_single[,c('drug_col','drug_row','ri_col')]
        oneil_a2058_3$drug_col=oneil_a2058_3$drug_row
        oneil_a2058_4$drug_row=oneil_a2058_4$drug_col
        colnames(oneil_a2058_2) = colnames(oneil_a2058_1)
        colnames(oneil_a2058_3) = colnames(oneil_a2058_1)
        colnames(oneil_a2058_4) = colnames(oneil_a2058_1)
        oneil_a2058_all = rbind(oneil_a2058_1, oneil_a2058_2, oneil_a2058_3, oneil_a2058_4)
        # css_mat: asymetric
        
        # ri values on the diagonal
        css_mat = dcast(oneil_a2058_all, drug_row ~ drug_col, value.var = "css_row", fun.aggregate = mean)
        rownames(css_mat) = css_mat$drug_row
        css_mat = css_mat[,-1]
      
        
        
        # impute NA with the average of RI of single drugs
        na_index = which(is.na(css_mat)==T, arr.ind = T)
        for (i in 1:nrow(na_index)){
          css_mat[na_index[i,1], na_index[i,2]] = (css_mat[na_index[i,1],na_index[i,1]] + css_mat[na_index[i,2],na_index[i,2]])/2 
        }
        
        # to be used by hclust, force it to be symmetric by taking lower triangle
        css_mat2 = css_mat
        css_mat2[upper.tri(css_mat2)] <- t(css_mat2)[upper.tri(css_mat2)]
        
   clusters <- hclust(as.dist(css_mat2))
        clusterCut <- cutree(clusters, 2)
        
        
    
    mds.coor <- cmdscale((css_mat) )
#plot(mds.coor[,1], mds.coor[,2], type="n", xlab="", ylab="")
#text(jitter(mds.coor[,1]), jitter(mds.coor[,2]),
    # rownames(mds.coor), cex=1.2)    
   #pheatmap(css_mat2, cluster_cols =FALSE )
        # SW
        N1 = length(which(clusterCut==1))
        N2 = length(which(clusterCut==2))
        
        # to run nmanova, it shall produce similarly two best clusters, determined by p-values
        
        # to run nmanova, it shall produce similarly two best clusters, determined by p-values
        partition <- paste( 'group_', clusterCut, sep = '' )
        
        res <- nmANOVA( css_mat, partition,1)
        #View(res$summary)
        all_res[[k]] <- res$summary
        all_res[[k]]$cell_line <- cur_cl
        all_res[[k]]$mat <- 'css_mat'
        all_res[[k]]$num <- k
        all_res[[k]]$cluster_num <- 2
        all_res[[k]]$slice <- j
        
        if(res$summary$p_value < 0.1){
       
        plot(clusters)
        css_mat2_ordered <- css_mat2[clusters$order,clusters$order]
        pheatmap( t( as.matrix( css_mat2_ordered ) ), cluster_cols = F, cluster_rows = F )
        css_mat_ordered <- css_mat[clusters$order,clusters$order]
        pheatmap( t( as.matrix( css_mat_ordered ) ), cluster_cols = F, cluster_rows = F )
       
        }
}
 

        


all_res <- ldply( all_res, data.frame )
all_res_slice <- ldply( all_res_slice, data.frame )




```




```{r}



all_cl <- unique( oneil$cell_line_name )

#cur_cl <- 'LOVO'
all_res <- list()
k <- 0
for (i in 1:length( all_cl ) ){
  k <- k+1
  
        cur_cl <- all_cl[i]
        # A2058 cell line
        oneil_a2058 = oneil[oneil$cell_line_name==cur_cl,]
       # A_oneil_a2058_single <- 
        #  oneil_a2058 %>%
        #  group_by( drug_row,drug_col )%>%
         # slice(3)
          
        A_oneil_a2058_single <- oneil_a2058 
        oneil_a2058_single = ddply(A_oneil_a2058_single, .(drug_row,drug_col), summarise, 
                                   css_row = mean(css_row), css_col = mean(css_col),
                                   ri_row = mean(ri_row), ri_col = mean(ri_col))
        # combo
        oneil_a2058_1 = oneil_a2058_single[,c('drug_row','drug_col','css_row')]
        oneil_a2058_2 = oneil_a2058_single[,c('drug_col','drug_row','css_col')]
        # single drug
        oneil_a2058_3 = oneil_a2058_single[,c('drug_col','drug_row','ri_row')]
        oneil_a2058_4 = oneil_a2058_single[,c('drug_col','drug_row','ri_col')]
        oneil_a2058_3$drug_col=oneil_a2058_3$drug_row
        oneil_a2058_4$drug_row=oneil_a2058_4$drug_col
        colnames(oneil_a2058_2) = colnames(oneil_a2058_1)
        colnames(oneil_a2058_3) = colnames(oneil_a2058_1)
        colnames(oneil_a2058_4) = colnames(oneil_a2058_1)
        oneil_a2058_all = rbind(oneil_a2058_1, oneil_a2058_2, oneil_a2058_3, oneil_a2058_4)
        # css_mat: asymetric
        
        # ri values on the diagonal
        css_mat = dcast(oneil_a2058_all, drug_row ~ drug_col, value.var = "css_row", fun.aggregate = mean)
        ri_mat = dcast(oneil_a2058_all, ri_row ~ ri_col, value.var = "ri_row", fun.aggregate = mean)
        rownames(css_mat) = css_mat$drug_row
        css_mat = css_mat[,-1]
        css_mat3 <- css_mat
        css_mat3[css_mat3=="NaN"] <- "NA"
        diag( css_mat3 ) <- 'NA'
        
        #p <- matrix(as.numeric(unlist(css_mat3)),nrow=nrow(css_mat3))
colnames(p) <- colnames(css_mat3 )
rownames(p) <- rownames(css_mat3 )
  pheatmap(p, cluster_rows = FALSE, cluster_cols = FALSE )
        pheatmap( as.matrix( p ) )
        
        
        
        
        
        # impute NA with the average of RI of single drugs
        na_index = which(is.na(css_mat)==T, arr.ind = T)
        for (i in 1:nrow(na_index)){
          css_mat[na_index[i,1], na_index[i,2]] = (css_mat[na_index[i,1],na_index[i,1]] + css_mat[na_index[i,2],na_index[i,2]])/2 
        }
        
        # to be used by hclust, force it to be symmetric by taking lower triangle
        css_mat2 = css_mat
        css_mat2[upper.tri(css_mat2)] <- t(css_mat2)[upper.tri(css_mat2)]
        clusters <- hclust(as.dist(css_mat2))
        #plot(clusters)
       pheatmap( as.matrix( css_mat ) )
        clusterCut <- cutree(clusters, 2)
        ind <- which( clusterCut == 2 )
        
   
        
        # SW
        N1 = length(which(clusterCut==1))
        N2 = length(which(clusterCut==2))
        
        # to run nmanova, it shall produce similarly two best clusters, determined by p-values
        
        # to run nmanova, it shall produce similarly two best clusters, determined by p-values
        partition <- paste( 'group_', clusterCut, sep = '' )
        
        res <- nmANOVA( css_mat, partition,1)
        #View(res$summary)
        all_res[[k]] <- res$summary
        all_res[[k]]$cell_line <- cur_cl
        all_res[[k]]$mat <- 'css_mat'
        all_res[[k]]$num <- k
        all_res[[k]]$cluster_num <- 2
        k <- k+1
        
        
        res <- nmANOVA( ( css_mat2 ), partition, 1)
        all_res[[k]] <- res$summary
        all_res[[k]]$cell_line <- cur_cl
        all_res[[k]]$mat <- 'css_mat2'
        all_res[[k]]$num <- k
        all_res[[k]]$cluster_num <- 2
        k <- k+1
        
       # View(res$summary)
        res <- nmANOVA( ( css_mat3 ), partition, 1)
        all_res[[k]] <- res$summary
        all_res[[k]]$cell_line <- cur_cl
        all_res[[k]]$mat <- 'css_mat3'
        all_res[[k]]$num <- k
        all_res[[k]]$cluster_num <- 2
         k <- k+1

  #for three clusters      
        
         clusterCut <- cutree(clusters, 3)
       
      
        partition <- paste( 'group_', clusterCut, sep = '' )
        
        res <- nmANOVA( css_mat, partition,1)
        #View(res$summary)
        all_res[[k]] <- res$summary
        all_res[[k]]$cell_line <- cur_cl
        all_res[[k]]$mat <- 'css_mat'
        all_res[[k]]$num <- k
        all_res[[k]]$cluster_num <- 3
        k <- k+1
        
        
        res <- nmANOVA( ( css_mat2 ), partition, 1)
        all_res[[k]] <- res$summary
        all_res[[k]]$cell_line <- cur_cl
        all_res[[k]]$mat <- 'css_mat2'
        all_res[[k]]$num <- k
        all_res[[k]]$cluster_num <- 3
        k <- k+1
        
       # View(res$summary)
        res <- nmANOVA( ( css_mat3 ), partition, 1)
        all_res[[k]] <- res$summary
        all_res[[k]]$cell_line <- cur_cl
        all_res[[k]]$mat <- 'css_mat3'
        all_res[[k]]$num <- k
        all_res[[k]]$cluster_num <- 3
        
        
        
}

all_res <- ldply( all_res, data.frame )





cl <- cur_cl
a1 <- get_df_from_dc( oneil, 'ONEIL', cl )

  p <- matrix(as.numeric(unlist(css_mat3)),nrow=nrow(css_mat3))
colnames(p) <- colnames(css_mat3 )
rownames(p) <- rownames(css_mat3 )
all.equal( a1, as.data.frame(p))

#a1 and css_mat3 are same
ri1 <- 
  oneil%>%
  dplyr::select( drug_row, ri_row, cell_line_name)%>%
  distinct()%>%
  group_by( cell_line_name, drug_row )%>%
   dplyr::summarise_all("mean")%>%
  mutate( drug = drug_row, ri = ri_row)%>%
  dplyr::select( -contains( 'row' ) )


ri2 <- 
  oneil%>%
  dplyr::select( drug_col, ri_col, cell_line_name)%>%
  distinct()%>%
  group_by( cell_line_name, drug_col )%>%
   dplyr::summarise_all("mean")%>%
  mutate( drug = drug_col, ri = ri_col)%>%
  dplyr::select( -contains( 'col' ) )


ri <- 
  rbind( ri1, ri2)%>%
  distinct()%>%
  group_by( cell_line_name, drug )%>%
   dplyr::summarise_all("mean")%>%
  dplyr::rename( cell_line = cell_line_name, drug_name = drug)
#%>%
 # group_by( cell_line_name )%>%
 # dplyr::summarise(n = n())


syn_res <- list()
k <- 0

for( i in 1:length( all_cl ) ){
  
  cl <- all_cl[i]
  for( j in 1:4){
  A_oneil_a2058_single <- 
         oneil %>%
         group_by( drug_row,drug_col, cell_line_name )%>%
          slice(j)
  
  
  ri_cl <- 
    ri %>%
    filter( cell_line == cl)
oneil1 <-  A_oneil_a2058_single
        
  a2 <- get_syn_from_single( oneil1, 'ONEIL', cl, ri_cl )
  diag(a2) <- 0
  
  for (i in 1:nrow(a2) ){
    
    ind <- which(ri_cl$drug_name == rownames( a2 )[i] ) 
    a2[i,i] <- ri_cl$ri[i]
    
    
  }
  
  na_index = which(is.na(a2)==T, arr.ind = T)
        for (i in 1:nrow(na_index)){
          
          r <-
            ri_cl%>%
            filter( drug_name %in% c( colnames( a2 )[na_index[i,2]],   rownames( a2 )[na_index[i,1]] ))
          r_row<- 
            ri_cl%>%
            filter( drug_name %in% c(  rownames( a2 )[na_index[i,1]] ))

          a2[na_index[i,1], na_index[i,2]] = (r$ri[1] + r$ri[2]) -  r_row$ri
        }
  
  #diag(a2) <- NA
  
# mds.coor <- cmdscale(abs(a2) )
#plot(mds.coor[,1], mds.coor[,2], type="n", xlab="", ylab="")
#text(jitter(mds.coor[,1]), jitter(mds.coor[,2]),
 # rownames(mds.coor), cex=1.2)
#pheatmap( a2, cluster_rows = F, cluster_cols = F )



   na_index = sum( which(is.na(a2)==T))
  
   
   
    k <- k+1
    a2 <- abs(a2)
    clusters <- hclust(as.dist(a2))
   clusterCut <- cutree(clusters, 2)
  partition <- paste( 'group_', clusterCut, sep = '' )
        
        res <- nmANOVA( a2, partition,1)
        
        syn_res[[k]] <- res$summary
        syn_res[[k]]$cell_line <- cl
        syn_res[[k]]$mat <- 'css_mat'
        syn_res[[k]]$num <- k
        syn_res[[k]]$slice <- j
        syn_res[[k]]$cluster_num <- 2
     
       
      
}
}
syn_res <- ldply( syn_res, data.frame ) 



#i = 18 
i = 36
cl <- all_cl[i]
  
  a1 <- get_df_from_dc( oneil, 'ONEIL', cl )
   diag(a1) <- 0
  ri_cl <- 
    ri %>%
    filter( cell_line == cl)

        
  a2 <- get_syn_from_single( oneil, 'ONEIL', cl, ri_cl )
  diag(a2) <- 0
  
  na_index = which(is.na(a2)==T, arr.ind = T)
        for (i in 1:nrow(na_index)){
          
          r <-
            ri_cl%>%
            filter( drug_name %in% c( colnames( a2 )[na_index[i,2]],   rownames( a2 )[na_index[i,1]] ))
          r_row<- 
            ri_cl%>%
            filter( drug_name %in% c(  rownames( a2 )[na_index[i,1]] ))

          a2[na_index[i,1], na_index[i,2]] = (r$ri[1] + r$ri[2]) -  r_row$ri
        }
  
  
  
  mds.coor <- cmdscale(abs(a2) )
plot(mds.coor[,1], mds.coor[,2], type="n", xlab="", ylab="")
text(jitter(mds.coor[,1]), jitter(mds.coor[,2]),
     rownames(mds.coor), cex=1.2)
partition <- paste( rep( 'group', nrow( a2 ) ), rep(1,nrow( a2 ) ), sep = '_' )
diff <- which( rownames( a2 ) %in% c( "Dasatinib",  "Erlotinib", "Dinaciclib", "Erlotinib" ,  "Bortezomib"  , "Lapatinib",  "Vorinostat", "MK-1775", "Sorafenib" ,  "geldanamycin",   "gemcitabine" ,"paclitaxel", "mitomycin C"      ) )
partition[diff] <- 'group_2'
pheatmap(abs(a2))
res <- nmANOVA( abs(a2), partition,1)

```

EXAMPLES


RNA velocity
```{r}

vel <- read.csv("~/Desktop/nmANOVA/NMANOVA_RNA_velocity_sample/RNA_velocity_cell_to_cell_transition_probability_pbmc.csv", header = TRUE)
rownames( vel ) <- vel[,1]
vel <- vel[,-1]
#vel <-( 1-vel)

max ( vel )
min ( vel )
sum( is.na( vel ) )
sum( vel < 0.7 )
sum( vel == 0 )/879^2
#pheatmap( as.matrix( vel ),  cluster_rows = F, cluster_cols = F )

#seurat_cl <- read.csv("~/Desktop/nmANOVA/NMANOVA_RNA_velocity_sample/RNA_velocity_cell_seurat_cluster.csv", header = TRUE)

#load("/Users/amalyuti/Desktop/nmANOVA/2020.10.06_NMAnova/code/new_seurat_clusters.RData")
seurat_cl <- cl 
colnames( seurat_cl ) <- 'cluster_seurat'
seurat_cl <-
  seurat_cl %>%
  mutate( name = paste0( 'cluster', '_', cluster_seurat ) )%>%
  mutate( col_names = paste0( name, '_', rownames( seurat_cl ) ) )%>%
  mutate( X = str_extract( rownames( seurat_cl ), "[^-1]+" ) )

length( unique( seurat_cl$X ) )
sum(  seurat_cl$X == colnames( vel ) )
sum(  seurat_cl$X == rownames( vel ) )
sum(  rownames( vel ) == colnames( vel ) )



df <- data.frame( X = rownames( vel ) )
df <- 
  df %>%
  left_join( seurat_cl, by = 'X' )
  

sum(  rownames( vel ) == colnames( vel ) )
vv <- vel

css_mat2 = 1 - abs(cor(vel)) # use correlation as distance, column wise
        css_mat3 = 1 - abs(cor(t(vel))) # row wise, you have two versions of correlation matrix
# then merge these two correlation matrix, lower diagnoal as css_mat2, upper diagonal as css_mat3
        css_mat4 = css_mat2
        css_mat4[upper.tri(css_mat4)] <- t(css_mat3)[upper.tri(css_mat3)] # take lower triangle
        clusters <- hclust(as.dist(css_mat2))
        clusterCut <- cutree(clusters, 9)


# plot(clusters)
        css_mat2_ordered <- css_mat2[clusters$order,clusters$order]
       # pheatmap( t( as.matrix( css_mat2_ordered ) ), cluster_cols = F, cluster_rows = F )
        css_mat_ordered <- css_mat4[clusters$order,clusters$order]
        #pheatmap( t( as.matrix( css_mat_ordered ) ), cluster_cols = F, cluster_rows = F )
       #colnames( css_mat4 )[which(clusterCut ==9 )]
      
vel <-( css_mat4  )
colnames( vel ) <- seurat_cl$col_names
rownames( vel ) <- seurat_cl$col_names       
    
partition <- 
 crossing( el1 = unique( seurat_cl$name ), el2 = unique( seurat_cl$name ) ) %>%
 filter( el1 != el2) %>%
 mutate( combo = ifelse( el1 > el2,  paste( el1, el2 , sep = '+' ), paste( el2, el1 , sep = '+' )  ) ) %>%
  group_by( combo )%>%
  dplyr::slice(1) %>%
  ungroup()

res_list  <- list() 
#vv <- vel 
 #vv <- -( -log( ( vel ) + 0.0000000001 ) - 23 )
 
#vv[vv == 0] <- NA
for( i in 1:nrow( partition ) ){
  
  sel_partition <- c( partition$el1[i],  partition$el2[i] )
  ind <- which( sub('_[^_]*$', '', colnames( vel ) ) %in% sel_partition )
  v <- vel[ ind, ind ]
  part <- seurat_cl$name[ind]
  res_list[[i]] <- nmANOVA(  as.matrix( v ), part, 10 )
  res_list[[i]] <- res_list[[i]]$summary

}

nm_vel <-ldply( res_list, data.frame )

nn1 <- 
  nm_vel %>%
  dplyr::select( partition, p_value )
# what is going on with the isolated cluster????
sel_partition <- c( partition$el1[i],  partition$el1[i])
  ind <- which( sub('_[^_]*$', '', colnames( vel ) ) %in% sel_partition )
  v <- vel[ ind, ind ]
  main_v <- vv[ ind, ind ]
mean(v)
pheatmap(v, cluster_rows = FALSE,cluster_cols = FALSE )
pheatmap(main_v, cluster_rows = FALSE,cluster_cols = FALSE )
ch <- 1 - abs(cor(main_v))
```




```{r}



nm_res <- 
  nm_vel %>%
  mutate( cl1 = 0, cl2 = 0 )

for( i in 1:nrow( nm_res )) {
  
  nm_res$cl1[i] <- scan(text = nm_vel$partition[i], sep = ",", what = "")[1]
  nm_res$cl2[i] <- scan(text = nm_vel$partition[i], sep = ",", what = "")[2]
  

  
}

nm_res_ave<- 
  nm_res %>%
  group_by ( cl1) %>%
  summarize_each( mean)


length( unique( seurat_cl$X ) )
sum(  seurat_cl$X == colnames( vel ) )
sum(  seurat_cl$X == rownames( vel ) )
sum(  rownames( vel ) == colnames( vel ) )

colnames( vel ) <- seurat_cl$col_names
rownames( vel ) <- seurat_cl$col_names

sel_partition <- c( 'cluster_0', 'cluster_1',  'cluster_2' ) 
 ind <- which( sub('_[^_]*$', '', colnames( vel ) ) %in% sel_partition )
  v <- -( -log( ( vel[ ind, ind ] ) + 0.0000000001 ) -23 )
 
  
 part <- sub('_[^_]*$', '', colnames( v ) )
 p1 <- c('cluster_0', 'cluster_1' )
 p2 <- c(  'cluster_2' )
 #v [v == 23.025851]<- 'NA'
 
 for( i in 1:length( part )) {
   
 if( part[i] %in% p1 ) part[i] <- 'group1'
 if( part[i] %in% p2 ) part[i] <- 'group2'
 }
 r <- nmANOVA(  as.matrix( v ), part, 10 ) 
 View( r$summary)
 
 
 
d <- as.dist(vv)
mds.coor <- cmdscale(d)
plot(mds.coor[,1], mds.coor[,2], type="n", xlab="", ylab="")
text(jitter(mds.coor[,1]), jitter(mds.coor[,2]),
     rownames(mds.coor), cex=1.2)
abline(h=0,v=0,col="gray75")
df.dist=as.matrix(d, labels=TRUE)


mds.coor <- as.data.frame( mds.coor)
colnames( mds.coor ) <- c( 'coor1', 'coor2' )
mds.coor <- 
  mds.coor %>%
  mutate( Sample =  sub('_[^_]*$', '', rownames( mds.coor ) ) )

 ggplot( mds.coor, aes( x =  ( coor1 ), y = ( coor2 ), col = Sample,  ) ) +  
   geom_point( alpha = 0.7,  size = 10)  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +

            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +
             theme_bw()+ xlab( "mds.coor1" ) + ylab( "mds.coor2" ) +
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=28), axis.text.y = element_text(angle = 0, hjust = 1, size =25), legend.title=element_text(size=28), legend.text=element_text(size=28) ) #+ geom_text( aes( label = rownames( mds.coor ) ), size = 4, hjust=0, vjust = 1 ) #+ theme(legend.position = "none")





vv  <-
  vel %>%
  dplyr::select( starts_with( 'cluster_4' ),  starts_with( 'cluster_6' ) )

ind <- which( rownames( vv ) %in% colnames( vv ) )
vv <- vv[ind,]
  
mds.coor <- cmdscale(vv)



mds.coor <- as.data.frame( mds.coor)
colnames( mds.coor ) <- c( 'coor1', 'coor2' )
mds.coor <- 
  mds.coor %>%
  mutate( Sample =  sub('_[^_]*$', '', rownames( mds.coor ) ) )

 ggplot( mds.coor, aes( x =  ( coor1 ), y = ( coor2 ), col = Sample,  ) ) +  
   geom_point( alpha = 0.7,  size = 10)  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +

            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +
             theme_bw()+ xlab( "mds.coor1" ) + ylab( "mds.coor2" ) +
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=28), axis.text.y = element_text(angle = 0, hjust = 1, size =25), legend.title=element_text(size=28), legend.text=element_text(size=28) ) #+ geom_text( aes( label = rownames( mds.coor ) ), size = 4, hjust=0, vjust = 1 ) #+ theme(legend.position = "none")



partition <- 
 crossing( el1 = unique( seurat_cl$name ), el2 = unique( seurat_cl$name ) ) %>%
 filter( el1 != el2) %>%
 mutate( combo = ifelse( el1 > el2,  paste( el1, el2 , sep = '+' ), paste( el2, el1 , sep = '+' )  ) ) %>%
  group_by( combo )%>%
  dplyr::slice(1) %>%
  ungroup()

res_list  <- list() 
vv <- vel 
 vv <- -( -log( ( vel ) + 0.0000000001 ) - 23 )
 
#vv[vv == 0] <- NA
for( i in 1:nrow( partition ) ){
  
  sel_partition <- c( partition$el1[i],  partition$el2[i] )
  ind <- which( sub('_[^_]*$', '', colnames( vel ) ) %in% sel_partition )
  v <- vv[ ind, ind ]
  part <- seurat_cl$name[ind]
  res_list[[i]] <- nmANOVA(  as.matrix( v ), part, 10 )
  res_list[[i]] <- res_list[[i]]$summary

}

nm_vel <-ldply( res_list, data.frame )

```


```{r}

d <- as.dist(bladderKL)
mds.coor <- cmdscale(d)
plot(mds.coor[,1], mds.coor[,2], type="n", xlab="", ylab="")
text(jitter(mds.coor[,1]), jitter(mds.coor[,2]),
     rownames(mds.coor), cex=1.2)
abline(h=0,v=0,col="gray75")
df.dist=as.matrix(d, labels=TRUE)


mds.coor <- as.data.frame( mds.coor)
colnames( mds.coor ) <- c( 'coor1', 'coor2' )
mds.coor <- 
  mds.coor %>%
  mutate( Sample =  sub('_[^_]*$', '', rownames( mds.coor ) ) )

 ggplot( mds.coor, aes( x =  ( coor1 ), y = ( coor2 ), col = Sample,  ) ) +  
   geom_point( alpha = 0.7,  size = 10)  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +

            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +
             theme_bw()+ xlab( "mds.coor1" ) + ylab( "mds.coor2" ) +
                theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=28), axis.text.y = element_text(angle = 0, hjust = 1, size =25), legend.title=element_text(size=28), legend.text=element_text(size=28) ) #+ geom_text( aes( label = rownames( mds.coor ) ), size = 4, hjust=0, vjust = 1 ) #+ theme(legend.position = "none")


#change the column/row names
better_names <- c( paste0( 'Normal', '_', c( 1:8 ) ), paste0( 'Biopsy', '_', c( 1:9 ) ), paste0( 'mTCC', '_', c( 1:12 ) ), paste0( 'sTCC+CIS', '_', c( 1:12 ) ),  paste0( 'sTCC-CIS', '_', c( 1:16 ) ) ) 
colnames( bladderKL ) <- better_names
rownames( bladderKL ) <- better_names
diss_df <- bladderKL
#select partitions to be used in the paper table
partition <- list()
partition[[1]] <-c( "Normal"   ,         "Biopsy" )
partition[[2]] <-c( "Normal"   ,         "mTCC" )
partition[[3]] <-c( "Normal"   ,         "sTCC+CIS" )
partition[[4]] <-c( "Normal"   ,         "sTCC-CIS" )
partition[[5]] <-c( "Biopsy"   ,         "mTCC" )
partition[[6]] <-c( "Biopsy"   ,         "sTCC+CIS" )
partition[[7]] <-c( "Biopsy"   ,         "sTCC-CIS" )
partition[[8]] <-c( "mTCC"   ,         "sTCC+CIS" )
partition[[9]] <-c( "mTCC"   ,         "sTCC-CIS" )
partition[[10]] <-c( "sTCC+CIS"   ,         "sTCC-CIS" )

partition[[11]] <- c( "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS" )

partition[[12]] <- c( "Normal"   , "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS"   )
partition[[13]] <- c( "Biopsy"   , "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS"   )
partition[[14]] <- c( "Normal"   ,      "mTCC+sTCC+CIS+sTCC-CIS" ) 
partition[[15]] <- c( "Biopsy"   ,       "mTCC+sTCC+CIS+sTCC-CIS" )

partition[[16]] <- c( "Normal"   ,         "Biopsy" ,   "sTCC+CIS" )
partition[[17]] <- c( "Normal+Biopsy"   , "sTCC+CIS" )

partition[[18]] <- c( "Normal",         "Biopsy" ,   "sTCC-CIS" )
partition[[19]] <- c( "Normal+Biopsy", "sTCC-CIS" )

partition[[20]] <- c( "Normal",         "Biopsy" ,   "mTCC" )
partition[[21]] <- c( "Normal+Biopsy", "mTCC" )


partition[[22]] <- c( "Normal+Biopsy"  , "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS" )
partition[[23]] <- c( "Normal+Biopsy"  ,"mTCC+sTCC+CIS+sTCC-CIS" )

partition[[24]] <- c( "Biopsy"   ,"Normal", "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS"   )



d <- as.matrix( diss_df )


joints <- c( "Normal+Biopsy", "mTCC+sTCC+CIS+sTCC-CIS" )
ind_Norm_Biopsy <-  which( sub('_[^_]*$', '', colnames( d ) ) %in% c( 'Normal', 'Biopsy' ) )
ind_Cancers <-  which( sub('_[^_]*$', '', colnames( d ) ) %in% c( "mTCC"  ,     "sTCC+CIS" ,  "sTCC-CIS" ) )


#nmANOVA 
res_m <- list()
res_dist <- list()
pca_plot <- list()
ggplot_list <- list()


for( i in 1:length( partition ) ){
  
  if( length( intersect( partition[[i]], joints ) ) > 0 ){
    
    sel_partition <- c( rep('Normal', 8), rep('Biopsy', 9), rep("mTCC" , 12 ), rep("sTCC+CIS" , 12 ), rep("sTCC-CIS" , 16 ) )
    l <- unique( partition[[i]] )
    sub1 <- vector()
    sub2 <- vector()
    if( "Normal+Biopsy" %in% l )  { 
      sel_partition[ ind_Norm_Biopsy ] <- 'Normal+Biopsy' 
      sub1 <- union( l, c( 'Normal', 'Biopsy') )
    }
    if( "mTCC+sTCC+CIS+sTCC-CIS" %in% l )  { 
      sel_partition[ ind_Cancers ] <- "mTCC+sTCC+CIS+sTCC-CIS" 
      sub2 <- union( l, c( 'mTCC', 'sTCC+CIS', 'sTCC-CIS') )
      }
    
    sub <- union( sub1 , sub2 )
    subpartition <- partition[[i]]
    res_m[[i]] <- nmANOVA(d, sel_partition,  10,  subpartition )
    res_m[[i]] <- res_m[[i]]$summary
    
    
   
    ind <- which( sub('_[^_]*$', '', colnames( d  ) ) %in%  sub )
     dd <- as.dist( d[ind, ind] )
      mds.coor <- cmdscale(dd)
      
      mds.coor <- as.data.frame( mds.coor)
      colnames( mds.coor ) <- c( 'coor1', 'coor2' )
      mds.coor <- 
        mds.coor %>%
        mutate( Sample =  sub('_[^_]*$', '', rownames( mds.coor ) ) )
      
      
      if( "Normal+Biopsy" %in% l ) { 
        ind <- which(mds.coor$Sample %in% c( 'Normal', 'Biopsy' ) )
        mds.coor$Sample[ind] <-  "Normal+Biopsy"
        
      }
      
      if( "mTCC+sTCC+CIS+sTCC-CIS" %in% l )  { 
      
       ind <- which(mds.coor$Sample %in%  c( 'mTCC', 'sTCC+CIS', 'sTCC-CIS') )
        mds.coor$Sample[ind] <-"mTCC+sTCC+CIS+sTCC-CIS" 
       
        
       
      }
      
      
       ggplot_list[[i]] <- ggplot( mds.coor, aes( x =  ( coor1 ), y = ( coor2 ), col = as.factor( Sample )  ) )  + xlim( -0.3, 0.3) +ylim( -0.05, 0.05 ) + 
         geom_point( alpha = 0.7,  size = 7)  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
      
                  theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
                    panel.grid.major = element_line(colour = "grey", size = 0.5)) + ggtitle( paste('p-value = ', round( res_m[[i]]$p_value, 4 ) )) +
                   theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +
                   theme_bw()+ xlab( "mds.coor1" ) + ylab( "mds.coor2" ) +
                      theme(plot.title = element_text(size = 15),axis.text.x = element_text(angle = 0, hjust = 1, size = 10), axis.title=element_text(size=10), axis.text.y = element_text(angle = 0, hjust = 1, size =10), legend.title=element_text(size=10), legend.text=element_text(size= 10) ) #+ geom_text( aes( label = rownames( mds.coor ) ), size = 4, hjust=0, vjust = 1 ) #+ theme(legend.position = "none")
      
          
          pheno2 <- 
            pheno %>%
            filter( outcome %in%  sub )
          ind <- which( colnames( edata ) %in% rownames( pheno2 ) )
          edata2 <- edata[, ind]
            
          prc <- prcomp( t( edata2 ), center = T, scale = T )
      
          prc_res <- as.data.frame( prc$x )
          prc_res <- merge( prc_res, pheno2, by = 'row.names' )
          prc_res$outcome <- as.character(prc_res$outcome  )
       if( "Normal+Biopsy" %in% l ) { 
        ind <- which(prc_res$outcome %in% c( 'Normal', 'Biopsy' ) )
        prc_res$outcome[ind] <-  "Normal+Biopsy"
    }
       
      if( "mTCC+sTCC+CIS+sTCC-CIS" %in% l )  { 
      
       ind <- which(prc_res$outcome %in%  c( 'mTCC', 'sTCC+CIS', 'sTCC-CIS') )
        prc_res$outcome[ind] <- "mTCC+sTCC+CIS+sTCC-CIS" 
      
       
      }
      
      
          
          
          #PCA plot
          pca_plot[[i]] <- ggplot( prc_res , aes( x =  PC1, y = PC2, col = as.factor( outcome ) ) ) + geom_point( size = 7, alpha = 0.7 ) +
                        theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
                        panel.grid.major = element_line(colour = "grey", size = 0.5)) +ggtitle( paste('p-value = ', round( res_m[[i]]$p_value, 4 ) ) )+
                       theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
                       theme_bw()+ xlab( "PC1" ) + ylab( "PC2" ) + guides(col=guide_legend(title="dataset"), shape = guide_legend(title='concentrations'))+ theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )

    
    
    
    
  } 
  else{
    
    sel_partition <- c( rep('Normal', 8), rep('Biopsy', 9), rep("mTCC" , 12 ), rep("sTCC+CIS" , 12 ), rep("sTCC-CIS" , 16 ) )
    subpartition <- partition[[i]]
    res_m[[i]] <- nmANOVA(d, sel_partition, 10, subpartition )
   res_m[[i]] <- res_m[[i]]$summary
  
    ind <- which( sub('_[^_]*$', '', colnames( d  ) ) %in%  subpartition )
     dd <- as.dist( d[ind, ind] )
      mds.coor <- cmdscale(dd)
      
      mds.coor <- as.data.frame( mds.coor)
      colnames( mds.coor ) <- c( 'coor1', 'coor2' )
      mds.coor <- 
        mds.coor %>%
        mutate( Sample =  sub('_[^_]*$', '', rownames( mds.coor ) ) )
      
       ggplot_list[[i]] <- ggplot( mds.coor, aes( x =  ( coor1 ), y = ( coor2 ), col = Sample  ) )  + xlim( -0.3, 0.3) +ylim( -0.05, 0.05 ) + 
         geom_point( alpha = 0.7,  size = 7)  +#xlim( -0.007, 0.01) + ylim( -0.005, 0.005 ) +
      
                  theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
                    panel.grid.major = element_line(colour = "grey", size = 0.5)) +ggtitle( paste('p-value = ', round( res_m[[i]]$p_value, 4 )  ))+
                   theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  +
                   theme_bw()+ xlab( "mds.coor1" ) + ylab( "mds.coor2" ) +
                      theme(plot.title = element_text(size = 15),axis.text.x = element_text(angle = 0, hjust = 1, size = 10), axis.title=element_text(size=10), axis.text.y = element_text(angle = 0, hjust = 1, size =10), legend.title=element_text(size=10), legend.text=element_text(size=10) ) #+ geom_text( aes( label = rownames( mds.coor ) ), size = 4, hjust=0, vjust = 1 ) #+ theme(legend.position = "none")
      
          
          pheno2 <- 
            pheno %>%
            filter( outcome %in%  subpartition )
          ind <- which( colnames( edata ) %in% rownames( pheno2 ) )
          edata2 <- edata[, ind]
            
          prc <- prcomp( t( edata2 ), center = T, scale = T )
          sum( colnames( edata2 ) == rownames( pheno2 ) )
          prc_res <- as.data.frame( prc$x )
          prc_res <- merge( prc_res, pheno2, by = 'row.names' )
          
          #PCA plot
          pca_plot[[i]] <- ggplot( prc_res , aes( x =  PC1, y = PC2, col = as.factor( outcome ) ) ) + geom_point( size = 7, alpha = 0.7 ) + ylim( -0.2, 0.2) +xlim( -0.03, 0.03 ) +
                        theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
                        panel.grid.major = element_line(colour = "grey", size = 0.5)) +ggtitle( paste('p-value = ', round( res_m[[i]]$p_value, 4 ) ) )+
                       theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
                       theme_bw()+ xlab( "PC1" ) + ylab( "PC2" ) + guides(col=guide_legend(title="Sample"), shape = guide_legend(title='concentrations'))+ theme(plot.title = element_text(size = 15),axis.text.x = element_text(angle = 0, hjust = 1, size = 15), axis.title=element_text(size=15), axis.text.y = element_text(angle = 0, hjust = 1, size = 15), legend.title=element_text(size=15), legend.text=element_text(size=15) )

    
    
    
  }
  
  
}  

i = 24
plot( pca_plot[[i]] )
plot( ggplot_list[[i]] )


nm_df <- 
  plyr::ldply( lapply( res_m, as.data.frame ) )




```


```{r}

set.seed(1234)
dplyr::sample_n(my_data, 10)
sepl <- iris$Sepal.Length
petl <- iris$Petal.Length
# MANOVA test
res.man <- manova(cbind(Sepal.Length, Petal.Length) ~ Species, data = iris)
summary(res.man)


data(dune)
data(dune.env)
## default test by terms
adonis2(as.dist( dune ) ~ Management, data = dune.env)
pheatmap( dune )
## overall tests
adonis2(dune ~ Management*A1, data = dune.env, by = NULL)
```



4.1.3
```{r}

start.time <- Sys.time()

change.dist.mat <- function( dist_mat, partition ){
  
   anova_dist_mat <- dist_mat
   anova_dist_mat[lower.tri(anova_dist_mat, diag = TRUE)] <- NA
   df <- data.frame( vec1 = c( 'group1', 'group1','group1', 'group2', 'group2', 'group3' ), vec2 = c( 'group1', 'group2', 'group3', 'group2', 'group3', 'group3' ),  ind_vec1 =  c( 1, 1, 1, 2, 2, 3 ), ind_vec2 =  c( 1, 2, 3, 2, 3, 3 ) )
   
   for( i in 1:nrow( df ) ){
     
     ind1 <- which( partition == df$vec1[i] )
     ind2 <- which( partition == df$vec2[i] )
     
     cur_mat <- anova_dist_mat[ind1, ind2]
     sel <- floor( sum( is.na( cur_mat ) == FALSE )/2 )
     #print( floor( sum( is.na( cur_mat ) == FALSE ) ) )
     #print( length( setdiff( unique( as.vector( cur_mat ) ), NA  ) ) )
     
     v <- setdiff( unique( as.vector( cur_mat ) ), NA  )
    #print( sum( is.na( v ) ) )
     
     sam <- sample( 1:length( v ), sel )
    
     for( j in 1:length( sam ) ){
       #print(  unique( as.vector( v ) )[ sam[j] ] )
       el <- which( cur_mat == unique( as.vector( v ) )[ sam[j] ], arr.ind = T )
      
       anova_dist_mat[  (df$ind_vec2[i] - 1)*N + el[2], (df$ind_vec1[i] - 1)*N + el[1] ] <- anova_dist_mat[(df$ind_vec1[i] - 1)*N + el[1], (df$ind_vec2[i] - 1)*N + el[2]] 
       anova_dist_mat[(df$ind_vec1[i] - 1)*N + el[1], (df$ind_vec2[i] - 1)*N + el[2]] <- NA
       
     } 
     
     
   } 
   #pheatmap( dist_mat, cluster_rows = F, cluster_cols = F ) 
   #pheatmap( anova_dist_mat, cluster_rows = F, cluster_cols = F ) 
  anova_dist_mat
  
}

library( pheatmap )
library( vegan )
#Example 1: normal distribution, 5 clusters of different size, 50*50 matrix of dissimilarities
p_value_nm <- vector()
p_value_ad <- vector()
p_value_ad2 <- vector()
#set.seed(Sys.time())
N <- 100
N_sim <- 10 
delta <- seq( 0, 2, length.out = 100 )
res_df <- data.frame( delta = sort( c( rep( delta, N_sim ) ) ), N_sim = rep( seq( 1:N_sim ), length( delta ) ), m1 = NA, m2 = NA, m3 = NA, cl_pval = 0, np_pval = 0, nm_pval = 0  )  


for( ii in 1:nrow( res_df ) ){
 
  print( ii )
               
                
                set.seed( 4111 )
                m1 <- matrix( rnorm(N, mean = 0,  sd=1), ncol= 1 )
                
                set.seed(Sys.time())
                m2 <- matrix( rnorm(N,mean = 0 + res_df$delta[ii] ,  sd=1), ncol= 1 )
                m3 <- matrix( rnorm(N,mean = 0 + 2*res_df$delta[ii],  sd=1), ncol= 1 )
                cl_df <- data.frame( data = c( m1, m2, m3 ), grouping = c( rep( 'm1', N ), rep( 'm2', N ), rep( 'm3', N ) )  )
                anova <- aov(cl_df$data ~ cl_df$grouping)
                res_df$cl_pval[ii]  <- summary( anova )[[1]]$`Pr(>F)`[1]
                
                #print( res_df$delta[ii] )
                res_df$m1[ii] <- paste( round( m1, 2 ), collapse = ',' )  
                res_df$m2[ii] <-paste(  round( m2, 2 ), collapse = ',' ) 
                res_df$m3[ii] <-paste( round( m3, 2 ), collapse = ',' ) 
                
                m <- cbind( m1, m2, m3 )
                
                colnames( m ) <- c( 'group1', 'group2', 'group3' )
                
                euc.dist <- function(x1, x2) sqrt(sum((x1 - x2) ^ 2))
                dist_mat <- matrix( 0, ncol = N, nrow = N )
                
                block11 <- as.matrix( dist( m1 ) )
                block22 <- as.matrix( dist( m2 ) )
                block33 <- as.matrix( dist( m3 ) )
                
                block12 <- matrix( 0, nrow = N, ncol = N )
                block13 <- matrix( 0, nrow = N, ncol = N )
                block23 <- matrix( 0, nrow = N, ncol = N )
                
                for( i in 1:N ){
                  
                  for( j in 1:N ){
                  
                    block12[i, j] <- euc.dist( m1[i], m2[j] )
                    block13[i, j] <- euc.dist( m1[i], m3[j] )
                    block23[i, j] <- euc.dist( m2[i], m3[j] )
                  
                }
                  
                }
                
                block32 <- t( block23 )
                block21 <- t( block12 )
                block31 <- t( block13 )
                
                dist_mat <- rbind( cbind( block11, block12, block13 ), cbind( block21, block22, block23 ), cbind( block31, block32, block33 ) )
                sum( diag( dist_mat ) )
                
                new.function <- function(a) {all(a==t(a))}
                new.function(dist_mat)
                
                
                
                #pheatmap( dist_mat, cluster_rows = F, cluster_cols = F ) 
                
                
                
                partition <- c( rep( 'group1', N ), rep( 'group2', N ), rep( 'group3', N ) )
                ad_res <- adonis2( as.dist( dist_mat ) ~ partition )
                ad_res <- ad_res$`Pr(>F)`
                ad_res <- as.numeric( ad_res[1] )
                res_df$np_pval[ii] <- as.numeric( ad_res )
                
                
               
                anova_dist_mat <- change.dist.mat( dist_mat, partition )
                nm_res1 <- nmANOVA( anova_dist_mat, partition, N_sampling = 10)
                
                nm_res <- nm_res1$summary$p_value
              
                res_df$nm_pval[ii] <- as.numeric( nm_res )
                
              
                

  
  
}

#hist(p_value_nm, 20 )
#hist(p_value_ad, 20 )

#pheatmap( anova_dist_mat, cluster_rows = F, cluster_cols = F ) 



end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
save( res_df, file = 'res_df_411.RData')
load(file = 'res_df_411.RData')



s <- 
  res_df %>%
  dplyr::select( delta, contains( 'pval' ) )%>%
  group_by( delta ) %>%
  dplyr::summarise_each( funs = mean ) %>%
 gather( method, p_value, -delta)
#f <- glm( x ~ num, data = df[1:1000,])
#summary(f)
#plot(f)


ggplot( s, aes( x =  delta, y = ( ( p_value ) ), group = method, col = method ) ) +  
  
   geom_point(  alpha = 0.5, size = 2 )  +
   geom_line( alpha = 0.7,  size = 1)  +
  
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ xlab( expression(delta) ) + ylab( "log(p-value)" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )#  + theme(legend.position = "none")







```

4.1.3
```{r}

start.time <- Sys.time()

change.dist.mat <- function( dist_mat, partition ){
  
   anova_dist_mat <- dist_mat
   anova_dist_mat[lower.tri(anova_dist_mat, diag = TRUE)] <- NA
   df <- data.frame( vec1 = c( 'group1', 'group1','group1', 'group2', 'group2', 'group3' ), vec2 = c( 'group1', 'group2', 'group3', 'group2', 'group3', 'group3' ),  ind_vec1 =  c( 1, 1, 1, 2, 2, 3 ), ind_vec2 =  c( 1, 2, 3, 2, 3, 3 ) )
   
   for( i in 1:nrow( df ) ){
     
     ind1 <- which( partition == df$vec1[i] )
     ind2 <- which( partition == df$vec2[i] )
     
     cur_mat <- anova_dist_mat[ind1, ind2]
     sel <- floor( sum( is.na( cur_mat ) == FALSE )/2 )
     #print( floor( sum( is.na( cur_mat ) == FALSE ) ) )
     #print( length( setdiff( unique( as.vector( cur_mat ) ), NA  ) ) )
     
     v <- setdiff( unique( as.vector( cur_mat ) ), NA  )
    #print( sum( is.na( v ) ) )
     
     sam <- sample( 1:length( v ), sel )
    
     for( j in 1:length( sam ) ){
       #print(  unique( as.vector( v ) )[ sam[j] ] )
       el <- which( cur_mat == unique( as.vector( v ) )[ sam[j] ], arr.ind = T )
      
       anova_dist_mat[  (df$ind_vec2[i] - 1)*N + el[2], (df$ind_vec1[i] - 1)*N + el[1] ] <- anova_dist_mat[(df$ind_vec1[i] - 1)*N + el[1], (df$ind_vec2[i] - 1)*N + el[2]] 
       anova_dist_mat[(df$ind_vec1[i] - 1)*N + el[1], (df$ind_vec2[i] - 1)*N + el[2]] <- NA
       
     } 
     
     
   } 
   #pheatmap( dist_mat, cluster_rows = F, cluster_cols = F ) 
   #pheatmap( anova_dist_mat, cluster_rows = F, cluster_cols = F ) 
  anova_dist_mat
  
}

library( pheatmap )
library( vegan )
#Example 1: normal distribution, 5 clusters of different size, 50*50 matrix of dissimilarities
p_value_nm <- vector()
p_value_ad <- vector()
p_value_ad2 <- vector()
#set.seed(Sys.time())
N <- 100
N_sim <- 10 
delta <- seq( 0, 2, length.out = 100 )
res_df <- data.frame( delta = sort( c( rep( delta, N_sim ) ) ), N_sim = rep( seq( 1:N_sim ), length( delta ) ), m1 = NA, m2 = NA, m3 = NA, cl_pval = 0, np_pval = 0, nm_pval = 0  )  


for( ii in 1:nrow( res_df ) ){
 
  print( ii )
               
                
                set.seed( 4111 )
                m1 <- matrix( rnorm(N, mean = 0,  sd=1), ncol= 1 )
                
                set.seed(Sys.time())
                m2 <- matrix( rnorm(N,mean = 0 + res_df$delta[ii] ,  sd=1), ncol= 1 )
                m3 <- matrix( rnorm(N,mean = 0 + 2*res_df$delta[ii],  sd=1), ncol= 1 )
                cl_df <- data.frame( data = c( m1, m2, m3 ), grouping = c( rep( 'm1', N ), rep( 'm2', N ), rep( 'm3', N ) )  )
                anova <- aov(cl_df$data ~ cl_df$grouping)
                res_df$cl_pval[ii]  <- summary( anova )[[1]]$`Pr(>F)`[1]
                
                #print( res_df$delta[ii] )
                res_df$m1[ii] <- paste( round( m1, 2 ), collapse = ',' )  
                res_df$m2[ii] <-paste(  round( m2, 2 ), collapse = ',' ) 
                res_df$m3[ii] <-paste( round( m3, 2 ), collapse = ',' ) 
                
                m <- cbind( m1, m2, m3 )
                
                colnames( m ) <- c( 'group1', 'group2', 'group3' )
                
                euc.dist <- function(x1, x2) sqrt(sum((x1 - x2) ^ 2))
                dist_mat <- matrix( 0, ncol = N, nrow = N )
                
                block11 <- as.matrix( dist( m1 ) )
                block22 <- as.matrix( dist( m2 ) )
                block33 <- as.matrix( dist( m3 ) )
                
                block12 <- matrix( 0, nrow = N, ncol = N )
                block13 <- matrix( 0, nrow = N, ncol = N )
                block23 <- matrix( 0, nrow = N, ncol = N )
                
                for( i in 1:N ){
                  
                  for( j in 1:N ){
                  
                    block12[i, j] <- euc.dist( m1[i], m2[j] )
                    block13[i, j] <- euc.dist( m1[i], m3[j] )
                    block23[i, j] <- euc.dist( m2[i], m3[j] )
                  
                }
                  
                }
                
                block32 <- t( block23 )
                block21 <- t( block12 )
                block31 <- t( block13 )
                
                dist_mat <- rbind( cbind( block11, block12, block13 ), cbind( block21, block22, block23 ), cbind( block31, block32, block33 ) )
                sum( diag( dist_mat ) )
                
                new.function <- function(a) {all(a==t(a))}
                new.function(dist_mat)
                
                
                
                #pheatmap( dist_mat, cluster_rows = F, cluster_cols = F ) 
                
                
                
                partition <- c( rep( 'group1', N ), rep( 'group2', N ), rep( 'group3', N ) )
                ad_res <- adonis2( as.dist( dist_mat ) ~ partition )
                ad_res <- ad_res$`Pr(>F)`
                ad_res <- as.numeric( ad_res[1] )
                res_df$np_pval[ii] <- as.numeric( ad_res )
                
                
               
                anova_dist_mat <- change.dist.mat( dist_mat, partition )
                nm_res1 <- nmANOVA( anova_dist_mat, partition, N_sampling = 10)
                
                nm_res <- nm_res1$summary$p_value
              
                res_df$nm_pval[ii] <- as.numeric( nm_res )
                
              
                

  
  
}

#hist(p_value_nm, 20 )
#hist(p_value_ad, 20 )

#pheatmap( anova_dist_mat, cluster_rows = F, cluster_cols = F ) 



end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
save( res_df, file = 'res_df_411.RData')
load(file = 'res_df_411.RData')



s <- 
  res_df %>%
  dplyr::select( delta, contains( 'pval' ) )%>%
  group_by( delta ) %>%
  dplyr::summarise_each( funs = mean ) %>%
 gather( method, p_value, -delta)
#f <- glm( x ~ num, data = df[1:1000,])
#summary(f)
#plot(f)


ggplot( s, aes( x =  delta, y = ( ( p_value ) ), group = method, col = method ) ) +  
  
   geom_point(  alpha = 0.5, size = 2 )  +
   geom_line( alpha = 0.7,  size = 1)  +
  
            theme(panel.grid.minor = element_line(colour = "grey", size = 0.1), 
              panel.grid.major = element_line(colour = "grey", size = 0.5)) +
             theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
             theme_bw()+ xlab( expression(delta) ) + ylab( "log(p-value)" ) +  theme(plot.title = element_text(size = 25),axis.text.x = element_text(angle = 0, hjust = 1, size = 25), axis.title=element_text(size=25), axis.text.y = element_text(angle = 0, hjust = 1, size = 25), legend.title=element_text(size=25), legend.text=element_text(size=25) )#  + theme(legend.position = "none")







```

check why for canberra distance we get always significant matrices
```{r}

m1 <- as.numeric( unlist( strsplit( res_df[1, 5], ',' ) ) )
m2 <- as.numeric( unlist( strsplit( res_df[1, 6], ',' ) ) )
m3 <- as.numeric( unlist( strsplit( res_df[1, 7], ',' ) ) )
m4 <- as.numeric( unlist( strsplit( res_df[1, 8], ',' ) ) )


 canb.dist<- function(a, b){
  sum( abs(a - b) / abs(a + b), na.rm = T )
}
my.dist <-  canb.dist


cl_df <- data.frame( data = c( m1, m2, m3, m4 ), grouping = c( rep( 'm1', N ), rep( 'm2', N ), rep( 'm3', N ), rep( 'm4', N )  )  )
 anova <- aov(cl_df$data ~ cl_df$grouping)
cl_pval  <- summary( anova )[[1]]$`Pr(>F)`[1]
  

m <- cbind( m1, m2, m3, m4 )
  
  colnames( m ) <- c( 'group1', 'group2', 'group3', 'group4' )
  
  
  dist_mat <- matrix( 0, ncol = N, nrow = N )
  
  block11 <- as.matrix( dist( m1, method = 'canberra'  ) )
  block22 <- as.matrix( dist( m2, method = 'canberra'  ) )
  block33 <- as.matrix( dist( m3, method = 'canberra'  ) )
  block44 <- as.matrix( dist( m4, method = 'canberra' ) )
  
  
  block12 <- matrix( 0, nrow = N, ncol = N )
  block13 <- matrix( 0, nrow = N, ncol = N )
  block14 <- matrix( 0, nrow = N, ncol = N )
  block23 <- matrix( 0, nrow = N, ncol = N )
  block24 <- matrix( 0, nrow = N, ncol = N )
  block34 <- matrix( 0, nrow = N, ncol = N )
  
  for( i in 1:N ){
    
    for( j in 1:N ){
      
      block12[i, j] <- my.dist( m1[i], m2[j] )
      block13[i, j] <- my.dist( m1[i], m3[j] )
      block23[i, j] <- my.dist( m2[i], m3[j] )
      block14[i, j] <- my.dist( m1[i], m4[j] )
      block24[i, j] <- my.dist( m2[i], m4[j] )
      block34[i, j] <- my.dist( m3[i], m4[j] )
      
    }
    
  }
  
  block32 <- t( block23 )
  block21 <- t( block12 )
  block31 <- t( block13 )
  block41 <- t( block14 )
  block42 <- t( block24 )
  block43 <- t( block34 )
  
  dist_mat <- rbind( cbind( block11, block12, block13, block14 ), cbind( block21, block22, block23, block24 ),
                     cbind( block31, block32, block33, block34), cbind( block41, block42, block43, block44) )

  print( sum( diag( dist_mat ) ) )
  
new.function <- function(a) {all(a==t(a))}
 print(  new.function(dist_mat) )
  
  
  
  pheatmap( dist_mat, cluster_rows = F, cluster_cols = F ) 
  
  
  
  partition <- c( rep( 'group1', N ), rep( 'group2', N ), rep( 'group3', N ), rep( 'group4', N ) )
  ad_res <- adonis2( as.dist( dist_mat ) ~ partition )
  ad_res <- ad_res$`Pr(>F)`
  ad_res <- as.numeric( ad_res[1] )
  res_df$np_pval[ii] <- as.numeric( ad_res )
  
  
  dist_mat2 <- dist_mat + matrix( rnorm(nrow( dist_mat )*ncol( dist_mat ), 0, sd = 0.0005 ), nrow = nrow( dist_mat ), ncol =  ncol( dist_mat ) )  
  anova_dist_mat <- change.dist.mat( dist_mat2, partition )
  #print('d')
  pheatmap( anova_dist_mat, cluster_rows = F, cluster_cols = F ) 
  nm_res1 <- nmANOVA( anova_dist_mat, partition, N_sampling = 1)
  
  nm_res <- nm_res1$summary$p_value
  
  res_df$nm_pval[ii] <- as.numeric( nm_res )


```


select distributions and groups sizes and make simulations to check the distribution of p-values
```{r}
library( pheatmap )
#you can now select a distribution from which the simulation matrix will be drawn:
#uniform (N, a = par1, b = par2)
#normal (N, mean = par1, sd = par2)
#gamma (N, shape = par1, rate = par2)
#chisq (N, df = par1, par2 is ingnored but has to be a random number)
    
distribution <- 'uniform' #distribution for the simulation matrix
group_N <- c( 10, 20, 30 )#group sizes 
par_vec <- c( 1, 25 )# distribution parameters

#in case you want to introduce the difference - select some groups and change parameters in H1_group
#dist_par1 is a new parameter to use instead of par1 for the specified groups
#dist_par2 is a new parameter to use instead of par2 for the specified groups
H1_group <- data.frame( groups = c( 'group2,group1', 'group1,group2' ), dist_par1 = c( 20, 20 ), dist_par2 = c( 30, 30 ) )
  

#perform simulations and check distribution of p-values w
Nsim <- 1
p_value <- vector()
p_value_H1 <- vector()
p_value_2_blocks <- vector()
p_value_H1_2_blocks <- vector()
for( i in 1:Nsim ){
  
  #case when all the groups are from the same distribution (no H1_group)
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, show_plots = FALSE )
  p_value[i] <- sim_results$summary$p_value 
  
  #case when not all of the groups are from the same distribution ( H1_group is added )
  sim_results <- nmANOVA_sim( distribution, group_N, par_vec, H1_group, show_plots = TRUE )
  p_value_H1[i] <- sim_results$summary$p_value 
  
  #case when all the groups are from the same distribution (no H1_group)
 # sim_results <- nmANOVA_2_blocks_sim( distribution, group_N, par_vec, show_plots = FALSE )
  #p_value_2_blocks[i] <- sim_results$p_value 
  
  #case when not all of the groups are from the same distribution ( H1_group is added )
 # sim_results <- nmANOVA_2_blocks_sim( distribution, group_N, par_vec, H1_group, show_plots = FALSE )
 # p_value_H1_2_blocks[i] <- sim_results$p_value 
  
}

#in case all are from the same distribution - we have a uniform p-value distribution
ks.test( p_value, "punif", 0, 1 )
hist( p_value, 30 )


#in case there is a difference between the groups - we have a skewed to 0 p-value distribution
ks.test( p_value_H1, "punif", 0, 1 )
hist( p_value_H1, 30 )

#in case all are from the same distribution - we have a uniform p-value distribution
ks.test( p_value_2_blocks, "punif", 0, 1 )
hist( p_value_2_blocks, 30 )


#in case there is a difference between the groups - we have a skewed to 0 p-value distribution
ks.test( p_value_H1_2_blocks, "punif", 0, 1 )
hist( p_value_H1_2_blocks, 30 )

cor( p_value_H1,  p_value_H1_2_blocks )
cor( p_value,  p_value_2_blocks )
```

